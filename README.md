# Fundamento de Microsserviços

## Aula 1: Microsserviços - Fundamentos, Vantagens e Desafios

A primeira aula explora os fundamentos da arquitetura de microsserviços, desmistificando conceitos essenciais e esclarecendo que se trata primariamente de uma arquitetura de infraestrutura, não de código. Microsserviços são caracterizados por serviços independentemente implantáveis, modelados em torno de domínios de negócio específicos, onde cada serviço pode utilizar tecnologias e bancos de dados distintos conforme suas necessidades. A aula demonstra vantagens significativas como escalabilidade direcionada, onde serviços podem ser escalados individualmente baseado em suas cargas específicas, infraestrutura otimizada por serviço, e desenvolvimento paralelo eficiente em equipes grandes. Utilizando o exemplo prático de um sistema de encurtamento de URLs, ilustra-se como o serviço de Analytics pode operar em múltiplas instâncias processando milhões de acessos, enquanto o serviço de Encurtamento permanece em infraestrutura modesta, demonstrando a granularidade na alocação de recursos.

Contudo, a aula enfatiza que microsserviços introduzem complexidades substanciais que não devem ser subestimadas. Cada desafio presente em monolitos multiplica-se pelo número de serviços, incluindo observabilidade, debugging distribuído, gestão de latência e consistência de dados entre serviços isolados. A necessidade de cada serviço possuir seu próprio banco de dados, comunicando-se exclusivamente através de protocolos como HTTP, gRPC, Kafka ou RabbitMQ, cria desafios de consistência eventual e transações distribuídas que exigem padrões como Saga Pattern e CQRS. A aula conclui com orientação pragmática: microsserviços fazem sentido para organizações grandes com centenas de desenvolvedores, domínios de negócio bem definidos e maturidade em DevOps, enquanto monolitos bem estruturados frequentemente representam escolha mais apropriada para equipes menores e produtos em validação inicial.

Para detalhamento completo dos conceitos, vantagens, desafios, padrões arquiteturais, ferramentas do ecossistema e exemplos práticos, consulte o [documento completo da Aula 1](.github/docs/content/a1.md).

## Aula 2: Comunicação em Microsserviços - Padrões, Protocolos e Práticas

A segunda aula aprofunda-se nos mecanismos de comunicação entre microsserviços, explorando os dois paradigmas fundamentais: comunicação síncrona e assíncrona. A comunicação síncrona, realizada através de protocolos como HTTP/REST e gRPC, é apropriada quando respostas imediatas são necessárias para decisões de negócio, como validação de estoque antes de criar pedido ou autenticação de usuário. O gRPC destaca-se por utilizar HTTP/2 e Protocol Buffers, oferecendo performance superior através de serialização binária eficiente e tipagem forte garantida por contratos em arquivos `.proto`. Entretanto, a comunicação síncrona introduz acoplamento temporal direto entre serviços, onde a indisponibilidade de uma dependência compromete imediatamente a operação requisitante. Este acoplamento, embora apropriado para operações críticas que exigem validação em tempo real, contradiz o princípio fundamental de independência operacional dos microsserviços.

A comunicação assíncrona emerge como padrão predominante para desacoplamento efetivo, mediada por message brokers como Apache Kafka e RabbitMQ que implementam o padrão Publish/Subscribe. Neste modelo, produtores publicam eventos em tópicos sem conhecimento de consumidores, enquanto consumidores subscrevem-se a tópicos de interesse processando mensagens em seu próprio ritmo. Apache Kafka, posicionado como plataforma de streaming de eventos distribuída, oferece arquitetura baseada em tópicos particionados com retenção configurável de mensagens, Consumer Groups para paralelização horizontal e capacidade de reprocessamento histórico, sendo ideal para event sourcing e stream processing. RabbitMQ, implementando protocolo AMQP, foca em entrega garantida com roteamento complexo através de exchanges e filas, adequado para job queues e tarefas em background. A aula demonstra implementações práticas utilizando KafkaJS em TypeScript, incluindo contratos de mensagens tipados com Zod, estratégias de resiliência como Circuit Breaker e Dead Letter Queues, padrões avançados como Saga Pattern para transações distribuídas, e observabilidade através de Correlation IDs para rastreamento end-to-end em sistemas distribuídos.

Para detalhamento completo sobre protocolos síncronos e assíncronos, implementações práticas com exemplos de código TypeScript, comparação entre Kafka e RabbitMQ, padrões de resiliência e estratégias de observabilidade, consulte o [documento completo da Aula 2](.github/docs/content/a2.md).

## Aula 3: Persistência em Microsserviços - Desafios, Padrões e Estratégias

A terceira aula aborda o desafio crucial da persistência de dados em arquiteturas de microsserviços, explorando o princípio fundamental "Database per Service" que estabelece que cada microsserviço deve possuir controle exclusivo sobre seu armazenamento de dados. Este isolamento, embora essencial para independência operacional e autonomia tecnológica, introduz complexidades substanciais relacionadas à duplicação controlada de dados, consistência eventual e coordenação de transações distribuídas. A aula demonstra como serviços distintos podem utilizar tecnologias de persistência heterogêneas otimizadas para suas necessidades específicas, exemplificando com MongoDB para flexibilidade documental no serviço de Encurtamento de URLs e ClickHouse otimizado para agregações analíticas em grandes volumes temporais no serviço de Analytics. A duplicação de dados não representa falha arquitetural mas estratégia deliberada, onde cada serviço mantém apenas dados essenciais para sua operação, sincronizados via eventos assíncronos publicados pelo serviço autoritativo. Utilizando exemplo prático de e-commerce com serviços Orders, Invoices e Shipping, ilustra-se como entidade Customer possui cópias parciais em cada serviço, contendo exclusivamente atributos necessários para suas responsabilidades específicas.

O conceito de Soft References substitui Foreign Keys tradicionais em contextos distribuídos, permitindo referências entre entidades de serviços distintos sem constraints de integridade do banco de dados, com prefixação por origem facilitando rastreamento como `orders_customer_id` ou `inventory_product_id`. A aula aprofunda-se em padrões avançados essenciais para coordenação de operações complexas, apresentando Saga Pattern para gerenciamento de transações distribuídas através de sequências de transações locais com compensações, demonstrando implementação de orquestrador que garante reversão de estado mediante falhas sem acoplamento temporal de Two-Phase Commit. Event Sourcing emerge como padrão invertendo modelo tradicional de persistência, armazenando sequência imutável de eventos representando todas mudanças ao invés de sobrescrever estado atual, fornecendo auditoria completa e capacidade de reconstrução temporal. CQRS (Command Query Responsibility Segregation) complementa Event Sourcing separando modelos de escrita que modificam Event Store e leitura que consultam projeções otimizadas construídas a partir de eventos, permitindo otimizações específicas para comandos e queries com trade-off de complexidade operacional adicional.

Para detalhamento completo sobre Database per Service, duplicação controlada de dados, Soft References, reconciliação e auditoria, Saga Pattern com orquestração e coreografia, Event Sourcing, CQRS, comparação de tecnologias de bancos de dados e estratégias de migração de monolito, consulte o [documento completo da Aula 3](.github/docs/content/a3.md).

## Aula 4: Autenticação em Microsserviços - Tokens, Criptografia e JWKS

A quarta aula aborda desafio crítico de autenticação em sistemas distribuídos, onde múltiplos serviços independentes expõem rotas HTTP protegidas sem duplicar mecanismos de autenticação em cada serviço. Solução arquitetural estabelecida centraliza responsabilidade de autenticação em serviço especializado dedicado que gera tokens de autenticação, enquanto serviços de domínio como Shortener e Analytics assumem exclusivamente papel de validação de credenciais já emitidas. JSON Web Token emerge como padrão predominante por natureza autocontida que encapsula claims de identidade em estrutura tripartite assinada criptograficamente: Header declarando algoritmo, Payload contendo dados do usuário, e Signature garantindo integridade. Aula contrasta algoritmos de assinatura simétrica como HS256, onde chave secreta única é compartilhada entre Auth Service e todos validadores, com algoritmos assimétricos como RS256 utilizando criptografia RSA onde chave privada exclusivamente no Auth Service gera assinaturas validadas por chave pública distribuída livremente aos serviços consumidores. Abordagem assimétrica resolve fundamentalmente problema de proliferação de segredos sensíveis, permitindo que comprometimento de serviço de domínio exponha apenas chave pública incapaz de forjar tokens, enquanto rotação de chaves simplifica-se eliminando necessidade de redeploy coordenado de centenas de serviços.

JSON Web Key Set, especificado na RFC 7517, eleva maturidade operacional publicando chaves públicas através de endpoint `/.well-known/jwks.json` acessível dinamicamente. Auth Service expõe conjunto de chaves ativas incluindo metadados como kid fornecendo identificador único para seleção durante validação, permitindo rotação transparente onde múltiplas chaves coexistem durante período de transição. Serviços consumidores utilizam biblioteca `jwks-rsa` para buscar chave apropriada baseando-se em kid presente no header JWT, implementando cache inteligente com TTL configurável entre 10 minutos e 1 hora que invalida-se automaticamente ao encontrar kid desconhecido, atualizando-se sem intervenção operacional. Aula demonstra implementação completa utilizando TypeScript e Express, incluindo registro de usuários com Argon2 para hashing de senhas resistente a força bruta, geração de tokens com claims temporais e audiência validada, middleware de autenticação reutilizável integrando validação JWKS, e padrões avançados como Refresh Tokens stateful de longa duração permitindo renovação de Access Tokens sem reapresentar credenciais. Segurança efetiva transcende implementação criptográfica, demandando validação rigorosa de claims para prevenir algorithm confusion attacks, proteção de chaves privadas através de Hardware Security Modules, rate limiting contra credential stuffing, e observabilidade abrangente através de logs estruturados com correlation IDs rastreando requisições end-to-end em sistemas distribuídos.

Para detalhamento completo sobre algoritmos simétricos e assimétricos, JWKS com cache inteligente, fluxo end-to-end de autenticação, Refresh Tokens, OAuth 2.0 e OpenID Connect, Mutual TLS para service-to-service, validação de claims, proteção de chaves privadas e estratégias de observabilidade, consulte o [documento completo da Aula 4](.github/docs/content/a4.md).

## Aula 5: Fundamento API Gateway - Centralização, Roteamento e Políticas Transversais

A quinta aula introduz API Gateway como componente arquitetural fundamental resolvendo desafio crítico de fragmentação de comunicação em sistemas de microsserviços, onde proliferação de serviços independentes operando em hosts e portas distintas criaria complexidade insustentável exigindo que clientes front-end gerenciem configuração de dezenas de URLs individuais, implementem descoberta de serviços e tratem falhas específicas de cada endpoint. API Gateway estabelece ponto de entrada único e centralizado operando como proxy reverso inteligente que recebe requisições de clientes através de interface unificada como `api.exemplo.com`, executa roteamento baseado em padrões de URL onde requisições para `/api/shortener/*` direcionam-se ao Shortener Service e `/api/analytics/`* ao Analytics Service, e encaminha requisições aos microsserviços apropriados retornando respostas agregadas, abstraindo completamente topologia interna de cliente. Aula demonstra implementação prática utilizando Kong Gateway configurado declarativamente via YAML onde arquivo `kong.yml` define Services representando backends upstream, Routes mapeando padrões de URL a serviços específicos com configuração de `strip_path` e `preserve_host`, e Plugins adicionando funcionalidades transversais aplicadas globalmente ou por serviço. Benefícios fundamentais incluem isolamento de clientes de particionamento interno permitindo reorganização transparente de infraestrutura backend sem impactar contratos públicos, otimização de APIs customizadas para diferentes tipos de clientes através de payloads distintos para mobile e web, redução de overhead de rede agregando múltiplas requisições em roundtrip único eliminando latência acumulada, e simplificação de lógica de cliente transferindo responsabilidade de orquestração complexa para gateway.

Concentração de responsabilidades transversais constitui vantagem estratégica onde API Gateway centraliza autenticação validando tokens JWT através de plugin dedicado que consulta JWKS endpoint do Auth Service, extrai claims de usuário autenticado e injeta `header X-User-ID` consumido por serviços downstream eliminando necessidade de validação redundante em cada microsserviço. Rate limiting implementado no gateway protege sistema inteiro contra abuso através de políticas configuráveis limitando 60 requisições por minuto por consumidor autenticado independente de serviços alvo requisitados, armazenando contadores em Redis para consistência através de múltiplas instâncias Kong horizontalmente escaladas, retornando `HTTP 429 Too Many Requests` com headers informativos quando limite é excedido. Plugin Request Transformer modifica requisições adicionando headers customizados, removendo Authorization sensível antes de encaminhar a upstream, e substituindo valores para roteamento baseado em nomes de serviço internos. Observabilidade centralizada através de plugin correlation-id propaga UUID único em `header X-Correlation-ID` rastreando requisições end-to-end através de múltiplos serviços facilitando debugging distribuído, enquanto integração nativa com Prometheus expõe métricas detalhadas de tráfego, latência em percentis p95/p99 e taxa de erros por serviço. Load balancing através de Upstreams distribui tráfego entre múltiplas instâncias de serviço backend utilizando algoritmos como round-robin ou consistent-hashing garantindo afinidade de sessão, combinado com health checking ativo sondando periodicamente endpoint `/health` e passivo monitorando taxa de erros de produção para remoção automática de instâncias falhas. Trade-offs incluem complexidade adicional de componente intermediário exigindo deployment e manutenção dedicados, overhead de performance tipicamente inferior a 10 milissegundos através de hop de rede extra, risco de tornar-se monolito distribuído quando responsabilidades excessivas concentram-se inadequadamente, e necessidade de arquitetura reativa baseada em event loops não-bloqueantes para processamento eficiente de milhares de requisições concorrentes.

Para detalhamento completo sobre padrão API Gateway e motivações arquiteturais, soluções disponíveis incluindo Kong, Apache APISIX, Traefik e Envoy, configuração declarativa YAML completa, autenticação JWT via plugins com JWKS, Request Transformer para injeção de headers, rate limiting com múltiplas políticas de armazenamento, agregação de respostas de múltiplos serviços, padrão Backend for Frontend, observabilidade com Correlation IDs e Prometheus, load balancing com health checking ativo e passivo, diferenciação entre API Gateway e Service Mesh, validação de input e CORS, TLS termination, deployment em Kubernetes com Helm charts, e glossário de termos técnicos, consulte o [documento completo da Aula 5](.github/docs/content/a5.md).

## Aula 6: Tracing Distribuído - Observabilidade em Sistemas de Microsserviços

A sexta aula aborda desafio crítico de observabilidade em arquiteturas de microsserviços, onde complexidade de sistemas distribuídos com requisições atravessando múltiplos serviços através de comunicação síncrona via HTTP/gRPC e assíncrona via Apache Kafka torna debugging e otimização de performance impossíveis sem visibilidade end-to-end. Tracing distribuído emerge como padrão fundamental que instrumenta aplicações para capturar, correlacionar e visualizar jornada completa de requisições através de topologia distribuída, propagando contexto de rastreamento através de identificadores únicos que acompanham operação desde origem até conclusão independentemente de quantos serviços intermediários participem do processamento. OpenTelemetry estabelece-se como framework vendor-neutral unificado fornecendo APIs, SDKs padronizados e auto-instrumentação para Node.js que automaticamente intercepta e rastreia operações em bibliotecas comuns incluindo HTTP, gRPC, Kafka, PostgreSQL e MongoDB sem modificações no código de aplicação, simplificando adoção através de arquivo de configuração carregado via flag `-r` do Node.js. Arquitetura de tracing baseia-se em conceitos fundamentais de Traces representando jornada completa end-to-end, Spans como unidades atômicas de trabalho com timestamps capturando operações individuais, Trace ID único propagado através de todos serviços garantindo correlação via especificação W3C Trace Context, e Span ID estabelecendo relacionamento parent-child formando árvore hierárquica visualizada em flame graphs.

Aula demonstra implementação prática incluindo configuração de OpenTelemetry SDK com BatchSpanProcessor exportando traces via protocolo OTLP para Jaeger utilizado em desenvolvimento local fornecendo UI web para busca e análise de traces, e Grafana Tempo otimizado para produção através de armazenamento em object storage econômico como S3 integrado nativamente com ecossistema Grafana permitindo correlação de traces com logs agregados por Loki e métricas coletadas por Prometheus em interface unificada. Estratégias de sampling controlam volume de traces coletados balanceando visibilidade e custos operacionais: head-based sampling decide capturar ou descartar trace no momento de criação baseando-se em taxa configurada aplicando algoritmo probabilístico antes de conhecimento de outcomes de processamento, enquanto tail-based sampling implementado através de OpenTelemetry Collector diferindo decisão até conclusão completa de trace permitindo lógica sofisticada que preserva automaticamente 100% de traces contendo erros ou latência excedendo threshold configurado. Padrões avançados incluem correlação entre logs e traces através de injeção automática de Trace ID em structured logs usando bibliotecas como Winston, Span Events registrando ocorrências timestamped como exceções capturadas durante execução sem criar spans filhos adicionais, instrumentação manual complementando auto-instrumentação através de criação explícita de spans customizados representando operações de negócio específicas de domínio, e integração com service mesh como Istio que automaticamente gera spans para requisições HTTP/gRPC interceptadas por Envoy sidecars fornecendo visibilidade baseline de topologia de comunicação combinada com instrumentação de aplicação capturando lógica de negócio.

Para detalhamento completo sobre desafios de observabilidade em microsserviços, fundamentos de tracing distribuído com Traces e Spans, OpenTelemetry como padrão unificado incluindo auto-instrumentação Node.js e configuração de NodeSDK, propagação de contexto através de W3C Trace Context para HTTP e headers de mensagens Kafka, Jaeger para desenvolvimento e Grafana Tempo para produção com integração Loki, estratégias de head-based e tail-based sampling com políticas configuráveis, correlação entre logs e traces via Winston, Span Events e instrumentação manual, observabilidade em service mesh com Istio Envoy sidecars, exemplos completos de código TypeScript, configurações Docker Compose para stack de observabilidade local, queries TraceQL para busca avançada em Tempo, e glossário de termos técnicos, consulte o [documento completo da Aula 6](.github/docs/content/a6.md).
