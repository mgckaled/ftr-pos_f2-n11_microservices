# Fundamentos de Microsserviços

Repositório pessoal de registro, referência e suporte para fins de aprendizado, consulta e acompanhamento da disciplina de Fundamentos de Microsserviços (Nível 11), Fase 2 (Estratégia e Inovação), do curso de Pós-Graduação Tech Developer 360, desenvolvido pela Faculdade de Tecnologia Rocketseat (FTR).

>[!NOTE]
> [Questionário Avaliativo](./.github/docs/content/assessment/q.md)
>
> [Resumo das aulas](./.github/docs/content/resume/classes.md)
>
> [Repositório](https://github.com/rocketseat-education/ftr-fundamentos-microsservicos) de acompanhamento das aulas

## Projeto Prático: Distributed Order Platform

O projeto implementa arquitetura de microsserviços distribuída composta por quatro serviços de domínio independentes coordenados por API Gateway centralizado, demonstrando pragmaticamente padrões fundamentais de sistemas distribuídos aplicados a plataforma de gerenciamento de pedidos. Arquitetura estabelece separação rigorosa mediante princípio Database per Service com quatro instâncias PostgreSQL isoladas, comunicação assíncrona através de Apache Kafka para propagação de eventos de negócio, comunicação síncrona HTTP/REST para operações críticas exigindo validação imediata, Redis para caching distribuído e implementação de idempotência, validação tipada end-to-end mediante Zod schemas, e autenticação centralizada mediante JSON Web Tokens assinados com algoritmo assimétrico RS256 publicando chaves públicas via JSON Web Key Set. Stack tecnológica fundamenta-se em Node.js v22 com TypeScript fornecendo type safety completo, framework NestJS oferecendo arquitetura modular enterprise-grade com dependency injection nativo, gerenciamento de dependências via pnpm workspaces organizando monorepo, TypeORM para persistência relacional, KafkaJS como cliente Apache Kafka, Scalar substituindo Swagger para documentação OpenAPI moderna, e Docker Compose orquestrando infraestrutura completa permitindo execução local simplificada.

Serviços implementados incluem Auth Service centralizando responsabilidade de autenticação gerando tokens JWT e expondo endpoint JWKS, Orders Service atuando como orchestrator de Saga Pattern coordenando transações distribuídas através de múltiplos contextos com compensações automáticas mediante falhas, Inventory Service gerenciando estoque mediante reservas temporárias e commit definitivo após confirmação de pedidos, Analytics Service implementando lado de leitura de CQRS consumindo eventos Kafka atualizando View Tables desnormalizadas eliminando necessidade de joins distribuídos, e API Gateway estabelecendo ponto de entrada único mediante proxy HTTP agregando documentação centralizada e tratamento de erros críticos. Padrões arquiteturais demonstrados incluem Saga Pattern com orchestrator coordenando sequência de transações locais através de etapas com ações e compensações semânticas inversas, Database per Service garantindo autonomia operacional completa de cada microsserviço, CQRS separando modelos de escrita transacionais de leitura otimizadas mediante projeções materializadas assíncronas, idempotência básica mediante tabela de eventos processados prevenindo duplicação de operações críticas, Soft References permitindo referências entre entidades de serviços distintos sem constraints de integridade, e observabilidade mediante correlation IDs propagados através de requisições rastreando fluxo end-to-end em sistema distribuído.

>[!NOTE]
> [Distributed Order Platform - Documentação Técnica](./docs/README.md)

## Aula 1: Microsserviços - Fundamentos, Vantagens e Desafios

A primeira aula explora os fundamentos da arquitetura de microsserviços, desmistificando conceitos essenciais e esclarecendo que se trata primariamente de uma arquitetura de infraestrutura, não de código. Microsserviços são caracterizados por serviços independentemente implantáveis, modelados em torno de domínios de negócio específicos, onde cada serviço pode utilizar tecnologias e bancos de dados distintos conforme suas necessidades. A aula demonstra vantagens significativas como escalabilidade direcionada, onde serviços podem ser escalados individualmente baseado em suas cargas específicas, infraestrutura otimizada por serviço, e desenvolvimento paralelo eficiente em equipes grandes. Utilizando o exemplo prático de um sistema de encurtamento de URLs, ilustra-se como o serviço de Analytics pode operar em múltiplas instâncias processando milhões de acessos, enquanto o serviço de Encurtamento permanece em infraestrutura modesta, demonstrando a granularidade na alocação de recursos.

Contudo, a aula enfatiza que microsserviços introduzem complexidades substanciais que não devem ser subestimadas. Cada desafio presente em monolitos multiplica-se pelo número de serviços, incluindo observabilidade, debugging distribuído, gestão de latência e consistência de dados entre serviços isolados. A necessidade de cada serviço possuir seu próprio banco de dados, comunicando-se exclusivamente através de protocolos como HTTP, gRPC, Kafka ou RabbitMQ, cria desafios de consistência eventual e transações distribuídas que exigem padrões como Saga Pattern e CQRS. A aula conclui com orientação pragmática: microsserviços fazem sentido para organizações grandes com centenas de desenvolvedores, domínios de negócio bem definidos e maturidade em DevOps, enquanto monolitos bem estruturados frequentemente representam escolha mais apropriada para equipes menores e produtos em validação inicial.

Para detalhamento completo dos conceitos, vantagens, desafios, padrões arquiteturais, ferramentas do ecossistema e exemplos práticos, consulte o [documento completo da Aula 1](.github/docs/content/a1.md).

## Aula 2: Comunicação em Microsserviços - Padrões, Protocolos e Práticas

A segunda aula aprofunda-se nos mecanismos de comunicação entre microsserviços, explorando os dois paradigmas fundamentais: comunicação síncrona e assíncrona. A comunicação síncrona, realizada através de protocolos como HTTP/REST e gRPC, é apropriada quando respostas imediatas são necessárias para decisões de negócio, como validação de estoque antes de criar pedido ou autenticação de usuário. O gRPC destaca-se por utilizar HTTP/2 e Protocol Buffers, oferecendo performance superior através de serialização binária eficiente e tipagem forte garantida por contratos em arquivos `.proto`. Entretanto, a comunicação síncrona introduz acoplamento temporal direto entre serviços, onde a indisponibilidade de uma dependência compromete imediatamente a operação requisitante. Este acoplamento, embora apropriado para operações críticas que exigem validação em tempo real, contradiz o princípio fundamental de independência operacional dos microsserviços.

A comunicação assíncrona emerge como padrão predominante para desacoplamento efetivo, mediada por message brokers como Apache Kafka e RabbitMQ que implementam o padrão Publish/Subscribe. Neste modelo, produtores publicam eventos em tópicos sem conhecimento de consumidores, enquanto consumidores subscrevem-se a tópicos de interesse processando mensagens em seu próprio ritmo. Apache Kafka, posicionado como plataforma de streaming de eventos distribuída, oferece arquitetura baseada em tópicos particionados com retenção configurável de mensagens, Consumer Groups para paralelização horizontal e capacidade de reprocessamento histórico, sendo ideal para event sourcing e stream processing. RabbitMQ, implementando protocolo AMQP, foca em entrega garantida com roteamento complexo através de exchanges e filas, adequado para job queues e tarefas em background. A aula demonstra implementações práticas utilizando KafkaJS em TypeScript, incluindo contratos de mensagens tipados com Zod, estratégias de resiliência como Circuit Breaker e Dead Letter Queues, padrões avançados como Saga Pattern para transações distribuídas, e observabilidade através de Correlation IDs para rastreamento end-to-end em sistemas distribuídos.

Para detalhamento completo sobre protocolos síncronos e assíncronos, implementações práticas com exemplos de código TypeScript, comparação entre Kafka e RabbitMQ, padrões de resiliência e estratégias de observabilidade, consulte o [documento completo da Aula 2](.github/docs/content/a2.md).

## Aula 3: Persistência em Microsserviços - Desafios, Padrões e Estratégias

A terceira aula aborda o desafio crucial da persistência de dados em arquiteturas de microsserviços, explorando o princípio fundamental "Database per Service" que estabelece que cada microsserviço deve possuir controle exclusivo sobre seu armazenamento de dados. Este isolamento, embora essencial para independência operacional e autonomia tecnológica, introduz complexidades substanciais relacionadas à duplicação controlada de dados, consistência eventual e coordenação de transações distribuídas. A aula demonstra como serviços distintos podem utilizar tecnologias de persistência heterogêneas otimizadas para suas necessidades específicas, exemplificando com MongoDB para flexibilidade documental no serviço de Encurtamento de URLs e ClickHouse otimizado para agregações analíticas em grandes volumes temporais no serviço de Analytics. A duplicação de dados não representa falha arquitetural mas estratégia deliberada, onde cada serviço mantém apenas dados essenciais para sua operação, sincronizados via eventos assíncronos publicados pelo serviço autoritativo. Utilizando exemplo prático de e-commerce com serviços Orders, Invoices e Shipping, ilustra-se como entidade Customer possui cópias parciais em cada serviço, contendo exclusivamente atributos necessários para suas responsabilidades específicas.

O conceito de Soft References substitui Foreign Keys tradicionais em contextos distribuídos, permitindo referências entre entidades de serviços distintos sem constraints de integridade do banco de dados, com prefixação por origem facilitando rastreamento como `orders_customer_id` ou `inventory_product_id`. A aula aprofunda-se em padrões avançados essenciais para coordenação de operações complexas, apresentando Saga Pattern para gerenciamento de transações distribuídas através de sequências de transações locais com compensações, demonstrando implementação de orquestrador que garante reversão de estado mediante falhas sem acoplamento temporal de Two-Phase Commit. Event Sourcing emerge como padrão invertendo modelo tradicional de persistência, armazenando sequência imutável de eventos representando todas mudanças ao invés de sobrescrever estado atual, fornecendo auditoria completa e capacidade de reconstrução temporal. CQRS (Command Query Responsibility Segregation) complementa Event Sourcing separando modelos de escrita que modificam Event Store e leitura que consultam projeções otimizadas construídas a partir de eventos, permitindo otimizações específicas para comandos e queries com trade-off de complexidade operacional adicional.

Para detalhamento completo sobre Database per Service, duplicação controlada de dados, Soft References, reconciliação e auditoria, Saga Pattern com orquestração e coreografia, Event Sourcing, CQRS, comparação de tecnologias de bancos de dados e estratégias de migração de monolito, consulte o [documento completo da Aula 3](.github/docs/content/a3.md).

## Aula 4: Autenticação em Microsserviços - Tokens, Criptografia e JWKS

A quarta aula aborda desafio crítico de autenticação em sistemas distribuídos, onde múltiplos serviços independentes expõem rotas HTTP protegidas sem duplicar mecanismos de autenticação em cada serviço. Solução arquitetural estabelecida centraliza responsabilidade de autenticação em serviço especializado dedicado que gera tokens de autenticação, enquanto serviços de domínio como Shortener e Analytics assumem exclusivamente papel de validação de credenciais já emitidas. JSON Web Token emerge como padrão predominante por natureza autocontida que encapsula claims de identidade em estrutura tripartite assinada criptograficamente: Header declarando algoritmo, Payload contendo dados do usuário, e Signature garantindo integridade. Aula contrasta algoritmos de assinatura simétrica como HS256, onde chave secreta única é compartilhada entre Auth Service e todos validadores, com algoritmos assimétricos como RS256 utilizando criptografia RSA onde chave privada exclusivamente no Auth Service gera assinaturas validadas por chave pública distribuída livremente aos serviços consumidores. Abordagem assimétrica resolve fundamentalmente problema de proliferação de segredos sensíveis, permitindo que comprometimento de serviço de domínio exponha apenas chave pública incapaz de forjar tokens, enquanto rotação de chaves simplifica-se eliminando necessidade de redeploy coordenado de centenas de serviços.

JSON Web Key Set, especificado na RFC 7517, eleva maturidade operacional publicando chaves públicas através de endpoint `/.well-known/jwks.json` acessível dinamicamente. Auth Service expõe conjunto de chaves ativas incluindo metadados como kid fornecendo identificador único para seleção durante validação, permitindo rotação transparente onde múltiplas chaves coexistem durante período de transição. Serviços consumidores utilizam biblioteca `jwks-rsa` para buscar chave apropriada baseando-se em kid presente no header JWT, implementando cache inteligente com TTL configurável entre 10 minutos e 1 hora que invalida-se automaticamente ao encontrar kid desconhecido, atualizando-se sem intervenção operacional. Aula demonstra implementação completa utilizando TypeScript e Express, incluindo registro de usuários com Argon2 para hashing de senhas resistente a força bruta, geração de tokens com claims temporais e audiência validada, middleware de autenticação reutilizável integrando validação JWKS, e padrões avançados como Refresh Tokens stateful de longa duração permitindo renovação de Access Tokens sem reapresentar credenciais. Segurança efetiva transcende implementação criptográfica, demandando validação rigorosa de claims para prevenir algorithm confusion attacks, proteção de chaves privadas através de Hardware Security Modules, rate limiting contra credential stuffing, e observabilidade abrangente através de logs estruturados com correlation IDs rastreando requisições end-to-end em sistemas distribuídos.

Para detalhamento completo sobre algoritmos simétricos e assimétricos, JWKS com cache inteligente, fluxo end-to-end de autenticação, Refresh Tokens, OAuth 2.0 e OpenID Connect, Mutual TLS para service-to-service, validação de claims, proteção de chaves privadas e estratégias de observabilidade, consulte o [documento completo da Aula 4](.github/docs/content/a4.md).

## Aula 5: Fundamento API Gateway - Centralização, Roteamento e Políticas Transversais

A quinta aula introduz API Gateway como componente arquitetural fundamental resolvendo desafio crítico de fragmentação de comunicação em sistemas de microsserviços, onde proliferação de serviços independentes operando em hosts e portas distintas criaria complexidade insustentável exigindo que clientes front-end gerenciem configuração de dezenas de URLs individuais, implementem descoberta de serviços e tratem falhas específicas de cada endpoint. API Gateway estabelece ponto de entrada único e centralizado operando como proxy reverso inteligente que recebe requisições de clientes através de interface unificada como `api.exemplo.com`, executa roteamento baseado em padrões de URL onde requisições para `/api/shortener/*` direcionam-se ao Shortener Service e `/api/analytics/`* ao Analytics Service, e encaminha requisições aos microsserviços apropriados retornando respostas agregadas, abstraindo completamente topologia interna de cliente. Aula demonstra implementação prática utilizando Kong Gateway configurado declarativamente via YAML onde arquivo `kong.yml` define Services representando backends upstream, Routes mapeando padrões de URL a serviços específicos com configuração de `strip_path` e `preserve_host`, e Plugins adicionando funcionalidades transversais aplicadas globalmente ou por serviço. Benefícios fundamentais incluem isolamento de clientes de particionamento interno permitindo reorganização transparente de infraestrutura backend sem impactar contratos públicos, otimização de APIs customizadas para diferentes tipos de clientes através de payloads distintos para mobile e web, redução de overhead de rede agregando múltiplas requisições em roundtrip único eliminando latência acumulada, e simplificação de lógica de cliente transferindo responsabilidade de orquestração complexa para gateway.

Concentração de responsabilidades transversais constitui vantagem estratégica onde API Gateway centraliza autenticação validando tokens JWT através de plugin dedicado que consulta JWKS endpoint do Auth Service, extrai claims de usuário autenticado e injeta `header X-User-ID` consumido por serviços downstream eliminando necessidade de validação redundante em cada microsserviço. Rate limiting implementado no gateway protege sistema inteiro contra abuso através de políticas configuráveis limitando 60 requisições por minuto por consumidor autenticado independente de serviços alvo requisitados, armazenando contadores em Redis para consistência através de múltiplas instâncias Kong horizontalmente escaladas, retornando `HTTP 429 Too Many Requests` com headers informativos quando limite é excedido. Plugin Request Transformer modifica requisições adicionando headers customizados, removendo Authorization sensível antes de encaminhar a upstream, e substituindo valores para roteamento baseado em nomes de serviço internos. Observabilidade centralizada através de plugin correlation-id propaga UUID único em `header X-Correlation-ID` rastreando requisições end-to-end através de múltiplos serviços facilitando debugging distribuído, enquanto integração nativa com Prometheus expõe métricas detalhadas de tráfego, latência em percentis p95/p99 e taxa de erros por serviço. Load balancing através de Upstreams distribui tráfego entre múltiplas instâncias de serviço backend utilizando algoritmos como round-robin ou consistent-hashing garantindo afinidade de sessão, combinado com health checking ativo sondando periodicamente endpoint `/health` e passivo monitorando taxa de erros de produção para remoção automática de instâncias falhas. Trade-offs incluem complexidade adicional de componente intermediário exigindo deployment e manutenção dedicados, overhead de performance tipicamente inferior a 10 milissegundos através de hop de rede extra, risco de tornar-se monolito distribuído quando responsabilidades excessivas concentram-se inadequadamente, e necessidade de arquitetura reativa baseada em event loops não-bloqueantes para processamento eficiente de milhares de requisições concorrentes.

Para detalhamento completo sobre padrão API Gateway e motivações arquiteturais, soluções disponíveis incluindo Kong, Apache APISIX, Traefik e Envoy, configuração declarativa YAML completa, autenticação JWT via plugins com JWKS, Request Transformer para injeção de headers, rate limiting com múltiplas políticas de armazenamento, agregação de respostas de múltiplos serviços, padrão Backend for Frontend, observabilidade com Correlation IDs e Prometheus, load balancing com health checking ativo e passivo, diferenciação entre API Gateway e Service Mesh, validação de input e CORS, TLS termination, deployment em Kubernetes com Helm charts, e glossário de termos técnicos, consulte o [documento completo da Aula 5](.github/docs/content/a5.md).

## Aula 6: Tracing Distribuído - Observabilidade em Sistemas de Microsserviços

A sexta aula aborda desafio crítico de observabilidade em arquiteturas de microsserviços, onde complexidade de sistemas distribuídos com requisições atravessando múltiplos serviços através de comunicação síncrona via HTTP/gRPC e assíncrona via Apache Kafka torna debugging e otimização de performance impossíveis sem visibilidade end-to-end. Tracing distribuído emerge como padrão fundamental que instrumenta aplicações para capturar, correlacionar e visualizar jornada completa de requisições através de topologia distribuída, propagando contexto de rastreamento através de identificadores únicos que acompanham operação desde origem até conclusão independentemente de quantos serviços intermediários participem do processamento. OpenTelemetry estabelece-se como framework vendor-neutral unificado fornecendo APIs, SDKs padronizados e auto-instrumentação para Node.js que automaticamente intercepta e rastreia operações em bibliotecas comuns incluindo HTTP, gRPC, Kafka, PostgreSQL e MongoDB sem modificações no código de aplicação, simplificando adoção através de arquivo de configuração carregado via flag `-r` do Node.js. Arquitetura de tracing baseia-se em conceitos fundamentais de Traces representando jornada completa end-to-end, Spans como unidades atômicas de trabalho com timestamps capturando operações individuais, Trace ID único propagado através de todos serviços garantindo correlação via especificação W3C Trace Context, e Span ID estabelecendo relacionamento parent-child formando árvore hierárquica visualizada em flame graphs.

Aula demonstra implementação prática incluindo configuração de OpenTelemetry SDK com BatchSpanProcessor exportando traces via protocolo OTLP para Jaeger utilizado em desenvolvimento local fornecendo UI web para busca e análise de traces, e Grafana Tempo otimizado para produção através de armazenamento em object storage econômico como S3 integrado nativamente com ecossistema Grafana permitindo correlação de traces com logs agregados por Loki e métricas coletadas por Prometheus em interface unificada. Estratégias de sampling controlam volume de traces coletados balanceando visibilidade e custos operacionais: head-based sampling decide capturar ou descartar trace no momento de criação baseando-se em taxa configurada aplicando algoritmo probabilístico antes de conhecimento de outcomes de processamento, enquanto tail-based sampling implementado através de OpenTelemetry Collector diferindo decisão até conclusão completa de trace permitindo lógica sofisticada que preserva automaticamente 100% de traces contendo erros ou latência excedendo threshold configurado. Padrões avançados incluem correlação entre logs e traces através de injeção automática de Trace ID em structured logs usando bibliotecas como Winston, Span Events registrando ocorrências timestamped como exceções capturadas durante execução sem criar spans filhos adicionais, instrumentação manual complementando auto-instrumentação através de criação explícita de spans customizados representando operações de negócio específicas de domínio, e integração com service mesh como Istio que automaticamente gera spans para requisições HTTP/gRPC interceptadas por Envoy sidecars fornecendo visibilidade baseline de topologia de comunicação combinada com instrumentação de aplicação capturando lógica de negócio.

Para detalhamento completo sobre desafios de observabilidade em microsserviços, fundamentos de tracing distribuído com Traces e Spans, OpenTelemetry como padrão unificado incluindo auto-instrumentação Node.js e configuração de NodeSDK, propagação de contexto através de W3C Trace Context para HTTP e headers de mensagens Kafka, Jaeger para desenvolvimento e Grafana Tempo para produção com integração Loki, estratégias de head-based e tail-based sampling com políticas configuráveis, correlação entre logs e traces via Winston, Span Events e instrumentação manual, observabilidade em service mesh com Istio Envoy sidecars, exemplos completos de código TypeScript, configurações Docker Compose para stack de observabilidade local, queries TraceQL para busca avançada em Tempo, e glossário de termos técnicos, consulte o [documento completo da Aula 6](.github/docs/content/a6.md).

## Aula 7: Idempotência em Microsserviços

A sétima aula aborda idempotência como fundamento crítico em arquiteturas de microsserviços, garantindo que operações executadas múltiplas vezes com parâmetros idênticos produzam resultado equivalente à execução única, independentemente de quantas tentativas sejam realizadas. Em sistemas distribuídos caracterizados por comunicação assíncrona através de message brokers como Apache Kafka e RabbitMQ, mensagens podem ser entregues múltiplas vezes devido a falhas de rede, timeouts, rebalanceamentos de partições em Consumer Groups ou reprocessamentos após exceções não tratadas, criando risco substancial de duplicação de operações críticas como cobranças financeiras, criação de registros redundantes ou incrementos incorretos de contadores analíticos. Mecanismo fundamental para implementação de idempotência baseia-se em identificadores únicos denominados Idempotency Keys ou Event IDs que acompanham cada mensagem, permitindo que consumidores consultem tabela de eventos processados antes de executar lógica de negócio, descartando silenciosamente mensagens cujos identificadores já constam como processados anteriormente. Padrão emergiu como requisito não-negociável em sistemas de pagamento demonstrado por implementações de referência em APIs públicas de Stripe, PayPal e Twilio, onde clientes submetem Idempotency-Key em header HTTP garantindo que requisição duplicada por instabilidade de rede não resulte em cobrança dupla ao usuário final. Aula demonstra implementação prática utilizando sistema de encurtamento de URLs onde serviço Shortener publica evento URLCreated para tópico Kafka incluindo Event ID determinístico gerado através de hash SHA-256 dos parâmetros de entrada, enquanto serviço Analytics mantém tabela ProcessedEvents armazenando identificadores de eventos já consumidos com timestamps de processamento, consultando existência antes de inserir registros analíticos e evitando inflação artificial de métricas através de reprocessamentos inadvertidos.

Desafio arquitetural amplia-se em cenários onde consumidor executa múltiplas operações heterogêneas sequencialmente, exemplificado por salvamento no Redis seguido de persistência no PostgreSQL, onde falha na segunda operação após sucesso na primeira desencadeia retentativa automática do Kafka que reexecuta ambas operações, necessitando idempotência implementada granularmente em cada etapa através de verificações específicas como EXISTS no Redis e ON CONFLICT DO NOTHING no PostgreSQL. Conceito transcende implementação técnica para tornar-se propriedade semântica fundamental de APIs RESTful conforme especificação RFC 7231 que classifica métodos HTTP GET, PUT e DELETE como inerentemente idempotentes por design, contrastando com POST que permite criação de recursos distintos a cada invocação, orientando desenvolvedores na modelagem apropriada de endpoints considerando comportamento esperado sob retentativas. Kafka oferece idempotência nativa em nível de produtor através de configuração enable.idempotence que atribui Producer ID único e mantém sequence numbers incrementais por partição, permitindo que broker detecte mensagens duplicadas e descarte silenciosamente retentativas redundantes, enquanto Transactional Producer fornece exactly-once semantics garantindo que múltiplas mensagens publicadas para tópicos distintos sejam commitadas atomicamente ou abortadas completamente mediante falha. Trade-offs incluem overhead de performance através de consultas adicionais a PostgreSQL introduzindo latência de 5-10ms por mensagem ou consultas Redis com 0.5-1ms, complexidade operacional de gerenciar armazenamento crescente de eventos processados através de estratégias de TTL automático e particionamento temporal, e necessidade de coordenação distribuída através de locks Redlock para prevenir race conditions onde múltiplas instâncias de consumidor processam simultaneamente mensagem duplicada, porém benefícios de correção e confiabilidade em presença de falhas de rede justificam amplamente custo incremental.

Para detalhamento completo sobre definição formal de idempotência e diferenciação de deduplicação, implementação de Event IDs determinísticos e aleatórios, tabela de eventos processados com schema PostgreSQL e índices otimizados, idempotência granular em operações heterogêneas Redis e PostgreSQL, configuração de produtores Kafka idempotentes e transacionais com KafkaJS, cache distribuído Redis para deduplicação com estratégia híbrida write-through, métodos HTTP idempotentes conforme RFC 7231 incluindo implementações PUT e DELETE, Idempotency Keys em APIs de pagamento seguindo padrão Stripe, idempotência em Event Sourcing com constraint UNIQUE e optimistic concurrency control, Saga Pattern com orquestrador rastreando etapas executadas, message deduplication em RabbitMQ através de headers customizados, estratégias de otimização como Bloom Filters e sharding temporal, gestão de armazenamento com particionamento PostgreSQL, locks distribuídos Redlock para consistência, exemplos completos de código TypeScript demonstrando sistema de encurtamento de URLs, e glossário de termos técnicos, consulte o [documento completo da Aula 7](.github/docs/content/a7.md).

## Aula 8: Saga Pattern em Microsserviços

A oitava aula apresenta Saga Pattern como padrão arquitetural fundamental para gerenciamento de transações distribuídas em microsserviços, resolvendo desafio crítico de manutenção de consistência de dados através de múltiplos serviços independentes sem depender de coordenação two-phase commit bloqueante. Em sistemas distribuídos caracterizados por Database per Service onde cada microsserviço possui controle exclusivo sobre armazenamento de dados, operações de negócio frequentemente requerem modificações coordenadas através de múltiplos contextos limitados, exemplificado por criação de pedido em e-commerce que desencadeia emissão de nota fiscal em serviço Invoice, preparação de envio em serviço Shipping e atualização de inventário em serviço Inventory, onde falha em qualquer etapa necessita reversão de todas modificações anteriores para evitar inconsistências parciais. Saga implementa transação distribuída como sequência de transações locais coordenadas onde cada serviço executa transação ACID individual em seu próprio banco de dados publicando evento após conclusão bem-sucedida que dispara próxima transação na sequência, enquanto define compensating transaction correspondente para cada operação capaz de desfazer semanticamente modificações realizadas mediante falha em etapa subsequente. Compensação difere fundamentalmente de rollback tradicional por operar em nível semântico executando operação de negócio que anula efeito lógico da transação original ao invés de reversão mecânica através de undo logs, exemplificado por transação que debita 100 unidades de conta bancária onde rollback restauraria diretamente saldo anterior enquanto compensação credita 100 unidades ao saldo atual independente de modificações concorrentes ocorridas entre transação original e compensação. Propriedades fundamentais incluem Atomicidade Relaxada onde saga completa integralmente ou compensa completamente permitindo estados intermediários visíveis durante execução, Isolamento Relaxado eliminando serialização tradicional introduzindo anomalias como dirty reads e lost updates, Durabilidade Garantida através de commit em banco de dados próprio antes de prosseguir, e Consistência Eventual convergindo para consistência após conclusão ou compensação completa.

Padrão manifesta-se através de dois modelos fundamentais de coordenação: Orchestration onde serviço central denominado orchestrator gerencia workflow completo através de comandos diretos enviados a cada participante mantendo estado de execução e decidindo próximas etapas baseado em respostas recebidas, apropriado para lógica complexa com decisões condicionais e visibilidade centralizada de progresso porém introduzindo acoplamento onde orchestrator conhece explicitamente todos participantes; e Choreography onde coordenação emerge através de eventos publicados sem autoridade central com cada serviço subscrevendo eventos relevantes e reagindo autonomamente publicando novos eventos que propagam execução, favorecendo desacoplamento máximo e escalabilidade horizontal natural porém dificultando rastreamento de fluxo completo através de sistema distribuído. Aula demonstra implementação prática de orchestrator customizado utilizando TypeScript para gerenciar deleção de usuário em sistema de encurtamento de URLs, onde remoção de conta em serviço Auth desencadeia saga coordenando deleção de URLs criadas por usuário em serviço Shortener seguida de remoção de dados analíticos em serviço Analytics, com cada etapa implementando soft delete reversível através de timestamps deleted_at permitindo compensações restaurarem registros através de operações UPDATE. Desafios substanciais emergem através de anomalias de isolamento exigindo contramedidas como semantic locks marcando registros em processamento para prevenir dirty reads e commutative updates estruturando operações independentes de ordem para evitar lost updates, complexidade de compensações que devem ser idempotentes tolerando execuções múltiplas sem efeitos colaterais adicionais, e gestão de timeouts e retentativas distinguindo falhas temporárias recuperáveis de permanentes que desencadeiam cascatas de compensações através de workflow implementadas mediante políticas de exponential backoff.

Para detalhamento completo sobre desafio de transações distribuídas e limitações de two-phase commit, definição formal de Saga Pattern incluindo paper original de Garcia-Molina e Salem de 1987, comparação entre Orchestration e Choreography com vantagens e desvantagens de cada abordagem, implementação de orchestrator customizado com definições de workflow incluindo SagaStep com actions e compensations, rastreamento de estado através de tabelas PostgreSQL saga_instances e saga_step_executions, classe SagaOrchestrator completa gerenciando ciclo de vida com métodos startSaga executeStep handleStepCompleted handleStepFailed e compensate, implementação de serviços participantes incluindo URL Shortener Service e Analytics Service com soft delete e restauração, implementação Choreography-based através de eventos com Order Service e Invoice Service reagindo autonomamente, anomalias de isolamento incluindo dirty reads com contramedida semantic lock e lost updates com contramedida commutative updates, políticas de timeout e retentativas com exponential backoff e distinção entre falhas temporárias e permanentes, compensações idempotentes através de verificação de estado e rastreamento de compensações, frameworks especializados como Axon Framework Temporal e Camunda, exemplos completos de código TypeScript, e glossário de termos técnicos, consulte o [documento completo da Aula 8](.github/docs/content/a8.md).

## Aula 9: Backend for Frontend - Agregação e Composição de Dados em Microsserviços

A nona aula apresenta Backend for Frontend como padrão arquitetural essencial resolvendo desafio fundamental de agregação e composição de dados em arquiteturas de microsserviços, onde fragmentação de domínios de negócio através de serviços independentes com bancos de dados isolados mediante princípio Database per Service cria complexidade substancial na apresentação de dados consolidados para clientes consumidores. Frontend confrontado com necessidade de exibir informações agregadas como listagem de pedidos incluindo URLs de notas fiscais e status de envio enfrenta dilemas entre realizar múltiplas requisições HTTP sequenciais a serviços distintos introduzindo latência acumulada inaceitável e problema N+1 queries, ou forçar serviços de domínio a implementarem endpoints customizados violando princípios de responsabilidade única e acoplando backends a necessidades específicas de interfaces. BFF resolve fundamentalmente esta problemática através de introdução de camada intermediária especializada posicionada estrategicamente entre clientes e microsserviços de domínio, assumindo responsabilidade exclusiva de orquestração executando múltiplas requisições paralelas a serviços downstream através de protocolos eficientes como gRPC, consolidando respostas heterogêneas mediante joins lógicos em memória correlacionando entidades através de identificadores compartilhados, e transformando dados em payloads customizados otimizados para consumo específico de aplicações web, mobile, desktop ou IoT. Diferenciando-se criticamente de API Gateway genérico que atua primariamente como proxy reverso implementando políticas transversais como autenticação e rate limiting, BFF executa lógica consciente de entidades de negócio aplicando regras de formatação e filtros específicos de plataforma, exemplificado por Mobile BFF retornando payloads minimalistas reduzindo tráfego de rede em conexões instáveis enquanto Web BFF fornece estruturas abrangentes incluindo metadados para rich interfaces.

GraphQL emerge como tecnologia especialmente adequada para implementação de BFFs através de alinhamento natural entre capacidades de linguagem de query flexível permitindo clientes especificarem exatamente campos necessários eliminando over-fetching e under-fetching, sistema de resolvers fornecendo pontos de extensão ideais para lógica de agregação onde resolver de campo invoice em tipo Order executa chamada a serviço Invoices transparentemente, e DataLoader pattern mitigando efetivamente problema N+1 queries através de batching automático acumulando múltiplas requisições individuais executadas em mesmo ciclo de event loop em requisição única em lote consolidada. Apollo Federation representa evolução permitindo microsserviços exporem diretamente capabilities GraphQL como subgraphs parciais consolidados por gateway em schema federado unificado, reduzindo necessidade de BFF customizado para agregações simples, porém BFF permanece relevante para transformações específicas de cliente e lógica de apresentação complexa impossível de expressar declarativamente. Implementação demanda consideração cuidadosa de trade-offs arquiteturais incluindo overhead operacional de serviço adicional exigindo deployment e manutenção dedicados, risco de duplicação de lógica através de múltiplos BFFs especializados, e necessidade de estratégias de resiliência robustas através de degradação graciosa retornando dados parciais mediante indisponibilidade de serviços não-críticos, Circuit Breaker bloqueando temporariamente requisições a serviços consistentemente falhando, e caching estratégico através de Redis armazenando resultados de agregações reduzindo latência e carga em microsserviços downstream.

Para detalhamento completo sobre contexto e motivação arquitetural, diferenciação entre BFF e API Gateway, implementação com NestJS e TypeScript incluindo clientes gRPC e agregação paralela de múltiplas fontes, transformação e otimização por tipo de cliente, resiliência através de degradação graciosa e Circuit Breaker, implementação com GraphQL e Apollo Server incluindo resolvers aninhados e DataLoader para otimização de N+1 queries, Apollo Federation para decomposição de schema em subgraphs distribuídos, padrões relacionados incluindo API Composition e CQRS com read models desnormalizados, GraphQL Mesh para unificação de fontes heterogêneas, exemplos completos de código TypeScript demonstrando BFF para sistema de e-commerce, métricas e observabilidade rastreando latência de agregações, e glossário de termos técnicos, consulte o [documento completo da Aula 9](.github/docs/content/a9.md).

## Aula 10: CQRS e Event Sourcing em Microsserviços

A décima aula aprofunda-se em Command Query Responsibility Segregation e Event Sourcing como padrões arquiteturais avançados resolvendo desafios críticos de agregação de dados distribuídos e auditoria de mudanças de estado em arquiteturas de microsserviços. CQRS estabelece separação arquitetural explícita onde microsserviços de domínio assumem responsabilidade exclusiva por operações de escrita através de comandos que modificam estado em bancos de dados transacionais otimizados com constraints ACID, enquanto banco de dados separado contém View Tables desnormalizadas populadas automaticamente mediante consumo de eventos publicados via Apache Kafka, eliminando overhead de joins distribuídos e múltiplas requisições HTTP através de dados pré-agregados otimizados para queries específicas com trade-off de consistência eventual. Sincronização de View Tables ocorre mediante consumidores dedicados processando eventos como InvoiceIssued e ShippingUpdated atualizando projeções materializadas como OrdersWithDetailsView consolidando informações de pedidos, clientes, produtos, notas fiscais e envios em estrutura única consultável em latência inferior a centenas de milissegundos. Event Sourcing inverte paradigma tradicional de persistência rejeitando sobrescrita de registros mediante operações UPDATE e DELETE, substituindo por armazenamento exclusivo de sequência imutável de eventos representando fatos históricos como stock_increased e stock_decreased, onde estado atual reconstrói-se mediante replay sequencial através de função de projeção acumulando eventos desde origem da entidade, fornecendo auditoria completa com timestamps e rastreabilidade integral essenciais para domínios regulados como financeiro e saúde.

Event Store representa banco de dados otimizado especificamente para armazenamento append-only de eventos imutáveis garantindo ordenação determinística mediante números de sequência incrementais e atomicidade transacional, implementável através de EventStoreDB especializado ou PostgreSQL com schema otimizado incluindo constraints UNIQUE prevenindo duplicação de sequências. Snapshots otimizam performance de agregados com histórico extenso mediante serialização periódica de estado completo permitindo reconstrução começar a partir de snapshot mais recente aplicando apenas eventos subsequentes ao invés de replay completo de milhares de eventos, com estratégia típica criando snapshot a cada 50 ou 100 eventos balanceando overhead de armazenamento contra benefício de redução de tempo de reconstrução. Combinação sinérgica de CQRS e Event Sourcing estabelece arquitetura onde Event Store serve como banco de dados de escrita para comandos processados por agregados implementando lógica de negócio através de métodos handleCommand que validam regras e produzem eventos, e applyEvent que reconstrói estado mediante bookkeeping sem validações pois eventos representam fatos históricos já ocorridos, enquanto múltiplas projeções como BankAccountSummaryView derivam-se mediante consumidores Kafka atualizando Read Models otimizados para consultas específicas. Frameworks especializados como Axon Framework para Java, Marten para .NET aproveitando capacidades JSONB de PostgreSQL, e Eventuous com integração OpenTelemetry fornecem abstrações completas para agregados, Event Stores e projeções, reduzindo complexidade de implementação mediante convenções e ferramental dedicado para versionamento de eventos através de upcasting, observabilidade distribuída com correlation IDs e gestão de snapshots automáticos.

Para detalhamento completo sobre fundamentos arquiteturais de CQRS incluindo View Tables e sincronização mediante eventos, Event Sourcing com Event Store e snapshots para otimização, implementação de agregados com separação entre handleCommand e applyEvent, processamento de comandos com persistência atômica e publicação Kafka, projeções para Read Models consumindo eventos assincronamente, ferramentas especializadas como EventStoreDB e Axon Framework, considerações sobre quando utilizar ou evitar estes padrões mediante requisitos de auditoria e complexidade, versionamento de eventos através de upcasting, observabilidade com correlation IDs e structured logging, exemplos completos de código TypeScript demonstrando BankAccountAggregate e BankAccountSummaryProjection, schemas PostgreSQL para tabelas events e snapshots, e glossário de termos técnicos incluindo Aggregate, Command Handler, Projection e Snapshot, consulte o [documento completo da Aula 10](.github/docs/content/a10.md).
