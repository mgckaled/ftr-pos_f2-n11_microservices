<!-- markdownlint-disable -->

# CQRS e Event Sourcing em Microsserviços

## Resumo Executivo

Command Query Responsibility Segregation e Event Sourcing representam padrões arquiteturais fundamentais que resolvem desafios críticos de agregação e persistência de dados em arquiteturas de microsserviços distribuídos. CQRS estabelece separação explícita entre operações de escrita mediante comandos que modificam estado e operações de leitura através de queries que consultam dados, permitindo otimizações independentes para cada responsabilidade através de modelos de dados heterogêneos especializados. Event Sourcing complementa este padrão invertendo paradigma tradicional de persistência onde estado atual é sobrescrito, substituindo por armazenamento de sequência imutável de eventos representando todas mudanças ocorridas ao longo do tempo, fornecendo auditoria completa, capacidade de reconstrução temporal de estado e rastreabilidade integral de evolução de entidades de negócio. Combinação sinérgica destes padrões permite que microsserviços mantenham bancos de dados de escrita otimizados para comandos transacionais através de Event Stores armazenando eventos imutáveis, enquanto múltiplas View Tables desnormalizadas são populadas automaticamente para consultas otimizadas sem overhead de joins distribuídos, resolvendo fundamentalmente problemática de agregação de dados fragmentados através de múltiplos serviços independentes com Database per Service.

## Introdução e Conceitos Fundamentais

Arquiteturas de microsserviços caracterizadas por fragmentação de domínios de negócio através de serviços independentes com isolamento de dados mediante princípio Database per Service enfrentam desafio substancial na apresentação de informações consolidadas para consumidores. Requisitos típicos de exibir pedidos incluindo URLs de notas fiscais e status de envio necessitam agregação de dados distribuídos através de serviços Orders, Invoices e Shipping operando independentemente, criando dilemas entre múltiplas requisições HTTP sequenciais introduzindo latência acumulada inaceitável ou forçar serviços de domínio a implementarem endpoints customizados violando responsabilidade única.

CQRS, acrônimo para Command Query Responsibility Segregation traduzido como Segregação de Responsabilidade de Comando e Consulta, fundamenta-se em princípio arquitetural originalmente articulado por Bertrand Meyer no conceito Command Query Separation onde métodos devem ser classificados como comandos que modificam estado sem retornar valores ou queries que retornam dados sem produzir efeitos colaterais. Greg Young expandiu este conceito para nível arquitetural propondo separação física de modelos de dados, infraestrutura e potencialmente serviços dedicados para operações de escrita e leitura, permitindo otimizações específicas impossíveis em arquitetura unificada tradicional.

Event Sourcing representa mudança paradigmática fundamental na persistência de dados, rejeitando modelo convencional onde registros em banco de dados são sobrescritos refletindo exclusivamente estado atual, substituindo por armazenamento de log imutável e ordenado de eventos representando fatos históricos sobre mudanças ocorridas em entidade ao longo do tempo. Estado atual de agregado não é lido diretamente de tabela mas reconstruído mediante aplicação sequencial de todos eventos desde criação da entidade, similar a extrato bancário onde saldo atual deriva-se de histórico completo de transações ao invés de único registro de saldo.

## CQRS: Separação de Responsabilidades de Comando e Consulta

### Fundamentos Arquiteturais de CQRS

CQRS estabelece divisão arquitetural onde microsserviços de domínio como Orders, Invoices e Stock assumem responsabilidade exclusiva por operações de escrita através de comandos representando intenções de modificar estado do sistema. Comandos tipicamente mapeiam para operações HTTP POST, PUT, PATCH e DELETE que criam, atualizam ou removem entidades em bancos de dados transacionais otimizados para escrita com constraints de integridade referencial, validações de regras de negócio e garantias ACID.

Lado de leitura implementa-se através de banco de dados separado contendo View Tables ou Read Models que são tabelas desnormalizadas populadas automaticamente com dados já formatados na estrutura exata requerida para consumo por aplicações cliente. Estas projeções otimizam-se especificamente para queries frequentes eliminando necessidade de joins complexos, agregações computacionalmente custosas ou múltiplas requisições distribuídas, fornecendo performance de leitura superior através de dados pré-computados.

### Fluxo de Dados em CQRS

Quando aplicação cliente necessita criar novo pedido, envia comando CreateOrder para serviço Orders através de requisição HTTP POST. Serviço de comando valida regras de negócio incluindo disponibilidade de estoque consultando serviços dependentes sincronamente, persiste entidade Order em banco de dados transacional PostgreSQL otimizado para escrita, e publica evento OrderCreated para message broker como Apache Kafka indicando que mudança ocorreu no sistema.

Serviço de leitura dedicado ou processo de sincronização de dados consome eventos publicados no Kafka, processa transformações necessárias correlacionando informações de múltiplas fontes, e atualiza View Tables em banco de dados otimizado para leitura como PostgreSQL com índices específicos para queries ou Elasticsearch para buscas full-text complexas. Aplicações cliente executam queries GET exclusivamente contra este banco de dados de leitura, obtendo dados pré-agregados sem impactar performance de serviços de escrita ou necessitar orquestração distribuída em tempo de requisição.

### Implementação de View Tables

View Tables representam projeções materializadas de dados distribuídos através de múltiplos microsserviços, consolidados em estrutura otimizada para consultas específicas. Considere sistema de e-commerce onde frontend necessita exibir listagem de pedidos incluindo informações de cliente, produtos, nota fiscal e rastreamento de envio:

```typescript
// Tabela desnormalizada otimizada para consulta de pedidos
interface OrdersWithDetailsView {
  order_id: string;
  order_status: 'pending' | 'confirmed' | 'shipped' | 'delivered';
  order_total: number;
  created_at: Date;

  // Dados de cliente replicados
  customer_id: string;
  customer_name: string;
  customer_email: string;

  // Dados de produtos agregados
  products: Array<{
    product_id: string;
    product_name: string;
    quantity: number;
    unit_price: number;
  }>;

  // Dados de nota fiscal
  invoice_id: string | null;
  invoice_url: string | null;
  invoice_issued_at: Date | null;

  // Dados de envio
  shipping_id: string | null;
  shipping_carrier: string | null;
  shipping_tracking_code: string | null;
  shipping_status: string | null;
}
```

Esta estrutura desnormalizada elimina necessidade de frontend executar múltiplas requisições HTTP para Orders Service, Invoices Service e Shipping Service, consolidando toda informação necessária em única query SQL eficiente contra View Table pré-populada.

### Sincronização de View Tables mediante Eventos

Populamento de View Tables ocorre mediante consumo de eventos publicados por serviços de domínio autoritativos. Quando serviço Invoices emite nota fiscal, publica evento InvoiceIssued contendo order_id e invoice_url. Consumidor dedicado processa este evento atualizando registro correspondente em OrdersWithDetailsView:

```typescript
import { Kafka, EachMessagePayload } from 'kafkajs';
import { z } from 'zod';
import { Pool } from 'pg';

const InvoiceIssuedSchema = z.object({
  event_id: z.string().uuid(),
  order_id: z.string().uuid(),
  invoice_id: z.string().uuid(),
  invoice_url: z.string().url(),
  issued_at: z.string().datetime(),
});

type InvoiceIssuedEvent = z.infer<typeof InvoiceIssuedSchema>;

class OrdersViewTableUpdater {
  constructor(
    private readonly kafka: Kafka,
    private readonly pgPool: Pool,
  ) {}

  async start(): Promise<void> {
    const consumer = this.kafka.consumer({
      groupId: 'orders-view-updater'
    });

    await consumer.connect();
    await consumer.subscribe({
      topics: ['invoices.issued', 'shipping.updated'],
      fromBeginning: false,
    });

    await consumer.run({
      eachMessage: async (payload: EachMessagePayload) => {
        await this.handleEvent(payload);
      },
    });
  }

  private async handleEvent(payload: EachMessagePayload): Promise<void> {
    const { topic, message } = payload;

    if (topic === 'invoices.issued') {
      await this.handleInvoiceIssued(message.value!.toString());
    }
  }

  private async handleInvoiceIssued(rawMessage: string): Promise<void> {
    const event = InvoiceIssuedSchema.parse(JSON.parse(rawMessage));

    await this.pgPool.query(
      `UPDATE orders_with_details_view
       SET invoice_id = $1,
           invoice_url = $2,
           invoice_issued_at = $3
       WHERE order_id = $4`,
      [event.invoice_id, event.invoice_url, event.issued_at, event.order_id]
    );

    console.log(`View table atualizada para order ${event.order_id}`);
  }
}
```

Esta abordagem garante que View Tables permanecem sincronizadas com estado autoritativo mantido por serviços de domínio através de consistência eventual, onde latência de sincronização tipicamente permanece inferior a centenas de milissegundos mediante message brokers de alta performance como Kafka.

### Vantagens e Trade-offs de CQRS

CQRS oferece benefícios substanciais incluindo otimização independente de modelos de escrita e leitura onde banco de dados transacional otimiza-se para comandos com constraints e normalizações enquanto banco de dados de leitura desnormaliza-se completamente para performance de queries, escalabilidade independente permitindo provisionamento de réplicas de leitura massivamente paralelas sem impactar capacidade de escrita, e eliminação de complexidade de agregação distribuída transferindo joins para processos assíncronos de sincronização ao invés de latência crítica de requisições de usuário.

Trade-offs incluem consistência eventual onde atualizações em serviços de comando não refletem-se instantaneamente em View Tables introduzindo janela temporal onde usuários podem visualizar dados ligeiramente desatualizados, complexidade operacional de manter infraestrutura adicional incluindo message brokers e processos de sincronização com estratégias de resiliência e monitoramento dedicados, e duplicação de dados através de múltiplos armazenamentos aumentando custos de infraestrutura e superfície de gestão.

## Event Sourcing: Persistência baseada em Eventos Imutáveis

### Fundamentos de Event Sourcing

Event Sourcing inverte modelo tradicional de persistência onde registros em banco de dados são mutados diretamente refletindo estado atual mediante operações UPDATE e DELETE. Ao invés disso, aplicação armazena exclusivamente eventos imutáveis representando fatos históricos sobre mudanças que ocorreram em entidade ao longo do tempo. Estado atual reconstrói-se mediante replay sequencial de todos eventos desde origem da entidade.

Considere exemplo de sistema de gerenciamento de estoque de produtos. Abordagem tradicional manteria tabela `products` com colunas `product_id`, `name` e `stock_amount`, onde operações de adição e remoção de estoque executariam UPDATE modificando valor de `stock_amount`. Event Sourcing substitui esta tabela por `product_stock_events` armazenando exclusivamente eventos:

```typescript
interface ProductStockEvent {
  event_id: string;
  product_id: string;
  event_type: 'stock_increased' | 'stock_decreased';
  amount: number;
  reason: string;
  created_at: Date;
}

// Sequência de eventos para produto ID 1
const events: ProductStockEvent[] = [
  {
    event_id: 'evt_001',
    product_id: 'prod_1',
    event_type: 'stock_increased',
    amount: 100,
    reason: 'Recebimento de fornecedor',
    created_at: new Date('2025-01-15T10:00:00Z'),
  },
  {
    event_id: 'evt_002',
    product_id: 'prod_1',
    event_type: 'stock_decreased',
    amount: 25,
    reason: 'Venda online pedido #12345',
    created_at: new Date('2025-01-16T14:30:00Z'),
  },
  {
    event_id: 'evt_003',
    product_id: 'prod_1',
    event_type: 'stock_increased',
    amount: 50,
    reason: 'Devolução de cliente',
    created_at: new Date('2025-01-17T09:15:00Z'),
  },
];
```

Estado atual de estoque para produto calcula-se mediante agregação de eventos: 100 (increase) - 25 (decrease) + 50 (increase) = 125 unidades. Este cálculo executa-se mediante função de projeção que processa eventos sequencialmente aplicando lógica de acumulação:

```typescript
interface ProductStockState {
  product_id: string;
  current_stock: number;
  last_updated: Date;
}

function projectCurrentStock(events: ProductStockEvent[]): ProductStockState {
  return events.reduce(
    (state, event) => {
      const delta = event.event_type === 'stock_increased'
        ? event.amount
        : -event.amount;

      return {
        product_id: event.product_id,
        current_stock: state.current_stock + delta,
        last_updated: event.created_at,
      };
    },
    { product_id: '', current_stock: 0, last_updated: new Date(0) }
  );
}

const currentState = projectCurrentStock(events);
console.log(currentState);
// { product_id: 'prod_1', current_stock: 125, last_updated: 2025-01-17T09:15:00Z }
```

### Event Store: Armazenamento Especializado para Eventos

Event Store representa banco de dados otimizado especificamente para armazenamento append-only de eventos imutáveis, fornecendo garantias de ordenação, atomicidade e capacidade de consulta eficiente de eventos por agregado. Implementações especializadas incluem EventStoreDB desenvolvido especificamente para Event Sourcing, ou utilização de bancos de dados relacionais como PostgreSQL com schema otimizado:

```sql
CREATE TABLE events (
  event_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  aggregate_type VARCHAR(100) NOT NULL,
  aggregate_id VARCHAR(100) NOT NULL,
  sequence BIGINT NOT NULL,
  event_type VARCHAR(100) NOT NULL,
  event_version VARCHAR(20) NOT NULL DEFAULT 'v1',
  payload JSONB NOT NULL,
  metadata JSONB NOT NULL DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,

  -- Constraint garante que não há duplicação de sequência
  UNIQUE (aggregate_type, aggregate_id, sequence)
);

CREATE INDEX idx_events_aggregate
  ON events (aggregate_type, aggregate_id, sequence);

CREATE INDEX idx_events_created_at
  ON events (created_at DESC);
```

Número de sequência `sequence` garante ordenação determinística de eventos para agregado específico, permitindo carregamento eficiente de histórico completo mediante query simples:

```typescript
import { Pool } from 'pg';

interface StoredEvent {
  event_id: string;
  aggregate_type: string;
  aggregate_id: string;
  sequence: number;
  event_type: string;
  payload: any;
  created_at: Date;
}

class PostgresEventStore {
  constructor(private readonly pool: Pool) {}

  async appendEvent(
    aggregateType: string,
    aggregateId: string,
    eventType: string,
    payload: any,
  ): Promise<void> {
    const client = await this.pool.connect();

    try {
      await client.query('BEGIN');

      // Obter próximo número de sequência
      const { rows } = await client.query(
        `SELECT COALESCE(MAX(sequence), 0) + 1 AS next_sequence
         FROM events
         WHERE aggregate_type = $1 AND aggregate_id = $2`,
        [aggregateType, aggregateId]
      );

      const nextSequence = rows[0].next_sequence;

      // Inserir evento com sequência garantida
      await client.query(
        `INSERT INTO events
         (aggregate_type, aggregate_id, sequence, event_type, payload)
         VALUES ($1, $2, $3, $4, $5)`,
        [aggregateType, aggregateId, nextSequence, eventType, payload]
      );

      await client.query('COMMIT');
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  async loadEvents(
    aggregateType: string,
    aggregateId: string,
  ): Promise<StoredEvent[]> {
    const { rows } = await this.pool.query(
      `SELECT event_id, aggregate_type, aggregate_id, sequence,
              event_type, payload, created_at
       FROM events
       WHERE aggregate_type = $1 AND aggregate_id = $2
       ORDER BY sequence ASC`,
      [aggregateType, aggregateId]
    );

    return rows;
  }
}
```

### Snapshots: Otimização de Performance

Para agregados com histórico extenso contendo milhares de eventos, reconstrução de estado mediante replay completo pode tornar-se computacionalmente custosa. Snapshots representam otimização onde estado completo de agregado é serializado e armazenado periodicamente, permitindo que reconstrução comece a partir de snapshot mais recente aplicando apenas eventos subsequentes:

```typescript
interface Snapshot {
  aggregate_type: string;
  aggregate_id: string;
  sequence: number;
  state: any;
  created_at: Date;
}

class EventStoreWithSnapshots extends PostgresEventStore {
  async saveSnapshot(
    aggregateType: string,
    aggregateId: string,
    sequence: number,
    state: any,
  ): Promise<void> {
    await this.pool.query(
      `INSERT INTO snapshots
       (aggregate_type, aggregate_id, sequence, state)
       VALUES ($1, $2, $3, $4)
       ON CONFLICT (aggregate_type, aggregate_id)
       DO UPDATE SET sequence = $3, state = $4, created_at = CURRENT_TIMESTAMP`,
      [aggregateType, aggregateId, sequence, state]
    );
  }

  async loadAggregate<T>(
    aggregateType: string,
    aggregateId: string,
    applyEvent: (state: T, event: StoredEvent) => T,
    initialState: T,
  ): Promise<T> {
    // Tentar carregar snapshot mais recente
    const { rows: snapshotRows } = await this.pool.query(
      `SELECT sequence, state FROM snapshots
       WHERE aggregate_type = $1 AND aggregate_id = $2`,
      [aggregateType, aggregateId]
    );

    let state = initialState;
    let fromSequence = 0;

    if (snapshotRows.length > 0) {
      state = snapshotRows[0].state as T;
      fromSequence = snapshotRows[0].sequence;
    }

    // Carregar apenas eventos posteriores ao snapshot
    const { rows: eventRows } = await this.pool.query(
      `SELECT * FROM events
       WHERE aggregate_type = $1 AND aggregate_id = $2 AND sequence > $3
       ORDER BY sequence ASC`,
      [aggregateType, aggregateId, fromSequence]
    );

    return eventRows.reduce((acc, event) => applyEvent(acc, event), state);
  }
}
```

Estratégia comum envolve criar snapshot a cada 50 ou 100 eventos, balanceando overhead de armazenamento de snapshots contra benefício de redução de tempo de reconstrução.

### Vantagens de Event Sourcing

Event Sourcing fornece auditoria completa e imutável onde cada mudança em sistema é registrada permanentemente com timestamp e contexto, atendendo requisitos regulatórios de compliance em domínios como financeiro e saúde onde rastreabilidade integral é mandatória. Capacidade de temporal queries permite reconstruir estado de entidade em qualquer ponto histórico mediante replay de eventos até timestamp específico, habilitando análises retroativas e debugging de problemas onde estado corrompido necessita investigação de causa raiz.

Debugging simplifica-se substancialmente através de capacidade de reproduzir exatamente sequência de eventos que levou a estado problemático em ambiente de desenvolvimento, eliminando incerteza típica de sistemas tradicionais onde logs incompletos dificultam reconstrução de cenário de falha. Flexibilidade de projeções permite criar múltiplas representações de dados a partir de mesma fonte autoritativa de eventos, onde novos requisitos de consulta são atendidos mediante criação de novas projeções sem modificar Event Store existente.

### Desafios de Event Sourcing

Complexidade operacional aumenta substancialmente através de necessidade de gerenciar versionamento de esquemas de eventos onde evolução de estrutura de eventos ao longo do tempo exige estratégias de upcasting convertendo eventos antigos para formatos compatíveis com versões atuais de código. Queries complexas tornam-se desafiadoras pois informação não existe em formato tradicional de tabelas relacionais, necessitando construção de projeções dedicadas para cada padrão de consulta requerido.

Overhead de armazenamento cresce continuamente mediante acumulação de eventos históricos, embora estratégias de archiving permitam mover eventos antigos para armazenamento de baixo custo mantendo snapshots e eventos recentes em armazenamento de alta performance. Curva de aprendizado é substancial para equipes habituadas a modelos CRUD tradicionais, exigindo mudança de mentalidade para pensar em termos de eventos e projeções ao invés de entidades e relacionamentos diretos.

## Combinação de CQRS e Event Sourcing

### Sinergia Arquitetural

CQRS e Event Sourcing combinam-se sinergicamente onde Event Store torna-se banco de dados de escrita para lado de comando, armazenando eventos imutáveis representando comandos executados com sucesso, enquanto múltiplas projeções materializadas servem como Read Models otimizados para queries específicas de lado de leitura. Esta arquitetura integrada elimina necessidade de manter estado atual duplicado em lado de escrita, onde Event Store constitui única fonte de verdade e todas View Tables derivam-se mediante processamento de eventos.

Fluxo completo inicia-se com comando CreateOrder submetido a Orders Service que valida regras de negócio consultando sincronamente serviços dependentes para verificação de disponibilidade de estoque e validação de cliente. Comando bem-sucedido resulta em criação de eventos OrderCreated, OrderItemAdded e InventoryReserved que são persistidos atomicamente em Event Store com garantia de ordenação mediante números de sequência incrementais. Publicação de eventos para Kafka permite que múltiplos consumidores incluindo serviço de sincronização de View Tables e serviços de domínio downstream como Invoices processem eventos independentemente aplicando lógica específica de suas projeções.

### Implementação de Agregado com Event Sourcing

Agregados em Domain-Driven Design representam clusters de objetos de domínio tratados como unidade única para propósitos de mudanças de dados, garantindo invariantes de negócio mediante encapsulamento de lógica de validação. Em Event Sourcing, agregados reconstroem-se mediante aplicação sequencial de eventos e produzem novos eventos mediante processamento de comandos:

```typescript
interface BankAccountState {
  account_id: string;
  is_opened: boolean;
  balance: number;
  overdraft_limit: number;
}

type BankAccountEvent =
  | { type: 'AccountOpened'; account_id: string; initial_deposit: number }
  | { type: 'MoneyDeposited'; amount: number }
  | { type: 'MoneyWithdrawn'; amount: number }
  | { type: 'CheckWritten'; check_number: string; amount: number };

type BankAccountCommand =
  | { type: 'OpenAccount'; account_id: string; initial_deposit: number }
  | { type: 'DepositMoney'; amount: number }
  | { type: 'WithdrawMoney'; amount: number }
  | { type: 'WriteCheck'; check_number: string; amount: number };

class BankAccountAggregate {
  private state: BankAccountState = {
    account_id: '',
    is_opened: false,
    balance: 0,
    overdraft_limit: 0,
  };

  // Reconstruir estado mediante aplicação de eventos
  applyEvent(event: BankAccountEvent): void {
    switch (event.type) {
      case 'AccountOpened':
        this.state.account_id = event.account_id;
        this.state.is_opened = true;
        this.state.balance = event.initial_deposit;
        break;

      case 'MoneyDeposited':
        this.state.balance += event.amount;
        break;

      case 'MoneyWithdrawn':
        this.state.balance -= event.amount;
        break;

      case 'CheckWritten':
        this.state.balance -= event.amount;
        break;
    }
  }

  // Processar comando e produzir eventos
  handleCommand(command: BankAccountCommand): BankAccountEvent[] {
    switch (command.type) {
      case 'OpenAccount':
        if (this.state.is_opened) {
          throw new Error('Account already opened');
        }
        return [{
          type: 'AccountOpened',
          account_id: command.account_id,
          initial_deposit: command.initial_deposit,
        }];

      case 'DepositMoney':
        if (!this.state.is_opened) {
          throw new Error('Account not opened');
        }
        return [{ type: 'MoneyDeposited', amount: command.amount }];

      case 'WithdrawMoney':
        if (!this.state.is_opened) {
          throw new Error('Account not opened');
        }
        const availableBalance = this.state.balance + this.state.overdraft_limit;
        if (command.amount > availableBalance) {
          throw new Error('Insufficient funds');
        }
        return [{ type: 'MoneyWithdrawn', amount: command.amount }];

      case 'WriteCheck':
        if (!this.state.is_opened) {
          throw new Error('Account not opened');
        }
        const available = this.state.balance + this.state.overdraft_limit;
        if (command.amount > available) {
          throw new Error('Insufficient funds');
        }
        return [{
          type: 'CheckWritten',
          check_number: command.check_number,
          amount: command.amount,
        }];
    }
  }

  getState(): Readonly<BankAccountState> {
    return Object.freeze({ ...this.state });
  }
}
```

Separação entre `applyEvent` que executa bookkeeping modificando estado sem validações pois eventos representam fatos históricos já ocorridos, e `handleCommand` que aplica regras de negócio validando precondições antes de produzir eventos, constitui padrão fundamental em Event Sourcing garantindo que invariantes sejam validadas apenas durante processamento de comandos enquanto reconstrução mediante eventos permanece sempre bem-sucedida.

### Processamento de Comandos com Persistência de Eventos

Orquestração de ciclo completo de processamento de comando envolve carregar estado atual de agregado mediante replay de eventos, executar comando através de método `handleCommand` que retorna eventos novos, persistir eventos em Event Store com garantia de atomicidade e ordenação, e publicar eventos para message broker permitindo processamento assíncrono por projeções e serviços downstream:

```typescript
class BankAccountCommandHandler {
  constructor(
    private readonly eventStore: EventStoreWithSnapshots,
    private readonly eventPublisher: KafkaProducer,
  ) {}

  async execute(
    accountId: string,
    command: BankAccountCommand,
  ): Promise<void> {
    // 1. Carregar agregado a partir de eventos
    const aggregate = new BankAccountAggregate();

    const events = await this.eventStore.loadEvents('BankAccount', accountId);
    events.forEach(event => {
      aggregate.applyEvent(JSON.parse(event.payload));
    });

    // 2. Processar comando e obter novos eventos
    const newEvents = aggregate.handleCommand(command);

    // 3. Persistir eventos atomicamente
    for (const event of newEvents) {
      await this.eventStore.appendEvent(
        'BankAccount',
        accountId,
        event.type,
        event,
      );
    }

    // 4. Publicar eventos para Kafka
    for (const event of newEvents) {
      await this.eventPublisher.send({
        topic: 'bank-accounts.events',
        messages: [{
          key: accountId,
          value: JSON.stringify({
            event_id: crypto.randomUUID(),
            aggregate_id: accountId,
            event_type: event.type,
            payload: event,
            occurred_at: new Date().toISOString(),
          }),
        }],
      });
    }

    // 5. Criar snapshot periodicamente
    const currentSequence = events.length + newEvents.length;
    if (currentSequence % 50 === 0) {
      await this.eventStore.saveSnapshot(
        'BankAccount',
        accountId,
        currentSequence,
        aggregate.getState(),
      );
    }
  }
}
```

### Projeções para Read Models

Consumidores dedicados subscrevem-se a eventos publicados em Kafka processando-os para atualizar View Tables otimizadas para consultas específicas. Considere projeção que mantém listagem de contas bancárias com saldos atualizados:

```typescript
import { Kafka, EachMessagePayload } from 'kafkajs';
import { Pool } from 'pg';

interface BankAccountSummaryView {
  account_id: string;
  current_balance: number;
  last_transaction_at: Date;
  total_deposits: number;
  total_withdrawals: number;
}

class BankAccountSummaryProjection {
  constructor(
    private readonly kafka: Kafka,
    private readonly pgPool: Pool,
  ) {}

  async start(): Promise<void> {
    const consumer = this.kafka.consumer({
      groupId: 'bank-account-summary-projection'
    });

    await consumer.connect();
    await consumer.subscribe({
      topics: ['bank-accounts.events'],
      fromBeginning: true,
    });

    await consumer.run({
      eachMessage: async (payload: EachMessagePayload) => {
        await this.handleEvent(payload);
      },
    });
  }

  private async handleEvent(payload: EachMessagePayload): Promise<void> {
    const event = JSON.parse(payload.message.value!.toString());

    switch (event.event_type) {
      case 'AccountOpened':
        await this.handleAccountOpened(event);
        break;
      case 'MoneyDeposited':
        await this.handleMoneyDeposited(event);
        break;
      case 'MoneyWithdrawn':
      case 'CheckWritten':
        await this.handleMoneyWithdrawn(event);
        break;
    }
  }

  private async handleAccountOpened(event: any): Promise<void> {
    await this.pgPool.query(
      `INSERT INTO bank_account_summary_view
       (account_id, current_balance, last_transaction_at,
        total_deposits, total_withdrawals)
       VALUES ($1, $2, $3, $4, $5)`,
      [
        event.aggregate_id,
        event.payload.initial_deposit,
        event.occurred_at,
        event.payload.initial_deposit,
        0,
      ]
    );
  }

  private async handleMoneyDeposited(event: any): Promise<void> {
    await this.pgPool.query(
      `UPDATE bank_account_summary_view
       SET current_balance = current_balance + $1,
           total_deposits = total_deposits + $1,
           last_transaction_at = $2
       WHERE account_id = $3`,
      [event.payload.amount, event.occurred_at, event.aggregate_id]
    );
  }

  private async handleMoneyWithdrawn(event: any): Promise<void> {
    await this.pgPool.query(
      `UPDATE bank_account_summary_view
       SET current_balance = current_balance - $1,
           total_withdrawals = total_withdrawals + $1,
           last_transaction_at = $2
       WHERE account_id = $3`,
      [event.payload.amount, event.occurred_at, event.aggregate_id]
    );
  }
}
```

Múltiplas projeções podem ser criadas a partir de mesma fonte de eventos, onde cada uma otimiza-se para padrões específicos de consulta como relatórios gerenciais agregados por período, auditoria detalhada de transações ou dashboards analíticos com métricas pré-computadas.

## Ferramentas e Frameworks Especializados

### EventStoreDB

EventStoreDB representa banco de dados open-source desenvolvido especificamente para Event Sourcing, oferecendo funcionalidades nativas como streams de eventos ordenados garantindo ordenação determinística mediante global position e stream position, projeções JavaScript permitindo construção de Read Models mediante código executado dentro do banco de dados, persistent subscriptions habilitando grupos de consumidores com balanceamento de carga automático, e snapshots integrados para otimização de performance de agregados com histórico extenso.

### Axon Framework

Axon Framework para Java fornece implementação completa de CQRS e Event Sourcing incluindo abstrações de agregados com decoradores para command handlers e event sourcing handlers, Event Bus para roteamento de eventos entre componentes, integração nativa com Axon Server fornecendo Event Store distribuído e message routing, e suporte para Saga Pattern coordenando transações distribuídas de longa duração através de múltiplos agregados.

### Marten para .NET

Marten aproveita capacidades JSONB de PostgreSQL transformando-o em Event Store completo através de document database híbrido permitindo armazenamento de agregados como documentos JSON e Event Sourcing mediante streams de eventos, projeções assíncronas construídas através de código C# executado fora do banco de dados, e integração nativa com frameworks .NET como ASP.NET Core e MediatR para CQRS.

### Eventuous

Eventuous representa biblioteca .NET moderna focada em simplicidade e developer experience, fornecendo abstrações leves para agregados, event stores e projeções, suporte para múltiplos backends incluindo EventStoreDB, PostgreSQL e MongoDB, e integração nativa com OpenTelemetry para observabilidade distribuída rastreando comandos, eventos e projeções através de traces correlacionados.

## Considerações Arquiteturais e Boas Práticas

### Quando Utilizar CQRS e Event Sourcing

CQRS justifica-se em cenários onde requisitos de leitura e escrita diferem substancialmente em complexidade, volume ou performance, exemplificado por sistemas analíticos onde queries agregadas complexas consultadas frequentemente beneficiam-se de projeções pré-computadas enquanto comandos permanecem transações simples. Domínios colaborativos onde múltiplos usuários modificam entidades concorrentemente beneficiam-se de Event Sourcing através de resolução natural de conflitos mediante merge de eventos e detecção de concorrência otimista baseada em versões.

Event Sourcing torna-se essencial em domínios regulados como financeiro, saúde e governamental onde auditoria completa e imutável constitui requisito legal não-negociável, capacidade de reconstrução histórica permite investigações de fraude e compliance, e necessidade de temporal queries habilita análises retroativas como "qual era saldo de conta em 31 de dezembro para declaração de impostos".

### Quando Evitar CQRS e Event Sourcing

Aplicações CRUD simples onde operações de leitura e escrita possuem complexidade equivalente e volumes semelhantes não justificam overhead adicional de CQRS, onde arquitetura tradicional com ORM e banco de dados relacional normalizado fornece simplicidade superior. Equipes pequenas sem experiência em sistemas distribuídos enfrentarão curva de aprendizado substancial e risco de implementação incorreta resultando em complexidade acidental que reduz produtividade ao invés de aumentar.

Requisitos de consistência forte onde usuários necessitam visualizar imediatamente modificações realizadas sem janela de consistência eventual tornam CQRS inadequado, exemplificado por aplicações de reservas onde disponibilidade de assentos ou quartos deve refletir instantaneamente após reserva para evitar double-booking.

### Versionamento de Eventos

Evolução de esquemas de eventos ao longo do tempo constitui desafio operacional fundamental onde eventos históricos armazenados permanentemente podem possuir estruturas incompatíveis com versões atuais de código. Estratégias incluem weak schema onde eventos são tratados como JSON flexível e código de projeção tolera campos ausentes mediante valores default, multiple versions onde agregados suportam múltiplas versões de eventos mediante pattern matching no tipo de evento, e upcasting onde transformações automáticas convertem eventos antigos para formatos atuais durante leitura:

```typescript
interface EventUpcastersRegistry {
  [eventType: string]: Array<(event: any) => any>;
}

const upcasters: EventUpcastersRegistry = {
  'CustomerRegistered': [
    // v1 -> v2: adicionar campo email
    (event) => {
      if (event.version === 'v1') {
        return { ...event, email: 'unknown@example.com', version: 'v2' };
      }
      return event;
    },
  ],
};

function upcastEvent(event: any): any {
  const eventUpcasters = upcasters[event.event_type] || [];
  return eventUpcasters.reduce((evt, upcaster) => upcaster(evt), event);
}
```

### Observabilidade e Debugging

Sistemas baseados em CQRS e Event Sourcing beneficiam-se de observabilidade abrangente através de correlation IDs propagados desde comandos originais através de eventos publicados até atualizações de projeções, permitindo rastreamento end-to-end de fluxos distribuídos. Logs estruturados incluindo metadados de eventos como aggregate_id, event_type, sequence e timestamps facilitam debugging mediante reconstrução de sequências de operações que levaram a estados problemáticos.

Ferramentas de visualização de Event Streams permitem inspecionar graficamente histórico completo de agregados, identificando rapidamente eventos malformados, sequências inesperadas ou violações de invariantes que resultaram em bugs de produção.

## Conclusões

CQRS e Event Sourcing representam padrões arquiteturais sofisticados que resolvem desafios fundamentais de microsserviços relacionados a agregação de dados distribuídos e auditoria de mudanças de estado, porém introduzem complexidade substancial que deve ser cuidadosamente justificada mediante requisitos reais de negócio. CQRS permite otimizações independentes de modelos de escrita e leitura através de bancos de dados heterogêneos especializados e View Tables desnormalizadas pré-computadas, eliminando overhead de agregação distribuída em tempo de requisição ao custo de consistência eventual e infraestrutura adicional.

Event Sourcing fornece auditoria completa e imutável de todas mudanças no sistema através de armazenamento de sequência ordenada de eventos representando fatos históricos, habilitando capacidades avançadas como temporal queries, replay de eventos para debugging e criação de múltiplas projeções otimizadas a partir de única fonte de verdade. Combinação sinérgica de CQRS e Event Sourcing onde Event Store serve como banco de dados de escrita para comandos enquanto projeções derivadas fornecem Read Models otimizados constitui arquitetura poderosa para domínios complexos com requisitos rigorosos de auditoria, escalabilidade independente e flexibilidade de queries.

Adoção bem-sucedida demanda maturidade técnica substancial incluindo compreensão profunda de sistemas distribuídos, experiência com message brokers e processamento assíncrono, estratégias robustas de versionamento de eventos e gestão de esquemas, e cultura de observabilidade abrangente rastreando fluxos end-to-end através de múltiplos componentes distribuídos. Organizações devem avaliar cuidadosamente trade-offs entre benefícios de escalabilidade, auditoria e flexibilidade contra custos de complexidade operacional, curva de aprendizado de equipes e overhead de infraestrutura antes de comprometer-se com estes padrões arquiteturais avançados.

## Referências Bibliográficas

- Fowler, Martin. "CQRS". martinfowler.com, https://martinfowler.com/bliki/CQRS.html. Artigo fundamental definindo padrão CQRS e contextualizando casos de uso apropriados.

- Fowler, Martin. "Event Sourcing". martinfowler.com, https://martinfowler.com/eaaDev/EventSourcing.html. Explicação conceitual de Event Sourcing como padrão de persistência baseado em eventos imutáveis.

- Young, Greg. "CQRS Documents". https://cqrs.files.wordpress.com/2010/11/cqrs_documents.pdf. Documento original do criador do padrão CQRS detalhando fundamentos e implementação.

- Richardson, Chris. "CQRS Pattern". Microservices.io, https://microservices.io/patterns/data/cqrs.html. Contextualização de CQRS especificamente para arquiteturas de microsserviços.

- Richardson, Chris. "Event Sourcing Pattern". Microservices.io, https://microservices.io/patterns/data/event-sourcing.html. Padrão de Event Sourcing aplicado a microsserviços distribuídos.

- Microsoft. "CQRS Pattern". Azure Architecture Center, https://learn.microsoft.com/azure/architecture/patterns/cqrs. Guia arquitetural oficial da Microsoft sobre implementação de CQRS.

- Microsoft. "Event Sourcing Pattern". Azure Architecture Center, https://learn.microsoft.com/azure/architecture/patterns/event-sourcing. Documentação oficial sobre Event Sourcing com exemplos de implementação.

- EventStore. "EventStoreDB Documentation". https://www.eventstore.com/documentation. Documentação oficial do banco de dados especializado em Event Sourcing.

- AxonIQ. "Axon Framework Reference Guide". https://docs.axoniq.io/. Guia completo do framework Java para CQRS e Event Sourcing.

- JetBrains. "Marten Documentation". https://martendb.io/. Documentação da biblioteca .NET para Event Sourcing com PostgreSQL.

- Confluent. "Apache Kafka Documentation". https://kafka.apache.org/documentation/. Documentação oficial do message broker utilizado para comunicação assíncrona entre comando e projeções.

- Confluent. "Schema Registry". https://docs.confluent.io/platform/current/schema-registry/. Ferramenta para versionamento e evolução de esquemas de eventos.

- Microsoft. "CQRS Journey". https://learn.microsoft.com/previous-versions/msp-n-p/jj554200(v=pandp.10). Guia prático completo sobre implementação de CQRS publicado por Microsoft patterns & practices.

- Vernon, Vaughn. "Implementing Domain-Driven Design". Addison-Wesley Professional, 2013. Livro fundamental sobre DDD incluindo capítulos dedicados a CQRS e Event Sourcing.

- Evans, Eric. "Domain-Driven Design". Domain Language, https://www.domainlanguage.com/. Contexto teórico fundamental para compreensão de agregados e bounded contexts essenciais em CQRS.

## Apêndice A: Schema Completo PostgreSQL para Event Store

```sql
-- Tabela de eventos imutáveis
CREATE TABLE events (
  event_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  aggregate_type VARCHAR(100) NOT NULL,
  aggregate_id VARCHAR(100) NOT NULL,
  sequence BIGINT NOT NULL CHECK (sequence >= 0),
  event_type VARCHAR(100) NOT NULL,
  event_version VARCHAR(20) NOT NULL DEFAULT 'v1',
  payload JSONB NOT NULL,
  metadata JSONB NOT NULL DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,

  UNIQUE (aggregate_type, aggregate_id, sequence)
);

-- Índices para performance de queries
CREATE INDEX idx_events_aggregate
  ON events (aggregate_type, aggregate_id, sequence);

CREATE INDEX idx_events_type
  ON events (event_type);

CREATE INDEX idx_events_created_at
  ON events (created_at DESC);

-- Tabela de snapshots para otimização
CREATE TABLE snapshots (
  snapshot_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  aggregate_type VARCHAR(100) NOT NULL,
  aggregate_id VARCHAR(100) NOT NULL,
  sequence BIGINT NOT NULL CHECK (sequence >= 0),
  payload JSONB NOT NULL,
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,

  UNIQUE (aggregate_type, aggregate_id)
);

-- Tabela de eventos processados para idempotência
CREATE TABLE processed_events (
  event_id UUID PRIMARY KEY,
  projection_name VARCHAR(100) NOT NULL,
  processed_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,

  UNIQUE (event_id, projection_name)
);

CREATE INDEX idx_processed_events_projection
  ON processed_events (projection_name, processed_at DESC);
```

## Apêndice B: Glossário e Termos Técnicos

**Aggregate (Agregado)**: Cluster de objetos de domínio tratados como unidade única para propósitos de mudanças de dados, garantindo invariantes de negócio mediante encapsulamento de lógica de validação conforme Domain-Driven Design.

**Command (Comando)**: Intenção de modificar estado do sistema representando operação de escrita que pode ser aceita ou rejeitada mediante validação de regras de negócio, mapeando tipicamente para operações HTTP POST, PUT, PATCH e DELETE.

**Command Handler**: Componente responsável por processar comandos recebidos, carregar agregados relevantes, executar lógica de negócio e persistir eventos resultantes em Event Store.

**Consistency Eventual (Consistência Eventual)**: Modelo de consistência em sistemas distribuídos onde atualizações propagam-se assincronamente através de componentes, garantindo que todos nós convergirão para mesmo estado após período finito sem novas atualizações.

**CQRS (Command Query Responsibility Segregation)**: Padrão arquitetural estabelecendo separação explícita entre operações de escrita mediante comandos e operações de leitura através de queries, permitindo otimizações independentes mediante modelos de dados heterogêneos.

**Event (Evento)**: Fato imutável representando mudança que ocorreu em sistema em ponto específico no tempo, armazenado permanentemente em Event Store e utilizado para reconstruir estado de agregados e atualizar projeções.

**Event Sourcing**: Padrão de persistência onde estado de aplicação é armazenado como sequência de eventos imutáveis ao invés de sobrescrever registros, habilitando auditoria completa, temporal queries e replay de eventos.

**Event Store**: Banco de dados otimizado para armazenamento append-only de eventos imutáveis, fornecendo garantias de ordenação, atomicidade e capacidade de consulta eficiente de eventos por agregado.

**Projection (Projeção)**: Processo de transformar sequência de eventos em representação otimizada para consultas específicas, resultando em View Table ou Read Model desnormalizado pré-computado.

**Query (Consulta)**: Operação de leitura que retorna dados sem produzir efeitos colaterais, executada exclusivamente contra Read Models otimizados sem modificar estado de agregados.

**Read Model**: Representação de dados otimizada especificamente para consultas, populada assincronamente mediante processamento de eventos e estruturada conforme necessidades de aplicações cliente.

**Snapshot**: Serialização de estado completo de agregado armazenada periodicamente para otimizar performance de reconstrução, permitindo que replay comece a partir de snapshot mais recente aplicando apenas eventos subsequentes.

**Upcasting**: Processo de transformar eventos antigos com esquemas desatualizados para formatos compatíveis com versões atuais de código mediante conversões automáticas durante leitura de Event Store.

**View Table**: Tabela desnormalizada em banco de dados de leitura contendo dados pré-agregados e otimizados para padrões específicos de consulta, populada automaticamente mediante consumo de eventos publicados por serviços de domínio.

**Write Model**: Modelo de dados otimizado para operações de escrita incluindo validações de regras de negócio, constraints de integridade e garantias ACID, tipicamente implementado através de Event Store em sistemas baseados em Event Sourcing.
