<!-- markdownlint-disable -->

# Fundamento API Gateway em Microsserviços

## Resumo Executivo

API Gateway constitui componente arquitetural fundamental em sistemas de microsserviços, estabelecendo ponto de entrada único e centralizado que medeia comunicação entre clientes front-end e múltiplos serviços backend distribuídos. Em arquiteturas monolíticas, cliente interage diretamente com aplicação única através de endpoint bem definido, enquanto transição para microsserviços fragmenta sistema em dezenas ou centenas de serviços independentes operando em hosts e portas distintas, criando complexidade insustentável onde front-end necessitaria gerenciar configuração de URLs, descoberta de serviços e comunicação individualizada com cada microsserviço. API Gateway soluciona este desafio implementando padrão proxy reverso que recebe requisições de clientes, executa roteamento inteligente baseado em padrões de URL ou headers, e encaminha requisições aos serviços apropriados, retornando respostas agregadas ao cliente. Além de simplificar comunicação cliente-servidor, API Gateway concentra responsabilidades transversais como autenticação e validação de tokens JWT, rate limiting para proteção contra abuso, transformação de protocolos, agregação de respostas de múltiplos serviços, observabilidade através de logging centralizado, e aplicação de políticas de segurança uniformes. Este documento explora fundamentos teóricos do padrão API Gateway, motivações arquiteturais, funcionalidades essenciais, implementação prática utilizando Kong Gateway, configuração declarativa via YAML, integração com autenticação JWT através de plugins, estratégias de roteamento e load balancing, e trade-offs de performance e complexidade operacional.

## Introdução e Conceitos

### Desafio da Comunicação Distribuída

Arquitetura de microsserviços fundamenta-se em decomposição de sistema monolítico em serviços independentes especializados em domínios de negócio específicos, cada qual operando em processo isolado com infraestrutura dedicada e banco de dados próprio. Enquanto esta separação oferece benefícios substanciais de escalabilidade, desenvolvimento paralelo e autonomia tecnológica, introduz complexidade significativa na comunicação externa. Considere sistema de encurtamento de URLs composto por três microsserviços: Auth Service responsável por autenticação operando em localhost:3000, Shortener Service gerenciando criação de URLs curtas em localhost:4000, e Analytics Service processando métricas de acessos em localhost:3001. Cliente front-end necessitando interagir com todos três serviços enfrentaria obrigação de manter configuração de três URLs distintas em arquivo de ambiente, implementar lógica de descoberta de serviços caso hosts ou portas alterem-se dinamicamente, e gerenciar tratamento de erros individualizado para cada endpoint.

Complexidade amplifica-se exponencialmente conforme sistema evolui incorporando dezenas de microsserviços adicionais: serviço de notificações, gerenciamento de usuários, billing, reporting, integrações externas. Manutenção de dezenas de URLs em configuração de front-end torna-se insustentável, versionamento de APIs entre serviços distintos cria incompatibilidades, e alterações em topologia de rede exigem redesploy coordenado de todos clientes. Adicionalmente, requisições que demandam dados de múltiplos serviços geram latência acumulada através de múltiplos roundtrips HTTP sequenciais, degradando experiência de usuário em redes de alta latência como conexões móveis.

### API Gateway como Ponto de Entrada Único

Padrão API Gateway resolve fundamentalmente estes desafios inserindo componente intermediário dedicado entre clientes e microsserviços, operando como proxy reverso inteligente que expõe interface unificada independente de topologia interna. Cliente front-end comunica-se exclusivamente com API Gateway através de endpoint único como api.exemplo.com ou localhost:80 em desenvolvimento, desconhecendo completamente existência, localização e quantidade de microsserviços backend. API Gateway assume responsabilidade de rotear requisições entrantes aos serviços apropriados baseando-se em padrões de URL, headers HTTP, métodos ou parâmetros de query, encaminhando requisição para /api/shortener/* ao Shortener Service, /api/analytics/* ao Analytics Service, e /auth/* ao Auth Service. Abstração permite reorganização completa de infraestrutura backend sem impactar clientes, facilitando migração de serviços entre hosts, alteração de portas, introdução de novos microsserviços e decomposição de serviços existentes.

### Funcionalidades Transversais Centralizadas

Além de roteamento fundamental, API Gateway concentra implementação de preocupações transversais que atravessam múltiplos microsserviços, evitando duplicação de lógica complexa em cada serviço individual. Autenticação e autorização constituem funcionalidade crítica frequentemente centralizada no gateway: ao invés de cada microsserviço validar independentemente tokens JWT consultando JWKS endpoint e verificando assinaturas, API Gateway intercepta requisições entrantes, extrai token do header Authorization, valida autenticidade e expiração, e injeta claims decodificados como headers customizados que serviços downstream consomem confiantemente sem revalidação. Implementação demonstrativa utiliza header X-User-ID contendo identificador extraído de payload JWT, permitindo que serviços de domínio acessem identidade de usuário autenticado sem dependências em bibliotecas criptográficas ou configuração de chaves públicas.

Rate limiting implementado no API Gateway protege sistema inteiro contra abuso e ataques de negação de serviço através de políticas centralizadas que limitam número de requisições permitidas por cliente baseando-se em endereço IP, identificador de usuário autenticado ou chave API. Configuração típica permite 60 requisições por minuto por usuário independente de serviços alvos requisitados, retornando HTTP 429 Too Many Requests quando limite é excedido, evitando necessidade de implementar throttling individualizado em cada microsserviço. Transformação de protocolos permite que API Gateway exponha interface REST JSON amigável a clientes web enquanto comunica-se com serviços backend utilizando gRPC binário para performance superior, ou traduz requisições GraphQL em múltiplas chamadas REST coordenadas.

Agregação de respostas unifica dados de múltiplos microsserviços em resposta única, reduzindo latência de rede e simplificando lógica de cliente. Requisição GET /api/dashboard pode ser processada pelo API Gateway consultando concorrentemente serviços de Orders, Inventory e Analytics, aguardando conclusão de todas requisições paralelas, agregando respostas em documento JSON unificado retornado ao cliente em roundtrip único. Observabilidade centralizada através de logging estruturado, correlação de requisições via Correlation IDs propagados através de headers, e integração com plataformas de APM como Datadog ou New Relic oferece visibilidade holística de tráfego atravessando sistema distribuído.

## Padrão API Gateway: Motivações e Trade-offs

### Vantagens Arquiteturais

Isolamento de clientes de particionamento interno representa benefício fundamental do padrão, onde aplicação cliente permanece agnóstica quanto a decomposição de funcionalidades em microsserviços específicos. Decisões arquiteturais de decompor serviço monolítico em microsserviços menores, mesclar microsserviços relacionados ou extrair funcionalidade compartilhada em serviço dedicado ocorrem transparentemente sem impactar contratos de API pública expostos através do gateway. Otimização de APIs para diferentes tipos de clientes habilita customização de interfaces: aplicação mobile com limitações de largura de banda recebe respostas compactas omitindo metadados desnecessários, aplicação web desktop obtém payloads completos com dados adicionais, e integrações third-party acessam subconjunto restrito de endpoints com rate limiting agressivo.

Redução de overhead de rede constitui vantagem mensurável em latências de conexão elevadas, onde agregação de múltiplas requisições em chamada única ao gateway elimina penalidades de estabelecimento de conexão TCP, handshake TLS e processamento de headers HTTP repetidos. Cliente requisitando dados de cinco microsserviços distintos tradicionalmente incorreria em cinco roundtrips completos acumulando centenas de milissegundos em redes de alta latência, enquanto agregação no gateway reduz operação a roundtrip único entre cliente e gateway, com requisições paralelas internas entre gateway e microsserviços ocorrendo em rede de baixa latência de datacenter. Simplificação de lógica de cliente transfere responsabilidade de orquestração complexa de múltiplos serviços, tratamento de falhas parciais e retentativas para gateway, permitindo que desenvolvedores de aplicações front-end concentrem-se em experiência de usuário ao invés de resiliência distribuída.

### Desvantagens e Considerações

Complexidade adicional introduzida por componente intermediário representa principal trade-off do padrão, exigindo desenvolvimento, deployment, configuração e manutenção de sistema adicional com suas próprias dependências, estratégias de escalonamento e pontos de falha. API Gateway torna-se componente crítico cuja indisponibilidade compromete sistema inteiro mesmo quando microsserviços backend permanecem operacionais, demandando arquitetura de alta disponibilidade com redundância, health checks, failover automático e disaster recovery. Overhead de performance introduz latência adicional através de hop de rede extra, deserialização de requisições, execução de lógica de roteamento, validação de autenticação e serialização de respostas, embora impacto tipicamente permaneça inferior a 10 milissegundos sendo negligível para maioria de aplicações.

Risco de API Gateway tornar-se monolito distribuído emerge quando responsabilidades excessivas concentram-se no gateway, incluindo lógica de negócio específica de domínios, transformações complexas de dados ou agregações envolvendo decisões de negócio. Gateway deve restringir-se a preocupações transversais genéricas como roteamento, autenticação, rate limiting e logging, delegando lógica de domínio aos microsserviços apropriados. Acoplamento através de contratos de API compartilhados exige coordenação cuidadosa durante evolução de interfaces, onde alterações breaking em serviços backend necessitam versionamento explícito e período de suporte simultâneo de múltiplas versões para evitar quebra de clientes existentes.

Necessidade de abordagem reativa e assíncrona torna-se crítica em cenários de alta carga onde gateway processa milhares de requisições concorrentes. Implementações baseadas em modelos síncronos tradicionais de thread-per-request esgotam rapidamente pool de threads sob carga elevada, enquanto frameworks reativos utilizando event loops não-bloqueantes como Node.js, Netty para JVM ou frameworks baseados em Reactor permitem processamento eficiente de dezenas de milhares de conexões concorrentes com footprint de recursos reduzido.

## Implementação de API Gateway

### Soluções Disponíveis no Mercado

Ecossistema oferece diversidade de implementações de API Gateway cobrindo espectro de open-source a soluções empresariais gerenciadas. Kong Gateway destaca-se como solução open-source madura construída sobre Nginx oferecendo performance excepcional através de engine Lua, arquitetura de plugins extensível para funcionalidades customizadas, suporte nativo a autenticação JWT e OAuth 2.0, rate limiting configurável, e deployment em modos tradicionais com banco de dados PostgreSQL ou DB-less através de configuração declarativa YAML. Apache APISIX emerge como alternativa cloud-native moderna construída em OpenResty enfatizando performance, configuração dinâmica através de etcd, e integração nativa com ecossistema Kubernetes.

Traefik posiciona-se como proxy reverso moderno e API Gateway projetado especificamente para ambientes containerizados, oferecendo descoberta automática de serviços através de integração com Docker, Kubernetes e Consul, configuração através de labels em containers, suporte nativo a HTTP/2 e gRPC, e provisionamento automático de certificados TLS via Let's Encrypt. Envoy Proxy, utilizado como data plane por service meshes como Istio e frameworks de API Gateway como Ambassador, fornece proxy L7 de alta performance com configuração dinâmica, observabilidade profunda através de métricas detalhadas, circuit breaking, retries e health checking avançado.

Soluções cloud-native gerenciadas incluem AWS API Gateway oferecendo escalabilidade automática, integração nativa com Lambda para serverless backends e AWS Cognito para autenticação, Azure API Management fornecendo portal de desenvolvedores, políticas de transformação declarativas e monetização de APIs, e Google Cloud API Gateway integrando-se com Google Cloud Endpoints e suporte nativo a OpenAPI specifications. Frameworks integrados a ecossistemas específicos como Spring Cloud Gateway para aplicações Spring Boot, Ocelot para .NET e Express Gateway para Node.js oferecem integração profunda com stack tecnológico escolhido.

### Kong Gateway: Arquitetura e Deployment

Kong Gateway implementa arquitetura modular baseada em plugins onde núcleo fornece funcionalidades fundamentais de proxy reverso e roteamento, enquanto plugins adicionam capacidades como autenticação, rate limiting, transformações, logging e CORS. Deployment tradicional utiliza banco de dados PostgreSQL ou Cassandra para armazenar configuração de serviços, rotas, plugins e consumidores, permitindo configuração dinâmica através de Admin API REST exposta tipicamente em porta 8001. Modo DB-less introduzido em versões recentes elimina dependência de banco de dados operando exclusivamente com configuração declarativa em arquivos YAML ou JSON carregados na inicialização, simplificando deployment em ambientes containerizados e alinhando-se com práticas de GitOps onde configuração é versionada em repositórios Git.

Componentes fundamentais de Kong incluem Services representando upstream APIs backend como serviço de Shortener ou Analytics, Routes definindo padrões de URL que mapeiam requisições entrantes a Services específicos como /api/shortener/* roteando para Shortener Service, Plugins configurando funcionalidades adicionais aplicadas globalmente, por serviço ou por rota, Consumers representando clientes autenticados da API com credenciais associadas, e Upstreams implementando load balancing e health checking para distribuir tráfego entre múltiplas instâncias de serviço backend. Admin API expõe endpoints RESTful para gerenciamento programático de configuração, permitindo automação de provisionamento através de ferramentas de Infrastructure as Code como Terraform utilizando provider oficial Kong.

### Configuração Declarativa com Kong

Configuração declarativa expressa topologia completa de API Gateway em arquivo YAML estruturado carregado durante inicialização, facilitando versionamento, revisões e deployment reproduzível. Estrutura demonstrativa para sistema de encurtamento de URLs:

```yaml
_format_version: "3.0"

services:
  - name: auth-service
    url: http://auth:3000
    protocol: http
    retries: 3
    connect_timeout: 5000
    write_timeout: 5000
    read_timeout: 5000

    routes:
      - name: auth-routes
        paths:
          - /auth
        strip_path: false
        preserve_host: false
        protocols:
          - http
          - https
        methods:
          - GET
          - POST

  - name: shortener-service
    url: http://shortener:4000
    protocol: http
    retries: 3

    routes:
      - name: shortener-routes
        paths:
          - /api/shortener
        strip_path: true
        protocols:
          - http
          - https

    plugins:
      - name: jwt
        config:
          uri_param_names:
            - jwt
          claims_to_verify:
            - exp
          key_claim_name: iss
          header_names:
            - authorization

      - name: request-transformer
        config:
          add:
            headers:
              - "X-User-ID:$(X-Consumer-Custom-ID)"

  - name: analytics-service
    url: http://analytics:3001
    protocol: http

    routes:
      - name: analytics-routes
        paths:
          - /api/analytics
        strip_path: true

    plugins:
      - name: jwt
        config:
          claims_to_verify:
            - exp
          key_claim_name: iss

      - name: request-transformer
        config:
          add:
            headers:
              - "X-User-ID:$(X-Consumer-Custom-ID)"

consumers:
  - username: auth-service-consumer
    custom_id: auth-service
    jwt_secrets:
      - key: auth-service
        algorithm: RS256
        rsa_public_key: |
          -----BEGIN PUBLIC KEY-----
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA...
          -----END PUBLIC KEY-----

plugins:
  - name: rate-limiting
    config:
      minute: 60
      policy: local
      limit_by: consumer
      fault_tolerant: true

  - name: correlation-id
    config:
      header_name: X-Correlation-ID
      generator: uuid
      echo_downstream: true

  - name: prometheus
    config:
      per_consumer: true
```

Atributo _format_version especifica versão de schema de configuração garantindo compatibilidade com versão de Kong deployment. Seção services declara microsserviços backend onde url aponta para endpoint interno acessível por Kong, protocol especifica HTTP ou HTTPS, e timeouts definem limites para estabelecimento de conexão, escrita de requisição e leitura de resposta. Routes associadas a cada serviço definem padrões de matching onde paths especifica prefixos de URL, strip_path controla se prefixo deve ser removido antes de encaminhar a upstream, preserve_host determina se header Host original deve ser mantido, e methods restringe matching a verbos HTTP específicos.

### Autenticação JWT via Plugin

Plugin JWT de Kong valida tokens JWT em requisições entrantes, extraindo claims e disponibilizando-os para plugins downstream e serviços backend. Configuração demonstrativa integra-se com Auth Service que emite tokens assinados com chave privada RSA:

```yaml
plugins:
  - name: jwt
    config:
      uri_param_names:
        - jwt
      claims_to_verify:
        - exp
        - nbf
      key_claim_name: iss
      header_names:
        - authorization
      cookie_names: []
      secret_is_base64: false
      run_on_preflight: false
```

Parâmetro uri_param_names permite passar JWT como query parameter além de header, útil para WebSockets onde headers customizados são restritos. claims_to_verify especifica claims JWT que devem ser validados automaticamente: exp garante que token não expirou, nbf valida que token já está ativo, e aud/iss podem ser verificados contra valores esperados. key_claim_name identifica claim contendo referência a consumidor Kong que possui chave pública ou secret para validação, tipicamente iss para issuer. header_names define headers HTTP onde token pode estar presente, defaultando para Authorization com esquema Bearer.

Consumers em Kong representam clientes autenticados possuidores de credenciais, associando chaves públicas RSA para validação de tokens:

```yaml
consumers:
  - username: auth-service-consumer
    custom_id: auth-service
    jwt_secrets:
      - key: auth-service
        algorithm: RS256
        rsa_public_key: |
          -----BEGIN PUBLIC KEY-----
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxGOr...
          -----END PUBLIC KEY-----
```

Campo key corresponde ao valor de claim especificado em key_claim_name no payload JWT, tipicamente iss. algorithm declara algoritmo de assinatura esperado como RS256, RS384 ou RS512 para chaves assimétricas, ou HS256 para simétricas. rsa_public_key contém chave pública em formato PEM utilizada para validar assinatura de tokens, obtida do JWKS endpoint do Auth Service ou gerada junto com par de chaves privadas. Após validação bem-sucedida, Kong injeta headers customizados contendo informações extraídas como X-Consumer-Username, X-Consumer-ID e X-Consumer-Custom-ID acessíveis por serviços downstream.

### Request Transformer: Injeção de Headers

Plugin Request Transformer modifica requisições antes de encaminhá-las a serviços upstream, adicionando, removendo ou substituindo headers, query parameters ou body fields. Caso de uso comum injeta identificador de usuário autenticado em header customizado para consumo por serviços backend:

```yaml
plugins:
  - name: request-transformer
    config:
      add:
        headers:
          - "X-User-ID:$(X-Consumer-Custom-ID)"
          - "X-Authenticated-At:$(date +%s)"
      remove:
        headers:
          - Authorization
      replace:
        headers:
          - "Host:upstream-service.internal"
```

Seção add injeta novos headers onde valores podem referenciar variáveis de ambiente Kong utilizando sintaxe $(VARIABLE). Variável X-Consumer-Custom-ID populada por plugin JWT contém custom_id do consumidor validado, extraído de claim userId ou similar no payload JWT. Remover header Authorization via remove previne vazamento de token JWT sensível para serviços upstream que não necessitam validá-lo novamente. Substituição de Host permite rotear requisições baseando-se em nomes de serviço internos independente de valor original enviado por cliente.

Serviços backend acessam identidade de usuário autenticado através de header injetado sem dependências em bibliotecas JWT:

```typescript
import express from 'express';

const app = express();

app.post('/shorten', (req, res) => {
  const userId = req.headers['x-user-id'];

  if (!userId) {
    return res.status(401).json({ error: 'Authentication required' });
  }

  console.log(`User ${userId} creating short URL`);

  // Lógica de negócio confiando que userId foi validado pelo API Gateway

  res.json({
    shortUrl: 'https://short.url/abc123',
    createdBy: userId
  });
});

app.listen(4000, () => {
  console.log('Shortener Service running on port 4000');
});
```

Abordagem elimina duplicação de lógica de validação JWT em cada microsserviço, centraliza gestão de chaves públicas exclusivamente no API Gateway, e permite evolução de mecanismo de autenticação sem alterações em serviços de domínio.

## Rate Limiting e Proteção contra Abuso

### Estratégias de Throttling

Rate limiting protege sistema contra sobrecarga acidental ou maliciosa limitando número de requisições permitidas por cliente em janela temporal. Plugin rate-limiting de Kong suporta múltiplas políticas de armazenamento e estratégias de identificação:

```yaml
plugins:
  - name: rate-limiting
    config:
      second: 10
      minute: 60
      hour: 1000
      day: 10000
      policy: redis
      redis_host: redis.internal
      redis_port: 6379
      redis_database: 0
      limit_by: consumer
      fault_tolerant: true
      hide_client_headers: false
```

Limites especificam número máximo de requisições permitidas em diferentes janelas temporais: second limita burst súbito, minute protege contra scripts automatizados, hour e day estabelecem cotas diárias. policy determina backend de armazenamento de contadores: local armazena em memória de processo Kong adequado para deployment single-instance, cluster sincroniza entre nós Kong via comunicação interna, redis ou redis-cluster centraliza contadores em instância Redis compartilhada permitindo rate limiting consistente através de múltiplas instâncias Kong horizontalmente escaladas.

Parâmetro limit_by define estratégia de identificação de cliente: consumer aplica limite baseando-se em consumidor autenticado identificado por plugin JWT, credential limita por chave API específica, ip utiliza endereço IP de origem adequado para endpoints públicos não autenticados, service restringe número total de requisições a serviço independente de cliente, e header permite limitar baseando-se em valor de header customizado como X-Tenant-ID para multi-tenancy. fault_tolerant garante que falha em acessar backend de armazenamento permite requisições prosseguirem ao invés de bloquear tráfego, priorizando disponibilidade sobre enforcement rigoroso.

Headers de resposta comunicam informações de rate limit a clientes: X-RateLimit-Limit-Minute indica limite configurado, X-RateLimit-Remaining-Minute mostra requisições restantes antes de throttling, e RateLimit-Reset timestamp Unix quando contadores serão resetados. Quando limite é excedido, Kong retorna HTTP 429 Too Many Requests com header Retry-After indicando segundos até permitir nova tentativa:

```http
HTTP/1.1 429 Too Many Requests
X-RateLimit-Limit-Minute: 60
X-RateLimit-Remaining-Minute: 0
RateLimit-Reset: 1704070860
Retry-After: 45
Content-Type: application/json

{
  "message": "API rate limit exceeded"
}
```

### Estratégias Avançadas: Leaky Bucket e Token Bucket

Algoritmos sofisticados de rate limiting oferecem controle mais granular sobre padrões de tráfego. Token Bucket permite bursts controlados onde tokens acumulam-se em bucket a taxa constante até capacidade máxima, e cada requisição consome token. Cliente pode consumir todos tokens acumulados em burst súbito mas subsequentemente limitado a taxa de reposição. Leaky Bucket processa requisições a taxa constante independente de burst, enfileirando requisições excedentes até capacidade de fila atingir limite onde requisições adicionais são descartadas. Implementações avançadas combinam múltiplas janelas temporais com pesos distintos, aplicam rate limiting diferenciado baseando-se em endpoints ou métodos HTTP, e integram-se com sistemas de detecção de anomalias para bloqueio adaptativo de clientes maliciosos.

## Agregação de Respostas e Backend for Frontend

### Composição de Múltiplos Serviços

Requisições de cliente frequentemente demandam dados de múltiplos microsserviços que API Gateway pode agregar em resposta unificada. Considere dashboard exibindo estatísticas de usuário requerendo dados de Orders Service, Analytics Service e User Profile Service. Abordagem tradicional exige três requisições sequenciais do front-end acumulando latência, ou implementação de endpoint dedicado em backend agregando dados. API Gateway pode implementar composição através de plugin customizado ou configuração de proxy agregador:

```typescript
// Plugin customizado Kong para agregação
const kong = require('kong-pdk');

function aggregate_dashboard(config) {
  return {
    access: async (self) => {
      const userId = kong.request.get_header('X-User-ID');

      // Requisições paralelas a múltiplos serviços
      const [orders, analytics, profile] = await Promise.all([
        fetch(`http://orders:5000/api/users/${userId}/orders`),
        fetch(`http://analytics:3001/api/users/${userId}/stats`),
        fetch(`http://profile:6000/api/users/${userId}`)
      ]);

      const aggregated = {
        user: await profile.json(),
        recentOrders: await orders.json(),
        statistics: await analytics.json()
      };

      kong.response.exit(200, aggregated, {
        'Content-Type': 'application/json'
      });
    }
  };
}

module.exports = {
  Plugin: aggregate_dashboard,
  Schema: [
    { consumer: { type: 'foreign', reference: 'consumers' } }
  ],
  Priority: 1000
};
```

Abordagem reduz três roundtrips cliente-servidor a único roundtrip, executa requisições internas paralelamente reduzindo latência total ao máximo da requisição mais lenta ao invés de soma de todas, e centraliza lógica de agregação eliminando duplicação em múltiplos clientes.

### Padrão Backend for Frontend

Backend for Frontend estende conceito de agregação criando API Gateways especializados para diferentes tipos de clientes. Mobile BFF expõe endpoints otimizados para limitações de largura de banda de redes móveis retornando payloads compactos, implementa paginação agressiva, e fornece versionamento explícito para suportar múltiplas versões de aplicativo mobile simultaneamente. Web BFF oferece payloads completos com metadados adicionais, suporta requisições complexas de filtros e ordenação, e implementa GraphQL permitindo que cliente especifique precisamente campos desejados. Third-party API BFF restringe acesso a subconjunto de funcionalidades, implementa rate limiting rigoroso, exige autenticação via OAuth 2.0 client credentials, e fornece documentação OpenAPI para integração externa.

## Observabilidade e Monitoramento

### Logging Estruturado e Correlation IDs

Rastreamento de requisições através de sistema distribuído exige propagação de identificador único correlacionando eventos de log dispersos. Plugin correlation-id de Kong gera ou propaga UUID através de header customizado:

```yaml
plugins:
  - name: correlation-id
    config:
      header_name: X-Correlation-ID
      generator: uuid
      echo_downstream: true
```

Parâmetro generator especifica estratégia de geração: uuid gera UUID v4 aleatório, uuid-counter combina timestamp com contador incremental, tracker utiliza esquema customizado. echo_downstream garante que Correlation ID seja incluído em resposta ao cliente permitindo rastreamento end-to-end. Serviços downstream extraem Correlation ID de header e incluem em todos logs:

```typescript
app.use((req, res, next) => {
  const correlationId = req.headers['x-correlation-id'];
  req.correlationId = correlationId;

  // Injetar em contexto de logging
  logger.setContext({ correlationId });

  logger.info('Request received', {
    method: req.method,
    path: req.path,
    userId: req.headers['x-user-id']
  });

  next();
});
```

Agregação de logs em plataforma centralizada como Elasticsearch permite queries correlacionando todos eventos de requisição única através de múltiplos serviços, facilitando debugging de falhas distribuídas e análise de latência por componente.

### Métricas e Prometheus

Plugin prometheus de Kong expõe métricas detalhadas de tráfego, latência e erros em formato compatível com Prometheus:

```yaml
plugins:
  - name: prometheus
    config:
      per_consumer: true
      status_code_metrics: true
      latency_metrics: true
      bandwidth_metrics: true
      upstream_health_metrics: true
```

Métricas expostas incluem kong_http_requests_total contabilizando requisições totais por serviço, rota, método e código de status, kong_latency_ms_bucket fornecendo histogramas de latência em percentis p50, p95 e p99, kong_bandwidth_bytes medindo bytes transferidos upstream e downstream, e kong_upstream_target_health indicando status de health checks de serviços backend. Configuração per_consumer adiciona dimensão de consumidor permitindo análise de padrões de uso por cliente autenticado.

Prometheus raspa endpoint /metrics exposto por Kong em porta administrativa, armazenando séries temporais consultáveis via PromQL para dashboards Grafana e alertas via Alertmanager:

```promql
# Taxa de requisições por segundo
rate(kong_http_requests_total[5m])

# Latência p95 por serviço
histogram_quantile(0.95, rate(kong_latency_ms_bucket[5m]))

# Taxa de erros 5xx
rate(kong_http_requests_total{code=~"5.."}[5m]) /
rate(kong_http_requests_total[5m])
```

## Load Balancing e Health Checking

### Upstreams e Targets

Kong abstrai conceito de upstream representando grupo de instâncias de serviço backend entre quais tráfego é distribuído. Configuração declarativa define upstream com múltiplos targets:

```yaml
upstreams:
  - name: shortener-cluster
    algorithm: consistent-hashing
    hash_on: consumer
    hash_fallback: ip
    slots: 10000
    healthchecks:
      active:
        type: http
        http_path: /health
        timeout: 3
        concurrency: 10
        healthy:
          interval: 5
          http_statuses: [200, 302]
          successes: 2
        unhealthy:
          interval: 5
          http_statuses: [429, 500, 503]
          tcp_failures: 3
          http_failures: 3
          timeouts: 3
      passive:
        healthy:
          http_statuses: [200, 201, 202, 204, 301, 302]
          successes: 5
        unhealthy:
          http_statuses: [429, 500, 503]
          tcp_failures: 2
          http_failures: 5
          timeouts: 2
    targets:
      - target: shortener-1.internal:4000
        weight: 100
      - target: shortener-2.internal:4000
        weight: 100
      - target: shortener-3.internal:4000
        weight: 50
```

Algoritmo de load balancing determina distribuição de requisições: round-robin alterna sequencialmente entre targets, least-connections encaminha para instância com menor número de conexões ativas, consistent-hashing mapeia requisições a targets baseando-se em hash de atributo como consumer ou header garantindo que requisições de mesmo cliente direcionem-se consistentemente a mesma instância backend. Parâmetro slots define granularidade de distribuição de peso onde targets com weight maior recebem proporção superior de tráfego.

### Health Checking Ativo e Passivo

Health checking ativo executa sondagens periódicas a endpoints de saúde de targets determinando disponibilidade. Configuração especifica http_path para endpoint de health check tipicamente /health ou /healthz, timeout para resposta, e concurrency limitando sondagens simultâneas. Target considera-se healthy após successes verificações bem-sucedidas consecutivas retornando códigos de status em http_statuses como 200, e unhealthy após http_failures falhas, tcp_failures falhas de conexão TCP ou timeouts expirações.

Health checking passivo monitora tráfego de produção inferindo saúde baseando-se em taxa de erros. Target marcado como unhealthy após http_failures respostas 5xx consecutivas ou timeouts, e recupera status healthy após successes respostas bem-sucedidas. Combinação de health checking ativo e passivo garante remoção rápida de instâncias falhas de pool de load balancing minimizando impacto a usuários, enquanto permite recuperação automática quando instâncias restauram operação.

## Service Mesh versus API Gateway

### Diferenciação de Responsabilidades

Service Mesh como Istio ou Linkerd gerencia comunicação service-to-service interna implementando proxy sidecar junto a cada instância de microsserviço interceptando todo tráfego de rede. Responsabilidades incluem autenticação mútua via mTLS garantindo identidade de serviços comunicantes, circuit breaking protegendo contra cascata de falhas, retries automáticas com backoff exponencial, telemetria detalhada de todas interações, e traffic shaping para deployments canary e blue-green. Service Mesh opera em camada de infraestrutura transparente a código de aplicação, configurado através de CRDs Kubernetes e políticas declarativas.

API Gateway concentra-se em comunicação north-south entre clientes externos e sistema, expondo interface pública unificada, implementando autenticação de usuários finais, aplicando rate limiting por cliente, agregando respostas de múltiplos serviços, e transformando protocolos externos em comunicação interna. Enquanto Service Mesh protege comunicação east-west entre microsserviços dentro de cluster Kubernetes, API Gateway medeia tráfego ingress de internet pública ou redes corporativas externas.

Arquiteturas maduras frequentemente combinam ambos padrões: API Gateway como Traefik ou Kong recebe tráfego externo, valida autenticação de usuários, aplica rate limiting público e roteia a microsserviços internos, enquanto Service Mesh gerencia comunicação inter-serviços com mTLS, observabilidade e resiliência. Integração permite que API Gateway injete headers de identidade de usuário em requisições upstream, propagados através de Service Mesh preservando contexto de autenticação através de múltiplos hops internos.

## Segurança e Melhores Práticas

### Validação de Input e Proteção contra Injeção

API Gateway deve validar rigorosamente inputs de requisições antes de encaminhá-las a serviços backend, protegendo contra SQL injection através de validação de parâmetros, XSS sanitizando strings submetidas, command injection rejeitando caracteres especiais em campos utilizados para execução de comandos, e path traversal normalizando caminhos de arquivo. Plugin request-validator de Kong valida requisições contra schema JSON ou OpenAPI specification:

```yaml
plugins:
  - name: request-validator
    config:
      allowed_content_types:
        - application/json
      body_schema: |
        {
          "type": "object",
          "properties": {
            "url": {
              "type": "string",
              "format": "uri",
              "maxLength": 2048
            }
          },
          "required": ["url"]
        }
```

### CORS e Segurança de Browser

Cross-Origin Resource Sharing permite que aplicações web hospedadas em domínio acessem APIs em domínio distinto, controlado através de headers CORS configurados no API Gateway:

```yaml
plugins:
  - name: cors
    config:
      origins:
        - https://app.exemplo.com
        - https://mobile.exemplo.com
      methods:
        - GET
        - POST
        - PUT
        - DELETE
        - OPTIONS
      headers:
        - Accept
        - Authorization
        - Content-Type
        - X-Requested-With
      exposed_headers:
        - X-Auth-Token
        - X-RateLimit-Remaining
      credentials: true
      max_age: 3600
      preflight_continue: false
```

Parâmetro origins especifica domínios permitidos para requisições cross-origin, methods restringe verbos HTTP aceitos, headers lista headers customizados permitidos em requisições, exposed_headers declara headers de resposta acessíveis por JavaScript, credentials permite envio de cookies e headers de autenticação, e max_age define cache de resposta preflight OPTIONS. Configuração inadequada de CORS pode expor APIs a ataques CSRF ou vazamento de dados sensíveis a origens maliciosas.

### TLS Termination e Certificados

API Gateway tipicamente implementa TLS termination onde conexões HTTPS de clientes são decifradas no gateway, comunicação interna a serviços backend ocorre em HTTP simples dentro de rede privada confiável, reduzindo overhead de criptografia em microsserviços e centralizando gestão de certificados. Deployment em produção exige certificados válidos emitidos por Certificate Authority confiável como Let's Encrypt, configurados em Kong via Admin API ou arquivos de configuração:

```yaml
certificates:
  - cert: |
      -----BEGIN CERTIFICATE-----
      MIIDXTCCAkWgAwIBAgIJAKJ3...
      -----END CERTIFICATE-----
    key: |
      -----BEGIN PRIVATE KEY-----
      MIIEvQIBADANBgkqhkiG9w0B...
      -----END PRIVATE KEY-----
    snis:
      - api.exemplo.com
      - "*.exemplo.com"
```

Renovação automática de certificados integra-se com ACME protocol através de plugins como kong-certbot ou integration com cert-manager em Kubernetes. Comunicação entre API Gateway e serviços backend sensíveis pode requerer mTLS onde ambos lados apresentam certificados validando identidade mútua, prevenindo ataques de man-in-the-middle em redes internas potencialmente comprometidas.

## Deployment e Escalabilidade

### Containerização e Kubernetes

Deployment moderno de Kong Gateway utiliza containers Docker orquestrados por Kubernetes aproveitando recursos nativos de service discovery, health checking e rolling updates. Deployment declarativo via Helm chart simplifica provisionamento:

```yaml
# values.yaml para Helm chart Kong
env:
  database: "off"
  nginx_worker_processes: "auto"
  proxy_access_log: /dev/stdout
  admin_access_log: /dev/stdout
  admin_gui_access_log: /dev/stdout
  portal_api_access_log: /dev/stdout
  proxy_error_log: /dev/stderr
  admin_error_log: /dev/stderr
  admin_gui_error_log: /dev/stderr

ingressController:
  enabled: true
  installCRDs: false

image:
  repository: kong
  tag: "3.4"

proxy:
  enabled: true
  type: LoadBalancer
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: nlb

admin:
  enabled: true
  type: ClusterIP

resources:
  limits:
    cpu: 2000m
    memory: 2Gi
  requests:
    cpu: 1000m
    memory: 1Gi

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
```

Horizontal Pod Autoscaler escala automaticamente número de réplicas Kong baseando-se em utilização de CPU ou métricas customizadas como requisições por segundo, garantindo capacidade adequada durante picos de tráfego. Service type LoadBalancer provisiona load balancer externo em provedores cloud distribuindo tráfego entre pods Kong, enquanto ClusterIP para Admin API restringe acesso a cluster interno. ConfigMaps armazenam configuração declarativa de serviços e rotas carregada por pods Kong, permitindo atualizações de configuração via rolling restart sem downtime.

## Conclusão

API Gateway estabelece-se como componente arquitetural indispensável em sistemas de microsserviços maduros, resolvendo fundamentalmente desafio de fragmentação de comunicação inerente a decomposição de monolitos em serviços distribuídos. Centralização de ponto de entrada unificado simplifica drasticamente integração de clientes front-end eliminando necessidade de gerenciar configuração de dezenas de endpoints individuais, permite reorganização transparente de topologia interna sem impactar contratos públicos de API, e habilita otimização de interfaces para diferentes tipos de clientes através de customização de payloads e agregação de respostas. Concentração de responsabilidades transversais como autenticação JWT, rate limiting, transformação de protocolos, logging estruturado e observabilidade evita duplicação de lógica complexa em cada microsserviço, promove consistência de políticas de segurança através de sistema inteiro, e centraliza gestão de chaves públicas e configuração de throttling facilitando evolução e manutenção.

Implementações práticas utilizando Kong Gateway demonstram maturidade de ecossistema open-source oferecendo arquitetura extensível via plugins, deployment flexível em modos tradicionais com banco de dados ou DB-less através de configuração declarativa YAML, integração profunda com autenticação JWT suportando JWKS para descoberta dinâmica de chaves públicas, rate limiting sofisticado com múltiplas políticas de armazenamento e estratégias de identificação, e observabilidade abrangente através de integração nativa com Prometheus e sistemas de logging centralizado. Trade-offs incluem complexidade adicional de componente intermediário exigindo desenvolvimento, deployment e manutenção dedicados, overhead de performance através de hop de rede adicional tipicamente inferior a 10 milissegundos, e risco de API Gateway tornar-se monolito distribuído quando responsabilidades excessivas concentram-se inadequadamente. Arquiteturas maduras frequentemente combinam API Gateway para tráfego north-south de clientes externos com Service Mesh gerenciando comunicação east-west inter-serviços, aproveitando pontos fortes de cada padrão em suas respectivas responsabilidades. Compreensão profunda de fundamentos de API Gateway, motivações arquiteturais, implementação prática e trade-offs permite arquitetar sistemas distribuídos resilientes, seguros e performáticos que escalam eficientemente com crescimento de complexidade e carga.

## Referências Bibliográficas

1. **Microservices.io - API Gateway Pattern**. Chris Richardson. Disponível em: https://microservices.io/patterns/apigateway.html

2. **Microsoft Azure - API Gateway Pattern**. Microsoft Corporation. Disponível em: https://learn.microsoft.com/azure/architecture/microservices/design/gateway

3. **Kong Gateway Documentation**. Kong Inc. Disponível em: https://docs.konghq.com/

4. **Apache APISIX Documentation**. Apache Software Foundation. Disponível em: https://apisix.apache.org/docs/

5. **Traefik Proxy Documentation**. Traefik Labs. Disponível em: https://doc.traefik.io/traefik/

6. **Envoy Proxy Documentation**. Envoy Authors. Disponível em: https://www.envoyproxy.io/docs/

7. **AWS API Gateway Documentation**. Amazon Web Services. Disponível em: https://docs.aws.amazon.com/apigateway/

8. **Istio - Gateway vs Service Mesh**. Istio Authors, 2024. Disponível em: https://istio.io/latest/docs/concepts/traffic-management/

9. **NGINX - API Gateway Guide**. NGINX Inc. Disponível em: https://www.nginx.com/learn/api-gateway/

10. **Spring Cloud Gateway Documentation**. VMware Inc. Disponível em: https://spring.io/projects/spring-cloud-gateway

11. **Martin Fowler - Gateway Patterns**. Martin Fowler. Disponível em: https://martinfowler.com/

12. **Kubernetes Gateway API**. Kubernetes SIG Network. Disponível em: https://gateway-api.sigs.k8s.io/

## Apêndice A: Exemplo Completo de Configuração Kong

Configuração declarativa completa demonstrando serviços, rotas, plugins e consumers para sistema de encurtamento de URLs:

```yaml
_format_version: "3.0"

services:
  - name: auth-service
    url: http://auth:3000
    protocol: http
    connect_timeout: 5000
    write_timeout: 5000
    read_timeout: 5000
    retries: 3

    routes:
      - name: register
        paths:
          - /auth/register
        methods:
          - POST
        strip_path: false

      - name: login
        paths:
          - /auth/login
        methods:
          - POST
        strip_path: false

      - name: jwks
        paths:
          - /.well-known/jwks.json
        methods:
          - GET
        strip_path: false

  - name: shortener-service
    url: http://shortener:4000
    protocol: http
    retries: 3

    routes:
      - name: create-short-url
        paths:
          - /api/shortener
        methods:
          - POST
        strip_path: true

      - name: redirect-short-url
        paths:
          - /s
        methods:
          - GET
        strip_path: true

    plugins:
      - name: jwt
        enabled: true
        config:
          claims_to_verify:
            - exp
          key_claim_name: iss

      - name: request-transformer
        config:
          add:
            headers:
              - "X-User-ID:$(X-Consumer-Custom-ID)"

      - name: rate-limiting
        config:
          minute: 30
          policy: redis
          redis_host: redis
          redis_port: 6379
          limit_by: consumer

  - name: analytics-service
    url: http://analytics:3001
    protocol: http

    routes:
      - name: get-analytics
        paths:
          - /api/analytics
        methods:
          - GET
        strip_path: true

    plugins:
      - name: jwt
        config:
          claims_to_verify:
            - exp

      - name: request-transformer
        config:
          add:
            headers:
              - "X-User-ID:$(X-Consumer-Custom-ID)"

consumers:
  - username: auth-system
    custom_id: auth-service
    jwt_secrets:
      - key: auth-service
        algorithm: RS256
        rsa_public_key: |
          -----BEGIN PUBLIC KEY-----
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxGOr-H7A...
          -----END PUBLIC KEY-----

plugins:
  - name: correlation-id
    config:
      header_name: X-Correlation-ID
      generator: uuid
      echo_downstream: true

  - name: prometheus
    config:
      per_consumer: true

  - name: request-size-limiting
    config:
      allowed_payload_size: 8
      size_unit: megabytes

upstreams:
  - name: shortener-upstream
    algorithm: round-robin
    slots: 10000
    healthchecks:
      active:
        type: http
        http_path: /health
        timeout: 3
        healthy:
          interval: 5
          successes: 2
        unhealthy:
          interval: 5
          http_failures: 3
    targets:
      - target: shortener-1:4000
        weight: 100
      - target: shortener-2:4000
        weight: 100
```

## Apêndice B: Exemplo de Plugin Customizado Kong

Implementação de plugin customizado em Lua para agregação de respostas:

```lua
-- handler.lua
local http = require "resty.http"
local cjson = require "cjson"

local DashboardAggregator = {
  PRIORITY = 1000,
  VERSION = "1.0.0"
}

function DashboardAggregator:access(conf)
  local userId = kong.request.get_header("X-User-ID")

  if not userId then
    return kong.response.exit(401, {
      message = "Authentication required"
    })
  end

  local httpc = http.new()
  httpc:set_timeout(5000)

  -- Requisições paralelas
  local responses = {}

  local function fetch_service(name, url)
    local res, err = httpc:request_uri(url, {
      method = "GET",
      headers = {
        ["X-User-ID"] = userId,
        ["X-Correlation-ID"] = kong.request.get_header("X-Correlation-ID")
      }
    })

    if err then
      kong.log.err("Failed to fetch ", name, ": ", err)
      responses[name] = { error = err }
    else
      responses[name] = cjson.decode(res.body)
    end
  end

  local threads = {
    ngx.thread.spawn(fetch_service, "orders",
      string.format("http://orders:5000/api/users/%s/orders", userId)),
    ngx.thread.spawn(fetch_service, "analytics",
      string.format("http://analytics:3001/api/users/%s/stats", userId)),
    ngx.thread.spawn(fetch_service, "profile",
      string.format("http://profile:6000/api/users/%s", userId))
  }

  for i = 1, #threads do
    ngx.thread.wait(threads[i])
  end

  return kong.response.exit(200, {
    user = responses.profile,
    recentOrders = responses.orders,
    statistics = responses.analytics
  })
end

return DashboardAggregator
```

## Glossário e Termos Técnicos

**API Gateway**: Componente arquitetural servindo como ponto de entrada único mediando comunicação entre clientes e microsserviços distribuídos, implementando roteamento, autenticação e políticas transversais.

**Active Health Check**: Sondagem periódica proativa a endpoints de saúde de serviços backend determinando disponibilidade através de requisições HTTP ou TCP.

**Circuit Breaker**: Padrão de resiliência detectando falhas consecutivas em serviço downstream temporariamente bloqueando requisições adicionais permitindo recuperação.

**Consistent Hashing**: Algoritmo de load balancing mapeando requisições a backends baseando-se em hash de atributo garantindo afinidade onde mesmo cliente direciona-se consistentemente a mesma instância.

**Consumer**: Entidade em Kong representando cliente autenticado da API possuindo credenciais como chaves API ou secrets JWT associados.

**Correlation ID**: Identificador único propagado através de headers HTTP rastreando requisição end-to-end através de múltiplos serviços distribuídos facilitando debugging.

**CORS**: Cross-Origin Resource Sharing, mecanismo de segurança de browsers controlando acesso de aplicações web a recursos em domínios distintos através de headers HTTP.

**DB-less Mode**: Modo de deployment de Kong eliminando dependência de banco de dados operando exclusivamente com configuração declarativa em arquivos YAML carregados na inicialização.

**Health Check**: Verificação periódica de disponibilidade e saúde de serviços backend através de sondagens ativas ou monitoramento passivo de taxa de erros.

**Ingress**: Tráfego de rede entrando em sistema de microsserviços originado de clientes externos, oposto a tráfego east-west entre serviços internos.

**Leaky Bucket**: Algoritmo de rate limiting processando requisições a taxa constante enfileirando excedentes até capacidade onde requisições adicionais são descartadas.

**Load Balancing**: Distribuição de tráfego entre múltiplas instâncias de serviço backend através de algoritmos como round-robin, least-connections ou consistent-hashing.

**North-South Traffic**: Tráfego de rede entre clientes externos e serviços internos atravessando perímetro de sistema, mediado por API Gateway.

**East-West Traffic**: Tráfego de rede entre serviços internos dentro de cluster, tipicamente gerenciado por Service Mesh.

**Passive Health Check**: Monitoramento de tráfego de produção inferindo saúde de backends baseando-se em taxa de erros e timeouts observados.

**Plugin**: Módulo extensível em API Gateway adicionando funcionalidades como autenticação, rate limiting, transformações ou logging.

**Proxy Reverso**: Servidor intermediário recebendo requisições de clientes e encaminhando a servidores backend, ocultando topologia interna.

**Rate Limiting**: Restrição de número de requisições permitidas por cliente em janela temporal protegendo contra sobrecarga e abuso.

**Route**: Configuração em API Gateway definindo padrões de matching de URLs, métodos HTTP e headers mapeando requisições a serviços backend específicos.

**Service Mesh**: Camada de infraestrutura dedicada gerenciando comunicação service-to-service com proxy sidecars implementando mTLS, observabilidade e resiliência.

**Strip Path**: Configuração em routes de API Gateway controlando se prefixo de URL deve ser removido antes de encaminhar requisição a serviço upstream.

**Target**: Instância individual de serviço backend em upstream recebendo tráfego distribuído por load balancer com weight configurável.

**TLS Termination**: Decifração de conexões HTTPS no API Gateway comunicando-se com backends em HTTP simples centralizando gestão de certificados.

**Token Bucket**: Algoritmo de rate limiting permitindo bursts controlados onde tokens acumulam-se a taxa constante e requisições consomem tokens disponíveis.

**Upstream**: Grupo de instâncias de serviço backend entre quais API Gateway distribui tráfego através de load balancing com health checking.
