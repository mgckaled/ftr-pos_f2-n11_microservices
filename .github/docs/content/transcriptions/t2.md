# Transcrição: 2. Comunicação em Microsserviços

Nessa aula a gente vai falar especificamente sobre a comunicação entre serviços e ao longo das aulas eu vou utilizar um projeto que eu vou deixar aqui embaixo o link para você acessar. Ele vai ser um projeto público que eu vou deixar no GitHub onde eu implemento a maioria dos conceitos que são importantes, você saber na hora de trabalhar com microserviços utilizando Node, então lá vão ter todos os conceitos das próximas aulas, aqui eu sempre vou mostrar ele na teoria e depois a gente vai ver como que ele é na prática. A gente não vai construir todo o código do zero, porque a gente teria que passar por muitas coisas que são Digamos que não tem a ver com micro serviços justamente e algumas coisas levariam muito tempo para ser implementadas, então eu vou te mostrar bem como que é a teoria, como que isso funciona e a gente vai ver depois no código como que isso é implementado. Comunicação entre microserviços. Como a gente falou, microserviços devem ser aplicações que funcionam de forma totalmente isolada, ou seja, o serviço de encurtamento de URL não deveria depender do serviço de analytics estar funcionando para que as URLs sejam criadas, que é diferente de um monolito, onde se o serviço de analytics caiu, provavelmente o serviço de encurtamento caiu também, eles não funcionam de forma separada. E para que isso aconteça, para que a gente tenha essa independência, a gente tem protocolos de comunicação para fazer a comunicação, a troca de mensagens entre serviços. Então, por exemplo, quando eu faço a construção, a criação aqui de uma URL dentro da tabela de URLs encurtadas, eu posso querer criar esse cadastro de URL também no sistema de Analytics, para que eu possa começar a contabilizar o número de cliques que eu tenho dentro de cada URL. Isso eu posso fazer de diversas formas, por exemplo, quando o cliente, o usuário, faz uma requisição para a minha API de encurtamento e essa API precisa avisar o serviço de Analytics, ela pode fazer isso usando HTTP, por exemplo. Isso é legal, só que o que acontece se o meu serviço de analítica estiver fora do ar? Essa requisição HTTP aqui vai falhar e provavelmente eu não vou ter uma retentativa e esse erro do HTTP provavelmente vai também prejudicar a comunicação que houve do front-end com o encurtador. Então, provavelmente eu vou ter um erro aqui, um erro acontecendo nessa requisição, então ela vai devolver um status 400, por exemplo, ou até 500 nesse caso, porque o servidor está fora do ar. Só que... Você concorda comigo que talvez a gente possa fazer isso aqui de forma assíncrona? Então, o usuário pode criar a URL encurtada e essa é a comunicação do nosso banco de analíticas ter a informação em tempo real da URL, pode ser feita de forma assíncrona. Mesmo que você queira ir por uma estratégia síncrona, ou seja, imagina que... A criação da URL depende totalmente do serviço de Analytics ter respondido corretamente. Então, imagina na verdade que a gente não está trabalhando com um app de encurtamento de URL. Imagina que a gente está trabalhando com um app de pedidos. E aí, eu tenho um app de pedidos e eu tenho um app de estoque, onde eu faço o controle de estoque das minhas mercadorias. E aí, o usuário está fazendo uma requisição para criar um pedido. Então, ele está fazendo uma requisição post que cria o pedido, E esse sistema de pedido aqui, por exemplo, ele tem que consultar o sistema de estoque para ver se eu tenho estoque suficiente. Nesse caso aqui, não daria para ser uma requisição assíncrona, porque o usuário está fazendo o pedido, eu preciso consultar o estoque em tempo real para saber se o estoque está disponível para que o pedido seja feito. Nesse caso, sim, eu posso fazer HTTP e falhar a requisição post aqui, caso o estoque me retorne que não está disponível, mas ainda nesses casos, seria provavelmente melhor a gente utilizar o gRPC no lugar do HTTP. O gRPC, diferente do HTTP, ele utiliza uma... A gRPC vem de Google Remote Procedure Call. Remote Procedure Call é um termo muito utilizado na RPC para várias tecnologias, mas diferente do HTTP, toda chamada gRPC passa por algo que a gente chama de protobuf. O protobuf é um arquivo que tem instruções de como cada chamada para a nossa API, aqui no caso, tem que ser feita. E o mais legal disso é que essa requisição ela fica totalmente tipada, ela evita que a gente faça requisições enviando parâmetros ou recebendo respostas que não estão disponíveis e outra coisa é que ela usa o protocolo htp2, então a gente já pula muitos dos processos que o htp1 faz mas bom isso aqui são só detalhes porque na grande maioria das vezes a gente vai estar utilizando comunicação assíncrona nos casos onde a gente pode e aí para comunicação assíncrona a gente tem geralmente três ferramentas que são as mais famosas para fazer isso que é o Kafka da Apache Ele é muito comum. O RabbitMQ também que é muito comum. E o Redis. O Redis como sendo uma alternativa quase que nunca utilizada e barra não recomendada. Geralmente você vai ver Kafka ou RabbitMQ sendo utilizados com esses propósitos. E aí como é que funcionam essas ferramentas aqui? Basicamente elas funcionam com um padrão de publish a subscribe. Você provavelmente já deve ter ouvido falar desse padrão. O que acontece? Ao invés de a API de encortamento enviar direto para o nosso Analytics via HTTP ou qualquer coisa assim, a gente tem aqui algo que a gente chama de broker, que é um sisteminha que vai estar rodando. Nesse caso, vamos imaginar que é o Kafka, vou botar entre parênteses aqui, que é o nosso broker, message broker, e o Kafka por si só tem um banco de dados onde ficam armazenadas as mensagens. E o que acontece? Deixa eu diminuir um pouquinho isso aqui. Beleza. Isso aqui vai estar comunicando aqui, o Kafka vai estar comunicando com esse carinha aqui. Então, o serviço de Shortener, ao invés de ele comunicar direto com o serviço de Analytics, ele vai, na verdade, publicar uma mensagem, por isso que tem o nome Publish, ele vai publicar uma mensagem dentro do nosso banco de dados do Kafka. E a mensagem, ela geralmente vai ter algo como o seguinte, ela vai ter um conteúdo, que pode ser em JSON, pode ser em Buffer, tem vários formatos. Você vai enviar uma mensagem, por exemplo, com um evento que aconteceu. Então, um evento que aconteceu foi um tópico, uma URL foi criada. Então, URL created. E aqui a gente pode ter os demais dados da nossa URL. Deixa eu diminuir um pouquinho esse texto aqui. E aí, o que acontece? Quando ele publica esse evento aqui dentro do nosso broker, a gente pode ter o serviço de analytics ouvindo essas mensagens, por isso o padrão subscribe. Então, o serviço de analytics, quando ele entrar no ar, ele vai lá no nosso broker aqui, buscar as mensagens que estão disponíveis lá e ele pode falar... Olha, me traz todas as mensagens onde o evento for URL created. E aí, ele vai ter, sei lá, 12 mensagens desde a última vez que foi processado e ele vai cadastrar tudo isso no banco de dados. É claro que esse negócio de ter 12 mensagens é só o seu serviço cair. Na grande maioria das vezes, na verdade, essas mensagens vão estar trafegando quase em tempo real. Então, assim que o serviço de Shortener publicar essa mensagem no broker, essa mensagem vai ser recebida pelo Analytics em tempo real praticamente e processada e criada no banco de dados dele. E aí, o legal é que o Kafka tem um banco de dados. Então, esse banco de dados aqui serve para armazenar as mensagens que ainda não foram processadas ou que precisam ser reprocessadas. O que isso quer dizer? Lá dentro do Kafka, quando a gente envia uma mensagem, a gente pode configurar para que ela fique dentro do banco de dados do Kafka por um tempo. Então, eu consigo... Deixa eu ver se consigo alinhar aqui o texto... Acho que aqui dentro não consigo... Tá, mas não tem problema. Eu consigo falar para ele, olha, eu quero que essa mensagem aqui fique dentro do Kafka por seis meses. Isso aqui é bem comum de acontecer. Isso quer dizer que as mensagens, quando elas forem processadas pelo Analytics, ou imagina que o Analytics está offline, se esse Analytics ficar fora do ar por um mês inteiro, quando ele voltar, ele vai automaticamente buscar todas as mensagens que tem no banco de dados do Kafka e trazer aqui para dentro do Analytics processar todas essas mensagens. E o mais legal de eu manter essas mensagens por um longo período de tempo aqui dentro, principalmente mensagens que são mais críticas, como por exemplo, voltada a e-commerce, pedido de cliente, nota fiscal, essas coisas assim, é que eu posso reprocessar essas mensagens no futuro. Então, o que acontece? Quando o Analytics lê essas mensagens do banco, ele não deleta do banco, ele só anota que o serviço de Analytics leu as mensagens. E para isso acontecer, dentro do Kafka, a gente tem uma configuração que a gente chama de... Consumer Group, ou seja, eu dou um nome para esse consumer, um grupo, digamos assim, falando... Esse cara aqui, o nome, o Consumer Group dele é Analytics. Isso quer dizer que lá no Kafka, quando ele lê essa mensagem, ele não vai deletar do banco, ele só vai anotar que... o Consumer Group Analytics já leu a mensagem. Ou seja, se em algum momento outro serviço entrar no ar e precisar dessas mensagens aqui, vai ser outro Consumer Group e ele vai começar a ler as mensagens. E geralmente essa diferenciação que a gente tem por eventos, ela é feita através de tópicos. Então, no Kafka, a gente tem tópicos. Ao invés de a gente ter eventos, a gente tem tópicos. Então, o que acontece? Quando uma URL é criada, a gente emite uma mensagem para um tópico específico do Kafka. Então, imagina que a gente tem um tópico, que é como se fosse um banco de dados, uma tabela específica, chamada... E geralmente, a gente prefixa esse tópico com o nome do serviço que gerou aquela mensagem. Então, por exemplo, shortener, ponto e o evento que aconteceu o rl created e aqui é um nome que eu eu sigo geralmente esse padrão com o ponto mas não precisa ser assim poderia ser um if, poderia nem ter o shortener aqui na frente e aí nesse tópico aqui é como se fosse uma tabela específica para todas as urls que foram criadas e dentro dela vai ficar todas as urls E lá no meu analytics, eu também faço subscribe para tópicos específicos. Então, eu não ouço todas as mensagens que estão trafegando no meu Kafka, até porque seria um overhead muito grande. E aí, vamos entender um pouquinho como que isso fica aqui no código. Então, eu trouxe um pouquinho aqui do exemplo de aplicação disso aqui no código. Até para a gente entender, nesse código aqui eu tenho, aqui dentro de apps, três serviços. Eu tenho o Analytics, como eu mostrei para você, o serviço de encurtamento de URL e eu mantive ele o mais simples possível. Provavelmente os arquivos, da maneira que você está vendo aqui agora, não necessariamente vão ser os mesmos arquivos até o final da aula, porque eu estou refaturando algumas coisas nesse projeto enquanto eu vou gravando para ele, mas a gente tem aqui dentro de contracts. Basicamente, algo que eu gosto muito de fazer que é, toda vez que nós temos comunicação assíncrona entre mais de um serviço, é muito importante que a gente saiba exatamente quais são os dados que vão ser trafegados entre esses tópicos. Então, qual é o formato da mensagem que eu estou enviando desse serviço de encurtamento, como essa mensagem deve ser tratada pelo serviço de analíticos, quais campos são obrigatórios, quais campos podem ser nulos... E, geralmente, a gente faz isso através de tipagem. Se eu não estou com todos os serviços escritos na mesma tecnologia, isso é um desafio muito grande e a gente parte para a utilização de algo como o JSON Schema, que é uma maneira de a gente tipar um JSON, criar um esquema para ele que é global, que todas as linguagens entendem. Só que se você está criando um projeto que é Full TypeScript, não tem por que a gente não fazer o uso da própria tipagem do TypeScript. Então, se eu entrar aqui em URL Shortener, você vai ver que eu tenho aqui o URL Created Event, que é basicamente uma tipagem, e aqui eu estou utilizando o Zod, de quais dados eu incluo no evento de URL criada, disparado aqui pelo serviço de URL Shortener. Então, isso é bem legal e eu deixo tudo documentado. Assim como, por exemplo, eu tenho aqui... o evento que é emitido pelo analytics quando alguém clica num link quando alguém acessa algum link né então eu tenho tudo isso disponível aqui dentro como também eu tenho aqui no caso é esse aqui são só os eventos do rl short né o analytics ele não tem nenhum evento aqui por enquanto né e aí o que acontece quando eu tenho lá na rota da minha aplicação usuário cria uma rl veja que eu vou lá E faço aqui, depois de criar o URL claro, eu publico esse evento dentro do Kafka. Então, eu dou aqui um publish urlCreatedEvent, passando todos os dados necessários. E aqui, como eu falei, eles já estão todos tipados com o TypeScript. Esse publish urlCreatedEvent aqui, ele nada mais é do que simplesmente a chamada para função do Kafka. Então, ele pega o Kafka, que é a conexão aqui com o nosso... o Apache Kafka, então é só uma classe que faz a conexão e faz a publicação dentro de um evento. E aí, veja que esse evento, como eu falei, eu o prefixo com o nome do serviço que disparou o evento, nesse caso aqui o rlShortener, ponto e o nome do evento, o rlCreated. Então, eu disparo isso e lá dentro do meu serviço de Analytics, eu tenho aqui dentro de Kafka os meus consumers, que são os meus subscribers, digamos assim, eu gosto de chamar de consumers. e aí eu tenho aqui o URL createdEventConsumer e aí o que ele faz aqui embaixo né ele vai lá no Kafka né então aqui eu tenho o Consumer ele é uma classe que ele faz basicamente aqui em cima eu tenho dentro de ConsumersIndex eu criei um objeto chamado ConsumedEvents que eu falo quais eventos Esse projeto, que no caso é o Analytics, ele consome. Então, aqui eu estou falando que ele consome tanto o evento URL created. Então, quando uma URL for criada, esse projeto Analytics precisa fazer alguma coisa. Como também quando acontece o clique dentro de uma URL, ele também precisa consumir. E aí ele fala, quando uma URL for criada, ele vai disparar esta função aqui, o handler, que a gente pode acessar ela aqui dentro. E aí o que eu faço nela é basicamente eu Cadastro essa URL dentro do nosso banco de dados. Então, lembra que é o que eu comentei sobre comunicação assíncrona. Então, eu tenho dois sistemas se comunicando, porém, quando acontece algo em um desses sistemas, ele apenas emite um evento. Os outros sistemas podem ouvir este evento e fazer alguma coisa com essa informação. Então, a grande maioria da comunicação, a grande maioria da parte de mensageria que a gente chama, de comunicação entre mais de um serviço, acontece exatamente dessa forma, utilizando comunicação assíncrona sempre que possível e recorrendo para comunicação síncrona através de HTTP e gRPC, por exemplo, somente nos casos onde são extremamente necessários.
