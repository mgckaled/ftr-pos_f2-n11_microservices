<!-- markdownlint-disable -->

# Aula 7: Idempotência em Microsserviços

## Resumo Executivo

Idempotência constitui fundamento crítico em arquiteturas de microsserviços, garantindo que operações executadas múltiplas vezes com parâmetros idênticos produzam resultado equivalente à execução única, independentemente de quantas tentativas sejam realizadas. Em sistemas distribuídos caracterizados por comunicação assíncrona através de message brokers como Apache Kafka e RabbitMQ, mensagens podem ser entregues múltiplas vezes devido a falhas de rede, timeouts, rebalanceamentos de partições em Consumer Groups, ou reprocessamentos após exceções não tratadas, criando risco substancial de duplicação de operações críticas como cobranças financeiras, criação de registros redundantes ou incrementos incorretos de contadores analíticos. Mecanismo fundamental para implementação de idempotência baseia-se em identificadores únicos denominados Idempotency Keys ou Event IDs que acompanham cada mensagem, permitindo que consumidores consultem tabela de eventos processados antes de executar lógica de negócio, descartando silenciosamente mensagens cujos identificadores já constam como processados anteriormente. Padrão emergiu como requisito não-negociável em sistemas de pagamento demonstrado por implementações de referência em APIs públicas de Stripe, PayPal e Twilio, onde clientes submetem Idempotency-Key em header HTTP garantindo que requisição duplicada por instabilidade de rede não resulte em cobrança dupla ao usuário final.

Aula demonstra implementação prática utilizando sistema de encurtamento de URLs onde serviço Shortener publica evento `URLCreated` para tópico Kafka incluindo Event ID determinístico gerado através de hash dos parâmetros de entrada, enquanto serviço Analytics mantém tabela `ProcessedEvents` armazenando identificadores de eventos já consumidos com timestamps de processamento, consultando existência antes de inserir registros analíticos e evitando inflação artificial de métricas através de reprocessamentos inadvertidos. Desafio arquitetural amplia-se em cenários onde consumidor executa múltiplas operações heterogêneas sequencialmente, exemplificado por salvamento no Redis seguido de persistência no PostgreSQL, onde falha na segunda operação após sucesso na primeira desencadeia retentativa automática do Kafka que reexecuta ambas operações, necessitando idempotência implementada granularmente em cada etapa através de verificações específicas como EXISTS no Redis e ON CONFLICT DO NOTHING no PostgreSQL. Conceito transcende implementação técnica para tornar-se propriedade semântica fundamental de APIs RESTful conforme especificação RFC 7231 que classifica métodos HTTP GET, PUT e DELETE como inerentemente idempotentes por design, contrastando com POST que permite criação de recursos distintos a cada invocação, orientando desenvolvedores na modelagem apropriada de endpoints considerando comportamento esperado sob retentativas.

## Introdução e Conceitos

### Contexto em Sistemas Distribuídos

Microsserviços operam em ambientes caracterizados por incerteza inerente onde comunicação entre componentes atravessa redes não confiáveis sujeitas a latências variáveis, perda de pacotes e particionamento temporário conforme teorema CAP. Diferentemente de arquiteturas monolíticas onde invocações de métodos ocorrem em memória compartilhada com semântica transacional garantida por ACID, sistemas distribuídos enfrentam desafios de mensagens duplicadas originadas por múltiplos vetores: retentativas automáticas de produtores após timeouts onde confirmação foi perdida mas mensagem efetivamente persistida, rebalanceamentos de Consumer Groups que reassignam partições Kafka para consumidores diferentes antes de commit de offset resultar em reprocessamento de mensagens já consumidas parcialmente, e falhas de consumidor após processar mensagem mas antes de confirmar offset resultando em redeliver após recuperação.

Problema amplifica-se em comunicação assíncrona através de message brokers que implementam garantias de entrega at-least-once delivery por padrão, onde broker retenta entregar mensagem até receber confirmação explícita de processamento bem-sucedido, priorizando prevenção de perda de dados sobre prevenção de duplicação. Apache Kafka exemplifica através de configuração `enable.idempotence=false` em produtores legados que permite duplicação de mensagens quando retentativas ocorrem após timeout mas antes de receber acknowledge do broker, enquanto `acks=all` garante persistência em todas réplicas mas não elimina possibilidade de producer reenviar mensagem idêntica interpretando timeout como falha quando na realidade commit foi concluído com sucesso.

### Definição Formal de Idempotência

Operação qualifica-se como idempotente quando aplicação múltipla com parâmetros idênticos produz estado final equivalente à aplicação única, formalmente expressa como `f(f(x)) = f(x)` para toda função `f` e entrada `x`. Propriedade matemática origina-se de álgebra abstrata onde operações como multiplicação por um em números reais ou união de conjunto consigo mesmo demonstram comportamento idempotente, contrastando com incremento aritmético que produz resultados distintos a cada aplicação.

No contexto de sistemas distribuídos, idempotência manifesta-se através de operações que podem ser invocadas repetidamente sem alterar resultado além da primeira execução bem-sucedida. Exemplos incluem atualização de registro com valores absolutos onde `UPDATE users SET name='João' WHERE id=123` produz estado idêntico independentemente de execuções repetidas, deleção de recurso onde segunda tentativa de deletar entidade já removida resulta em noop sem efeitos colaterais adversos, e consultas read-only que por natureza não modificam estado.

Contrasta com operações não-idempotentes caracterizadas por modificação cumulativa de estado como incremento de contadores onde `UPDATE analytics SET click_count = click_count + 1` aplicado múltiplas vezes para mesma mensagem infla artificialmente métricas, criação de registros duplicados onde inserção repetida de pedido com parâmetros idênticos resulta em múltiplas cobranças ao cliente, e disparo de notificações onde reprocessamento de evento envia emails ou SMS redundantes degradando experiência de usuário e incorrendo custos operacionais desnecessários.

### Idempotência versus Deduplicação

Terminologia frequentemente utilizada intercambiavelmente requer diferenciação conceitual precisa. Idempotência representa propriedade semântica de operação que tolera execuções repetidas produzindo resultado consistente, implementada através de lógica de negócio que verifica estado atual antes de modificação como consultar existência de registro antes de inserção. Deduplicação constitui mecanismo infraestrutural que previne reprocessamento através de rastreamento de identificadores únicos de mensagens já consumidas, implementado tipicamente através de tabela auxiliar ou cache distribuído armazenando Event IDs processados.

Sistemas robustos combinam ambas abordagens em defesa em profundidade onde deduplicação em nível de mensageria através de Processed Events atua como primeira linha de proteção descartando mensagens duplicadas antes de alcançar lógica de negócio, enquanto operações idempotentes por design fornecem segunda camada de segurança garantindo que mesmo mensagens não detectadas pelo mecanismo de deduplicação não corrompam estado do sistema.

## Implementação de Idempotência em Microsserviços

### Idempotency Keys em Eventos Kafka

Padrão fundamental estabelece que todo evento publicado para message broker deve incluir identificador único imutável denominado Event ID ou Idempotency Key que acompanha mensagem durante todo ciclo de vida. Geração deste identificador segue estratégias distintas conforme requisitos:

**Identificadores Aleatórios**: Utilização de UUID v4 garante unicidade probabilística através de 122 bits de aleatoriedade produzindo aproximadamente 2^122 combinações possíveis, apropriado quando não existe correlação natural entre parâmetros de entrada e identidade do evento. Implementação em TypeScript demonstra geração através de biblioteca nativa:

```typescript
import { randomUUID } from 'node:crypto';

interface URLCreatedEvent {
  eventId: string;
  urlId: string;
  originalUrl: string;
  shortCode: string;
  createdAt: Date;
}

async function publishURLCreatedEvent(url: URL): Promise<void> {
  const event: URLCreatedEvent = {
    eventId: randomUUID(), // UUID v4 aleatório
    urlId: url.id,
    originalUrl: url.originalUrl,
    shortCode: url.shortCode,
    createdAt: url.createdAt,
  };

  await kafka.producer().send({
    topic: 'url.created',
    messages: [
      {
        key: url.id,
        value: JSON.stringify(event),
        headers: {
          'event-id': event.eventId,
          'event-type': 'URLCreated',
        },
      },
    ],
  });
}
```

**Identificadores Determinísticos**: Geração baseada em hash criptográfico de parâmetros semânticos de evento garante que requisições idênticas produzam mesmo Event ID, permitindo deduplicação em nível de produtor antes mesmo de publicar para broker. Implementação utiliza SHA-256 sobre concatenação de campos relevantes:

```typescript
import { createHash } from 'node:crypto';

function generateDeterministicEventId(
  urlId: string,
  originalUrl: string,
  shortCode: string
): string {
  const payload = `${urlId}:${originalUrl}:${shortCode}`;
  return createHash('sha256').update(payload).digest('hex');
}

async function publishURLCreatedEvent(url: URL): Promise<void> {
  const eventId = generateDeterministicEventId(
    url.id,
    url.originalUrl,
    url.shortCode
  );

  const event: URLCreatedEvent = {
    eventId,
    urlId: url.id,
    originalUrl: url.originalUrl,
    shortCode: url.shortCode,
    createdAt: url.createdAt,
  };

  await kafka.producer().send({
    topic: 'url.created',
    messages: [{ key: url.id, value: JSON.stringify(event) }],
  });
}
```

Abordagem determinística apresenta vantagem adicional de detectar duplicação em nível de aplicação antes de interagir com infraestrutura de mensageria, reduzindo carga em broker e eliminando mensagens redundantes precocemente no pipeline.

### Tabela de Eventos Processados

Consumidores implementam rastreamento de mensagens processadas através de tabela auxiliar que armazena Event IDs com metadados contextuais. Schema no PostgreSQL demonstra estrutura fundamental:

```typescript
CREATE TABLE processed_events (
  event_id VARCHAR(255) PRIMARY KEY,
  event_type VARCHAR(100) NOT NULL,
  processed_at TIMESTAMP NOT NULL DEFAULT NOW(),
  consumer_id VARCHAR(100) NOT NULL,
  payload JSONB,
  INDEX idx_processed_at (processed_at),
  INDEX idx_event_type (event_type)
);
```

Constraint `PRIMARY KEY` em `event_id` garante unicidade através de rejeição automática de inserções duplicadas, enquanto índices secundários facilitam queries analíticas e operações de manutenção como remoção de eventos antigos após período de retenção.

Implementação de consumidor Analytics demonstra verificação de idempotência antes de processamento:

```typescript
interface ProcessedEvent {
  eventId: string;
  eventType: string;
  processedAt: Date;
  consumerId: string;
  payload: object;
}

async function handleURLCreatedEvent(
  message: KafkaMessage
): Promise<void> {
  const event: URLCreatedEvent = JSON.parse(
    message.value.toString()
  );

  // Verificar se evento já foi processado
  const alreadyProcessed = await db.query(
    'SELECT event_id FROM processed_events WHERE event_id = $1',
    [event.eventId]
  );

  if (alreadyProcessed.rows.length > 0) {
    console.log(
      `Event ${event.eventId} already processed, skipping...`
    );
    return; // Retorna sem processar novamente
  }

  // Processar evento em transação atômica
  await db.transaction(async (tx) => {
    // Inserir URL no banco de analytics
    await tx.query(
      `INSERT INTO analytics_urls (url_id, original_url, short_code, click_count, created_at)
       VALUES ($1, $2, $3, 0, $4)`,
      [event.urlId, event.originalUrl, event.shortCode, event.createdAt]
    );

    // Registrar evento como processado
    await tx.query(
      `INSERT INTO processed_events (event_id, event_type, consumer_id, payload)
       VALUES ($1, $2, $3, $4)`,
      [
        event.eventId,
        'URLCreated',
        'analytics-consumer',
        JSON.stringify(event),
      ]
    );
  });

  console.log(`Event ${event.eventId} processed successfully`);
}
```

Utilização de transação SQL garante atomicidade entre inserção de dados analíticos e registro de evento processado, prevenindo cenário onde sistema processa evento mas falha antes de marcar como concluído, resultando em reprocessamento legítimo na próxima tentativa.

### Idempotência com Múltiplas Operações

Desafio amplia-se quando consumidor executa operações heterogêneas em sistemas de armazenamento distintos. Cenário exemplificado por Analytics que salva contadores de clicks no Redis para acesso de baixa latência e simultaneamente persiste metadados no PostgreSQL para agregações complexas.

Abordagem ingênua executando operações sequencialmente sem proteção individual cria vulnerabilidade:

```typescript
async function handleURLCreatedEvent(
  message: KafkaMessage
): Promise<void> {
  const event: URLCreatedEvent = JSON.parse(
    message.value.toString()
  );

  // Operação 1: Salvar no Redis
  await redis.set(
    `url:${event.urlId}:clicks`,
    0,
    'EX',
    86400
  ); // TTL 24h

  // Operação 2: Salvar no PostgreSQL (pode falhar)
  await db.query(
    `INSERT INTO analytics_urls (url_id, original_url, short_code, click_count)
     VALUES ($1, $2, $3, 0)`,
    [event.urlId, event.originalUrl, event.shortCode]
  );
}
```

Falha na inserção PostgreSQL após sucesso no Redis desencadeia retentativa Kafka que reexecuta ambas operações, sobrescrevendo contador Redis e potencialmente falhando novamente em PostgreSQL, criando loop infinito de retentativas.

Solução implementa idempotência granular em cada operação:

```typescript
async function handleURLCreatedEvent(
  message: KafkaMessage
): Promise<void> {
  const event: URLCreatedEvent = JSON.parse(
    message.value.toString()
  );

  // Verificar deduplicação global
  const alreadyProcessed = await db.query(
    'SELECT event_id FROM processed_events WHERE event_id = $1',
    [event.eventId]
  );

  if (alreadyProcessed.rows.length > 0) {
    console.log(`Event ${event.eventId} already processed`);
    return;
  }

  // Operação 1: Redis com verificação de existência
  const exists = await redis.exists(`url:${event.urlId}:clicks`);
  if (!exists) {
    await redis.set(`url:${event.urlId}:clicks`, 0, 'EX', 86400);
    console.log(`Redis key created for URL ${event.urlId}`);
  } else {
    console.log(
      `Redis key already exists for URL ${event.urlId}, skipping`
    );
  }

  // Operação 2: PostgreSQL com ON CONFLICT
  await db.transaction(async (tx) => {
    await tx.query(
      `INSERT INTO analytics_urls (url_id, original_url, short_code, click_count, created_at)
       VALUES ($1, $2, $3, 0, $4)
       ON CONFLICT (url_id) DO NOTHING`,
      [event.urlId, event.originalUrl, event.shortCode, event.createdAt]
    );

    await tx.query(
      `INSERT INTO processed_events (event_id, event_type, consumer_id, payload)
       VALUES ($1, $2, $3, $4)
       ON CONFLICT (event_id) DO NOTHING`,
      [
        event.eventId,
        'URLCreated',
        'analytics-consumer',
        JSON.stringify(event),
      ]
    );
  });

  console.log(`Event ${event.eventId} fully processed`);
}
```

Comando `ON CONFLICT DO NOTHING` em PostgreSQL fornece idempotência em nível de banco dados onde tentativa de inserir registro com chave primária duplicada resulta em noop silencioso ao invés de erro, permitindo conclusão bem-sucedida de transação mesmo quando dados já existem. Combinação com verificação `EXISTS` no Redis garante que cada etapa tolera reexecução sem efeitos colaterais adversos.

### Idempotência em Produtores Kafka

Kafka oferece idempotência nativa em nível de produtor através de configuração `enable.idempotence=true` introduzida na versão 0.11.0, eliminando duplicação causada por retentativas de producer através de mecanismo de sequence numbers atribuídos automaticamente a cada mensagem.

Implementação em KafkaJS demonstra configuração:

```typescript
import { Kafka } from 'kafkajs';

const kafka = new Kafka({
  clientId: 'url-shortener',
  brokers: ['kafka1:9092', 'kafka2:9092'],
});

const producer = kafka.producer({
  idempotent: true, // Habilita idempotência do produtor
  maxInFlightRequests: 5, // Máximo de requests pendentes
  transactionTimeout: 60000,
  retry: {
    retries: Number.MAX_SAFE_INTEGER,
  },
});

await producer.connect();

await producer.send({
  topic: 'url.created',
  messages: [
    {
      key: urlId,
      value: JSON.stringify(event),
    },
  ],
});
```

Quando `idempotent: true`, Kafka atribui Producer ID único e mantém sequence number incremental por partição, permitindo que broker detecte mensagens duplicadas através de comparação de sequence numbers e descarte silenciosamente retentativas redundantes. Configuração `maxInFlightRequests: 5` limita paralelismo garantindo ordenação de mensagens mesmo com múltiplas requisições em voo, enquanto `retries: Number.MAX_SAFE_INTEGER` permite retentativas ilimitadas confiando em deduplicação do broker.

Para garantias transacionais mais fortes incluindo exactly-once semantics através de múltiplos tópicos, Kafka oferece Transactional Producer:

```typescript
const producer = kafka.producer({
  transactionalId: 'url-shortener-tx-producer',
  maxInFlightRequests: 1, // Necessário para EOS
  idempotent: true, // Requerido para transações
});

await producer.connect();

const transaction = await producer.transaction();

try {
  await transaction.send({
    topic: 'url.created',
    messages: [{ key: urlId, value: JSON.stringify(event) }],
  });

  await transaction.send({
    topic: 'analytics.events',
    messages: [{ key: urlId, value: JSON.stringify(analyticsEvent) }],
  });

  await transaction.commit();
} catch (error) {
  await transaction.abort();
  throw error;
}
```

Transactional Producer garante que múltiplas mensagens publicadas para tópicos distintos sejam commitadas atomicamente ou abortadas completamente mediante falha, prevenindo estado inconsistente onde apenas subset de mensagens relacionadas é persistido.

### Cache Distribuído para Deduplicação

Alternativa à tabela de banco de dados utiliza cache distribuído como Redis para rastreamento de eventos processados, oferecendo latência substancialmente inferior através de armazenamento in-memory. Implementação demonstra utilização de Set para verificação de existência com complexidade O(1):

```typescript
import { Redis } from 'ioredis';

const redis = new Redis({
  host: 'localhost',
  port: 6379,
  db: 0,
});

async function isEventProcessed(eventId: string): Promise<boolean> {
  const exists = await redis.sismember('processed_events', eventId);
  return exists === 1;
}

async function markEventAsProcessed(
  eventId: string,
  ttlSeconds: number = 86400
): Promise<void> {
  await redis.sadd('processed_events', eventId);
  // Configurar expiração para limpeza automática após 24h
  await redis.expire('processed_events', ttlSeconds);
}

async function handleURLCreatedEvent(
  message: KafkaMessage
): Promise<void> {
  const event: URLCreatedEvent = JSON.parse(
    message.value.toString()
  );

  if (await isEventProcessed(event.eventId)) {
    console.log(`Event ${event.eventId} already processed`);
    return;
  }

  await processURLCreation(event);

  await markEventAsProcessed(event.eventId, 86400);
}
```

Vantagem primária reside em throughput elevado para verificações de existência executadas milhares de vezes por segundo, enquanto desvantagem manifesta-se através de volatilidade onde restart de Redis sem persistência RDB ou AOF resulta em perda de histórico de eventos processados, potencialmente causando reprocessamento de mensagens antigas ainda presentes em Kafka.

Abordagem híbrida combina ambos mecanismos onde Redis atua como cache de primeira linha para performance enquanto PostgreSQL fornece persistent store autoritativo:

```typescript
async function isEventProcessed(eventId: string): Promise<boolean> {
  // Verificar cache Redis primeiro (rápido)
  const inCache = await redis.sismember('processed_events', eventId);
  if (inCache === 1) {
    return true;
  }

  // Fallback para PostgreSQL (mais lento, mas autoritativo)
  const result = await db.query(
    'SELECT event_id FROM processed_events WHERE event_id = $1',
    [eventId]
  );

  if (result.rows.length > 0) {
    // Repopular cache para próximas verificações
    await redis.sadd('processed_events', eventId);
    return true;
  }

  return false;
}

async function markEventAsProcessed(eventId: string): Promise<void> {
  await db.transaction(async (tx) => {
    // Persistir em PostgreSQL
    await tx.query(
      `INSERT INTO processed_events (event_id, event_type, processed_at)
       VALUES ($1, $2, NOW())
       ON CONFLICT (event_id) DO NOTHING`,
      [eventId, 'URLCreated']
    );

    // Atualizar cache Redis
    await redis.sadd('processed_events', eventId);
  });
}
```

Estratégia write-through garante consistência onde toda inserção em PostgreSQL replica-se imediatamente para Redis, enquanto cache misses resultam em consulta a PostgreSQL seguida de warming automático do cache.

## Idempotência em APIs RESTful

### Métodos HTTP Idempotentes

Especificação RFC 7231 que define semântica HTTP classifica métodos segundo propriedade de idempotência, orientando design de APIs RESTful:

**GET**: Inerentemente idempotente por natureza read-only onde múltiplas requisições idênticas retornam mesmo recurso sem modificação de estado servidor. Requisição `GET /urls/abc123` executada repetidamente sempre retorna mesma representação de URL encurtada.

**PUT**: Projetado para idempotência através de substituição completa de recurso onde estado final depende exclusivamente de payload enviado, independente de quantas vezes operação é aplicada. Requisição `PUT /urls/abc123` com body `{"originalUrl": "https://example.com", "shortCode": "abc123"}` aplicada múltiplas vezes resulta em estado idêntico.

```typescript
app.put('/urls/:id', async (req, res) => {
  const { id } = req.params;
  const { originalUrl, shortCode } = req.body;

  // Operação idempotente: sempre resulta no mesmo estado final
  await db.query(
    `INSERT INTO urls (id, original_url, short_code, updated_at)
     VALUES ($1, $2, $3, NOW())
     ON CONFLICT (id) DO UPDATE
     SET original_url = EXCLUDED.original_url,
         short_code = EXCLUDED.short_code,
         updated_at = NOW()`,
    [id, originalUrl, shortCode]
  );

  res.status(200).json({ id, originalUrl, shortCode });
});
```

Utilização de `INSERT ... ON CONFLICT DO UPDATE` garante que operação cria recurso se inexistente ou atualiza completamente se já existe, produzindo resultado idempotente.

**DELETE**: Idempotente através de semântica onde deleção de recurso inexistente resulta em noop ou status `404 Not Found` sem efeitos colaterais. Segunda tentativa de deletar recurso já removido não altera estado do sistema.

```typescript
app.delete('/urls/:id', async (req, res) => {
  const { id } = req.params;

  const result = await db.query(
    'DELETE FROM urls WHERE id = $1 RETURNING id',
    [id]
  );

  if (result.rows.length === 0) {
    return res.status(404).json({ error: 'URL not found' });
  }

  res.status(204).send();
});
```

Primeira execução deleta recurso retornando `204 No Content`, enquanto execuções subsequentes retornam `404 Not Found` sem modificar estado, comportamento considerado idempotente por convenção REST.

**POST**: Explicitamente não-idempotente por design onde cada requisição deve criar novo recurso com identificador distinto. Requisição `POST /urls` com payload idêntico executada múltiplas vezes resulta em criação de URLs encurtadas separadas.

```typescript
app.post('/urls', async (req, res) => {
  const { originalUrl } = req.body;

  // Não-idempotente: cada chamada cria novo recurso
  const id = randomUUID();
  const shortCode = generateShortCode();

  await db.query(
    `INSERT INTO urls (id, original_url, short_code, created_at)
     VALUES ($1, $2, $3, NOW())`,
    [id, originalUrl, shortCode]
  );

  res.status(201).json({
    id,
    originalUrl,
    shortCode,
    shortUrl: `https://short.url/${shortCode}`,
  });
});
```

### Implementação de Idempotency Keys em APIs

Apesar de POST ser semanticamente não-idempotente, APIs de pagamento e operações críticas implementam idempotência através de header customizado `Idempotency-Key` fornecido por cliente, permitindo que requisições duplicadas sejam detectadas e respondidas com resultado da operação original.

Stripe API demonstra padrão de referência:

```typescript
import { createHash } from 'node:crypto';

interface IdempotentRequest {
  idempotencyKey: string;
  endpoint: string;
  statusCode: number;
  responseBody: string;
  createdAt: Date;
  expiresAt: Date;
}

const requestCache = new Map<string, IdempotentRequest>();

app.post('/payments', async (req, res) => {
  const idempotencyKey = req.headers['idempotency-key'] as string;

  if (!idempotencyKey) {
    return res.status(400).json({
      error: 'Idempotency-Key header is required',
    });
  }

  // Verificar se requisição com mesmo idempotency key já foi processada
  const cachedRequest = requestCache.get(idempotencyKey);
  if (cachedRequest) {
    console.log(`Returning cached response for key ${idempotencyKey}`);
    return res
      .status(cachedRequest.statusCode)
      .json(JSON.parse(cachedRequest.responseBody));
  }

  // Processar pagamento
  const { amount, currency, customerId } = req.body;

  const payment = await processPayment({
    amount,
    currency,
    customerId,
  });

  const response = {
    id: payment.id,
    amount: payment.amount,
    currency: payment.currency,
    status: payment.status,
  };

  // Cachear resposta com TTL de 24 horas
  requestCache.set(idempotencyKey, {
    idempotencyKey,
    endpoint: '/payments',
    statusCode: 201,
    responseBody: JSON.stringify(response),
    createdAt: new Date(),
    expiresAt: new Date(Date.now() + 86400000),
  });

  res.status(201).json(response);
});
```

Cliente gera Idempotency Key através de UUID ou hash de parâmetros da requisição, enviando em header customizado:

```typescript
import axios from 'axios';
import { randomUUID } from 'node:crypto';

async function createPayment(
  amount: number,
  currency: string,
  customerId: string
): Promise<Payment> {
  const idempotencyKey = randomUUID();

  const response = await axios.post(
    'https://api.example.com/payments',
    {
      amount,
      currency,
      customerId,
    },
    {
      headers: {
        'Idempotency-Key': idempotencyKey,
      },
    }
  );

  return response.data;
}

// Primeira chamada: cria pagamento
await createPayment(1000, 'USD', 'cus_123');

// Segunda chamada com mesmo key: retorna resultado cacheado sem criar novo pagamento
await createPayment(1000, 'USD', 'cus_123');
```

Servidor armazena mapeamento entre Idempotency Key e resposta completa da primeira requisição bem-sucedida, retornando resultado cacheado para requisições subsequentes com mesmo key sem reexecutar lógica de negócio.

Implementação robusta persiste cache em Redis com expiração automática:

```typescript
async function handleIdempotentRequest(
  idempotencyKey: string,
  handler: () => Promise<any>
): Promise<any> {
  const cacheKey = `idempotency:${idempotencyKey}`;

  // Verificar cache
  const cached = await redis.get(cacheKey);
  if (cached) {
    return JSON.parse(cached);
  }

  // Executar handler
  const result = await handler();

  // Cachear resultado com TTL de 24h
  await redis.set(cacheKey, JSON.stringify(result), 'EX', 86400);

  return result;
}

app.post('/payments', async (req, res) => {
  const idempotencyKey = req.headers['idempotency-key'] as string;

  if (!idempotencyKey) {
    return res.status(400).json({
      error: 'Idempotency-Key header required',
    });
  }

  const payment = await handleIdempotentRequest(idempotencyKey, async () => {
    return await processPayment(req.body);
  });

  res.status(201).json(payment);
});
```

## Padrões Avançados e Casos de Uso

### Idempotência em Event Sourcing

Event Sourcing armazena sequência imutável de eventos representando todas mudanças de estado ao invés de sobrescrever estado atual, onde idempotência manifesta-se através de prevenção de eventos duplicados em Event Store.

Implementação demonstra deduplicação em nível de append:

```typescript
interface Event {
  eventId: string;
  aggregateId: string;
  eventType: string;
  data: object;
  metadata: {
    userId: string;
    timestamp: Date;
    correlationId: string;
  };
  version: number;
}

class EventStore {
  async appendEvent(event: Event): Promise<void> {
    // Verificar se evento já foi appendado
    const exists = await db.query(
      'SELECT event_id FROM events WHERE event_id = $1',
      [event.eventId]
    );

    if (exists.rows.length > 0) {
      console.log(`Event ${event.eventId} already exists, skipping`);
      return;
    }

    // Append idempotente com constraint de versão otimista
    await db.query(
      `INSERT INTO events (event_id, aggregate_id, event_type, data, metadata, version, created_at)
       VALUES ($1, $2, $3, $4, $5, $6, NOW())`,
      [
        event.eventId,
        event.aggregateId,
        event.eventType,
        JSON.stringify(event.data),
        JSON.stringify(event.metadata),
        event.version,
      ]
    );
  }
}
```

Constraint `UNIQUE (event_id)` em tabela events garante impossibilidade de duplicação, enquanto optimistic concurrency control através de campo `version` previne race conditions onde múltiplas threads tentam appendar eventos concorrentemente.

### Idempotência em Saga Pattern

Saga Pattern coordena transações distribuídas através de sequência de transações locais com compensações, onde idempotência torna-se crítica para garantir que etapas e compensações possam ser retentadas sem efeitos colaterais duplicados.

Implementação demonstra orquestrador idempotente:

```typescript
interface SagaStep {
  stepId: string;
  action: () => Promise<void>;
  compensation: () => Promise<void>;
}

class SagaOrchestrator {
  private executedSteps: Set<string> = new Set();

  async executeSaga(sagaId: string, steps: SagaStep[]): Promise<void> {
    // Carregar estado de execução anterior
    const state = await this.loadSagaState(sagaId);
    this.executedSteps = new Set(state.executedSteps);

    try {
      for (const step of steps) {
        if (this.executedSteps.has(step.stepId)) {
          console.log(`Step ${step.stepId} already executed, skipping`);
          continue;
        }

        await step.action();
        this.executedSteps.add(step.stepId);

        await this.persistSagaState(sagaId, {
          executedSteps: Array.from(this.executedSteps),
        });
      }
    } catch (error) {
      await this.compensate(steps);
      throw error;
    }
  }

  private async compensate(steps: SagaStep[]): Promise<void> {
    const executedStepsList = Array.from(this.executedSteps).reverse();

    for (const stepId of executedStepsList) {
      const step = steps.find((s) => s.stepId === stepId);
      if (step) {
        await step.compensation();
      }
    }
  }
}
```

Saga persiste conjunto de etapas executadas antes de cada ação, permitindo que falha seguida de restart retome execução pulando etapas já concluídas através de verificação em `executedSteps`.

### Idempotência em Message Deduplication

RabbitMQ não oferece deduplicação nativa como Kafka, exigindo implementação em nível de aplicação. Plugin RabbitMQ Message Deduplication fornece idempotência baseada em header customizado:

```typescript
import amqp from 'amqplib';

const connection = await amqp.connect('amqp://localhost');
const channel = await connection.createChannel();

await channel.assertExchange('events', 'topic', { durable: true });
await channel.assertQueue('analytics-queue', { durable: true });
await channel.bindQueue('analytics-queue', 'events', 'url.created');

// Publicar mensagem com deduplication header
const event = {
  eventId: randomUUID(),
  urlId: 'url_123',
  originalUrl: 'https://example.com',
  shortCode: 'abc123',
};

channel.publish('events', 'url.created', Buffer.from(JSON.stringify(event)), {
  persistent: true,
  headers: {
    'x-deduplication-header': event.eventId,
  },
});

// Consumir com deduplicação manual
channel.consume('analytics-queue', async (msg) => {
  if (!msg) return;

  const event = JSON.parse(msg.content.toString());
  const deduplicationId = msg.properties.headers['x-deduplication-header'];

  if (await isEventProcessed(deduplicationId)) {
    channel.ack(msg);
    return;
  }

  await processEvent(event);
  await markEventAsProcessed(deduplicationId);

  channel.ack(msg);
});
```

Header `x-deduplication-header` transporta Event ID utilizado por consumidor para verificação de processamento prévio, enquanto plugin RabbitMQ Message Deduplication pode ser configurado para rejeição automática de mensagens duplicadas antes de alcançar consumidores.

## Desafios e Trade-offs

### Overhead de Performance

Verificação de idempotência através de consultas a tabela de eventos processados introduz latência adicional em caminho crítico de processamento de mensagens. Benchmarks demonstram impacto mensurável:

- Consulta PostgreSQL: 5-10ms de latência adicional por mensagem
- Consulta Redis: 0.5-1ms de latência adicional por mensagem
- Cache em memória local: <0.1ms mas limitado a instância única

Para sistemas processando milhares de mensagens por segundo, overhead acumulativo pode degradar throughput substancialmente. Estratégias de otimização incluem:

**Batching de Verificações**: Acumular múltiplas mensagens e verificar idempotência em lote único através de query `WHERE event_id IN (...)` reduzindo roundtrips ao banco.

**Bloom Filters**: Estrutura probabilística de dados que indica com certeza quando evento definitivamente não foi processado, eliminando maioria de consultas ao banco para eventos novos enquanto aceita taxa configurável de falsos positivos que resultam em consultas desnecessárias mas não em incorretude.

**Sharding Temporal**: Particionar tabela de eventos processados por janelas temporais onde verificações consultam exclusivamente partição recente, reduzindo tamanho de índice pesquisado.

### Gestão de Armazenamento

Tabela de eventos processados cresce indefinidamente acumulando milhões de registros em sistemas de alto throughput, consumindo armazenamento substancial e degradando performance de índices. Estratégias de retenção incluem:

**TTL Automático**: Expurgar eventos processados após janela de retenção configurada baseando-se em observação empírica de que mensagens duplicadas tipicamente chegam dentro de minutos ou horas da original, raramente após dias.

```typescript
-- Job periódico de limpeza executado diariamente
DELETE FROM processed_events
WHERE processed_at < NOW() - INTERVAL '7 days';
```

**Particionamento por Data**: Utilizar table partitioning do PostgreSQL criando partições mensais automaticamente, permitindo DROP de partições antigas sem bloqueio de tabela principal.

```typescript
CREATE TABLE processed_events (
  event_id VARCHAR(255) NOT NULL,
  event_type VARCHAR(100) NOT NULL,
  processed_at TIMESTAMP NOT NULL DEFAULT NOW(),
  PRIMARY KEY (event_id, processed_at)
) PARTITION BY RANGE (processed_at);

CREATE TABLE processed_events_2025_01
PARTITION OF processed_events
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

### Consistência em Sistemas Distribuídos

Verificação de idempotência seguida de processamento não constitui operação atômica quando atravessam sistemas distintos, criando race condition onde duas instâncias de consumidor verificam simultaneamente que evento não foi processado, ambas prosseguem com processamento resultando em duplicação.

Solução através de lock distribuído:

```typescript
import Redlock from 'redlock';

const redlock = new Redlock([redis], {
  retryCount: 3,
  retryDelay: 200,
});

async function handleURLCreatedEvent(
  message: KafkaMessage
): Promise<void> {
  const event: URLCreatedEvent = JSON.parse(
    message.value.toString()
  );

  const lockKey = `lock:event:${event.eventId}`;
  const lock = await redlock.acquire([lockKey], 5000); // 5s TTL

  try {
    if (await isEventProcessed(event.eventId)) {
      return;
    }

    await processURLCreation(event);
    await markEventAsProcessed(event.eventId);
  } finally {
    await lock.release();
  }
}
```

Redlock garante que apenas uma instância de consumidor processa evento específico mesmo quando múltiplas réplicas recebem mensagem duplicada simultaneamente, eliminando race condition através de coordenação distribuída.

## Conclusões

Idempotência constitui propriedade arquitetural não-negociável em sistemas de microsserviços modernos que dependem de comunicação assíncrona através de message brokers implementando garantias at-least-once delivery. Ausência de mecanismos robustos de deduplicação resulta em inconsistências sutis e perniciosas manifestando-se como duplicação de cobranças financeiras, inflação de métricas analíticas, envio redundante de notificações e corrupção de estado agregado através de incrementos espúrios. Implementação efetiva combina múltiplas camadas de defesa incluindo idempotência nativa de produtores Kafka através de sequence numbers, rastreamento de Event IDs em tabelas de eventos processados ou caches distribuídos Redis, operações SQL idempotentes através de `ON CONFLICT DO NOTHING` e `INSERT ... ON CONFLICT DO UPDATE`, e design de APIs RESTful aderentes a semântica de métodos HTTP conforme RFC 7231.

Padrão transcende implementação técnica para tornar-se consideração fundamental em design de contratos de eventos e APIs públicas, exemplificado por adoção universal de Idempotency Keys em serviços de pagamento como Stripe, PayPal e Twilio que reconhecem criticidade de permitir retentativas seguras de operações financeiras sensíveis. Desenvolvedores construindo sistemas distribuídos devem internalizar idempotência como requisito padrão ao invés de otimização opcional, projetando cada operação de modificação de estado para tolerar execuções repetidas sem efeitos colaterais adversos. Trade-offs incluem overhead de performance através de consultas adicionais ao banco de dados ou Redis, complexidade operacional de gerenciar armazenamento crescente de eventos processados, e necessidade de coordenação distribuída através de locks para prevenir race conditions em ambientes multi-threaded, porém benefícios de correção e confiabilidade em presença de falhas de rede e retentativas justificam amplamente custo incremental. Evolução futura concentra-se em padronização de headers HTTP para idempotência além de contexto de pagamentos, integração nativa de deduplicação em message brokers eliminando necessidade de implementação em nível de aplicação, e desenvolvimento de bibliotecas e frameworks que abstraiam complexidade de idempotência fornecendo primitivas reutilizáveis para desenvolvedores.

## Referências Bibliográficas

1. **RFC 7231 - Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content**. IETF. Disponível em: https://datatracker.ietf.org/doc/html/rfc7231#section-4.2.2. Especificação oficial de semântica HTTP incluindo classificação de métodos idempotentes.

2. **RFC 9110 - HTTP Semantics**. IETF. Disponível em: https://www.rfc-editor.org/rfc/rfc9110.html. Atualização da especificação HTTP com revisão de conceitos de idempotência.

3. **Stripe API - Idempotent Requests**. Stripe. Disponível em: https://stripe.com/docs/api/idempotent_requests. Documentação de referência sobre implementação de Idempotency Keys em APIs de pagamento.

4. **PayPal Developer - Idempotency**. PayPal. Disponível em: https://developer.paypal.com/api/rest/idempotency/. Padrões de idempotência em APIs financeiras.

5. **Apache Kafka Documentation - Idempotent Producer**. Apache Software Foundation. Disponível em: https://kafka.apache.org/documentation/#producerconfigs_enable.idempotence. Configuração e garantias de produtores idempotentes.

6. **Microservices.io - Idempotent Consumer Pattern**. Chris Richardson. Disponível em: https://microservices.io/patterns/communication-style/idempotent-consumer.html. Padrão arquitetural de consumidor idempotente.

7. **Microsoft Azure Architecture - Idempotent Message Processing**. Microsoft. Disponível em: https://learn.microsoft.com/azure/architecture/reference-architectures/containers/aks-mission-critical/mission-critical-data-platform#idempotent-message-processing. Estratégias de processamento idempotente em plataformas cloud.

8. **Martin Fowler - Idempotency**. Martin Fowler. Disponível em: https://martinfowler.com/bliki/IdempotentReceiver.html. Conceitos fundamentais de idempotência em sistemas distribuídos.

9. **Enterprise Integration Patterns - Idempotent Receiver**. Gregor Hohpe. Disponível em: https://www.enterpriseintegrationpatterns.com/patterns/messaging/IdempotentReceiver.html. Padrão de integração corporativa para receptores idempotentes.

10. **AWS SQS - Exactly-Once Processing**. Amazon Web Services. Disponível em: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-exactly-once-processing.html. Implementação de exactly-once semantics em SQS FIFO.

## Apêndice A: Exemplo Completo de Sistema Idempotente

Implementação completa demonstrando todos conceitos apresentados em sistema de encurtamento de URLs:

```typescript
// shared/types.ts
export interface URLCreatedEvent {
  eventId: string;
  urlId: string;
  originalUrl: string;
  shortCode: string;
  userId: string;
  createdAt: Date;
}

// shortener-service/producer.ts
import { Kafka } from 'kafkajs';
import { createHash, randomUUID } from 'node:crypto';

const kafka = new Kafka({
  clientId: 'url-shortener',
  brokers: ['localhost:9092'],
});

const producer = kafka.producer({
  idempotent: true,
  maxInFlightRequests: 5,
});

function generateEventId(
  urlId: string,
  originalUrl: string,
  shortCode: string
): string {
  const payload = `${urlId}:${originalUrl}:${shortCode}`;
  return createHash('sha256').update(payload).digest('hex');
}

export async function publishURLCreatedEvent(
  url: {
    id: string;
    originalUrl: string;
    shortCode: string;
    userId: string;
  }
): Promise<void> {
  const event: URLCreatedEvent = {
    eventId: generateEventId(url.id, url.originalUrl, url.shortCode),
    urlId: url.id,
    originalUrl: url.originalUrl,
    shortCode: url.shortCode,
    userId: url.userId,
    createdAt: new Date(),
  };

  await producer.send({
    topic: 'url.created',
    messages: [
      {
        key: url.id,
        value: JSON.stringify(event),
        headers: {
          'event-id': event.eventId,
          'event-type': 'URLCreated',
          'correlation-id': randomUUID(),
        },
      },
    ],
  });

  console.log(`Published event ${event.eventId} for URL ${url.id}`);
}

// analytics-service/consumer.ts
import { Kafka, EachMessagePayload } from 'kafkajs';
import { Pool } from 'pg';
import { Redis } from 'ioredis';

const kafka = new Kafka({
  clientId: 'analytics-consumer',
  brokers: ['localhost:9092'],
});

const consumer = kafka.consumer({ groupId: 'analytics-group' });

const db = new Pool({
  host: 'localhost',
  port: 5432,
  database: 'analytics',
  user: 'postgres',
  password: 'password',
});

const redis = new Redis({
  host: 'localhost',
  port: 6379,
});

async function isEventProcessed(eventId: string): Promise<boolean> {
  // Verificar cache Redis primeiro
  const inCache = await redis.sismember('processed_events', eventId);
  if (inCache === 1) {
    return true;
  }

  // Fallback para PostgreSQL
  const result = await db.query(
    'SELECT event_id FROM processed_events WHERE event_id = $1',
    [eventId]
  );

  if (result.rows.length > 0) {
    await redis.sadd('processed_events', eventId);
    return true;
  }

  return false;
}

async function handleURLCreatedEvent(
  event: URLCreatedEvent
): Promise<void> {
  if (await isEventProcessed(event.eventId)) {
    console.log(`Event ${event.eventId} already processed`);
    return;
  }

  const client = await db.connect();

  try {
    await client.query('BEGIN');

    // Inserir URL no analytics
    await client.query(
      `INSERT INTO analytics_urls (url_id, original_url, short_code, click_count, created_at)
       VALUES ($1, $2, $3, 0, $4)
       ON CONFLICT (url_id) DO NOTHING`,
      [event.urlId, event.originalUrl, event.shortCode, event.createdAt]
    );

    // Registrar evento como processado
    await client.query(
      `INSERT INTO processed_events (event_id, event_type, consumer_id, payload, processed_at)
       VALUES ($1, $2, $3, $4, NOW())`,
      [
        event.eventId,
        'URLCreated',
        'analytics-consumer',
        JSON.stringify(event),
      ]
    );

    await client.query('COMMIT');

    // Atualizar cache Redis
    await redis.sadd('processed_events', event.eventId);

    console.log(`Event ${event.eventId} processed successfully`);
  } catch (error) {
    await client.query('ROLLBACK');
    throw error;
  } finally {
    client.release();
  }
}

async function run(): Promise<void> {
  await consumer.connect();
  await consumer.subscribe({ topic: 'url.created', fromBeginning: false });

  await consumer.run({
    eachMessage: async ({ message }: EachMessagePayload) => {
      const event: URLCreatedEvent = JSON.parse(
        message.value!.toString()
      );

      try {
        await handleURLCreatedEvent(event);
      } catch (error) {
        console.error(`Error processing event ${event.eventId}:`, error);
        throw error;
      }
    },
  });
}

run().catch(console.error);
```

## Apêndice B: Glossário e Termos Técnicos

**At-Least-Once Delivery**: Garantia de entrega de mensagens onde message broker assegura que mensagem seja entregue ao menos uma vez, podendo resultar em duplicações mediante retentativas após falhas ou timeouts.

**Bloom Filter**: Estrutura probabilística de dados que testa se elemento pertence a conjunto com possibilidade de falsos positivos mas impossibilidade de falsos negativos, utilizada para reduzir consultas a armazenamento persistente.

**Consumer Group**: Conjunto de consumidores Kafka que compartilham processamento de tópico através de distribuição de partições entre membros do grupo, garantindo paralelização horizontal.

**Deduplication**: Processo de identificar e eliminar mensagens ou requisições duplicadas através de rastreamento de identificadores únicos.

**Event ID**: Identificador único e imutável associado a evento específico, utilizado para rastreamento e deduplicação através de todo sistema distribuído.

**Event Sourcing**: Padrão arquitetural onde estado de aplicação é armazenado como sequência imutável de eventos ao invés de sobrescrever valores atuais.

**Exactly-Once Semantics**: Garantia de processamento onde cada mensagem é processada exatamente uma vez, sem duplicações ou perdas, alcançada através de coordenação entre produtores idempotentes e consumidores transacionais.

**Idempotency Key**: Identificador único fornecido por cliente em requisições HTTP através de header customizado, permitindo que servidor detecte e responda apropriadamente a requisições duplicadas.

**Idempotent Operation**: Operação que pode ser aplicada múltiplas vezes produzindo resultado idêntico à aplicação única, propriedade fundamental para tolerância a retentativas.

**Message Broker**: Infraestrutura intermediária que facilita comunicação assíncrona entre serviços através de padrões publish/subscribe e queueing, exemplificado por Apache Kafka e RabbitMQ.

**Offset**: Posição sequencial de mensagem dentro de partição Kafka, utilizada por consumidores para rastrear progresso de processamento e possibilitar reprocessamento controlado.

**Optimistic Concurrency Control**: Técnica de controle de concorrência onde transações verificam conflitos apenas no momento de commit através de campos de versão, permitindo paralelismo otimista.

**Partitioning**: Divisão de tópico Kafka em múltiplas partições distribuídas através de cluster, permitindo paralelização de produção e consumo.

**Processed Events Table**: Tabela auxiliar que armazena identificadores de eventos já processados com timestamps, utilizada para implementar deduplicação em consumidores.

**Redlock**: Algoritmo de distributed locking para Redis que garante exclusão mútua através de múltiplos nós Redis independentes.

**Saga Pattern**: Padrão para gerenciamento de transações distribuídas através de sequência de transações locais com compensações definidas para reversão mediante falhas.

**Sequence Number**: Número sequencial atribuído automaticamente por produtor Kafka idempotente a cada mensagem por partição, permitindo detecção de duplicações pelo broker.

**Soft Reference**: Referência entre entidades de microsserviços distintos através de identificadores sem constraints de foreign key em nível de banco de dados.

**Transactional Producer**: Produtor Kafka que suporta escrita atômica de múltiplas mensagens através de tópicos distintos mediante transações com semântica commit/abort.

**TTL (Time To Live)**: Período de tempo após qual registro ou entrada de cache expira automaticamente, utilizado para gestão de armazenamento de eventos processados.

**Two-Phase Commit**: Protocolo de commit distribuído que coordena transações através de múltiplos recursos garantindo atomicidade mediante fase de preparação seguida de commit, geralmente evitado em microsserviços devido a acoplamento temporal.
